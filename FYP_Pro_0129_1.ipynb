{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMoo606A7ugc05g9jk7Jo6B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lrrong2020/A/blob/main/FYP_Pro_0129_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "VjeGEXN7MH4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwK1YvMFL9Xz",
        "outputId": "72a17e5f-0f8a-4e6b-d003-f7f2bfe2e3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prep"
      ],
      "metadata": {
        "id": "wT_n6JPqMeCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Kaggle/unzip/\n",
        "!cp ../kaggle.json /root/.kaggle/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWJglFbYMmEr",
        "outputId": "c652695d-1647-4b5d-daba-0a233c6fc2f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Kaggle/unzip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GitHub"
      ],
      "metadata": {
        "id": "i_Y1lyGWiJAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #For reading csv files.\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt #For plotting.\n",
        "\n",
        "import PIL.Image as Image #For working with image files.\n",
        "\n",
        "#Importing torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset,DataLoader #For working with data.\n",
        "\n",
        "from torchvision import models,transforms #For pretrained models,image transformations.\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "torch.manual_seed(3407)"
      ],
      "metadata": {
        "id": "qqAFoYKfjQHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d1b367-d832-4248-f3ba-b2d194c9c564"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ed776298330>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Use GPU if it's available or else use CPU.\n",
        "print(device) #Prints the device we're using."
      ],
      "metadata": {
        "id": "_-dPSwwujHvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf35a9f4-7086-438f-a2a0-b697f5dc28bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/gdrive/MyDrive/Kaggle/unzip/\"\n",
        "\n",
        "all_df = pd.read_csv(f\"{path}allLabels.csv\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# subset\n",
        "sub_df, depre_df = train_test_split(all_df, test_size=0.8, random_state=42)\n",
        "\n",
        "# Assuming train_df is your original training DataFrame\n",
        "train_df, test_df = train_test_split(sub_df, test_size=1400, random_state=42)\n",
        "\n",
        "# Now split the remaining training data into training and validation sets\n",
        "train_df, valid_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "print(f'No.of.training_samples: {len(train_df)}')\n",
        "print(f'No.of.testing_samples: {len(test_df)}')\n",
        "print(f'No.of.val_samples: {len(valid_df)}')"
      ],
      "metadata": {
        "id": "NjkojF_kawHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e0d129d-cb3c-42e1-9032-d0e0a608efda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.of.training_samples: 5062\n",
            "No.of.testing_samples: 1400\n",
            "No.of.val_samples: 563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogram of label counts.\n",
        "train_df.level.hist()\n",
        "plt.xticks([0,1,2,3,4])\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "yQVZJzjXkBwP",
        "outputId": "a5bd99d3-f7e5-4b77-b916-2b2836980483"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#As you can see,the data is imbalanced.\n",
        "#So we've to calculate weights for each class,which can be used in calculating loss.\n",
        "\n",
        "from sklearn.utils import class_weight #For calculating weights for each class.\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.array([0,1,2,3,4]),y=train_df['level'].values)\n",
        "class_weights = torch.tensor(class_weights,dtype=torch.float).to(device)\n",
        "\n",
        "print(class_weights) #Prints the calculated weights for the classes."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYrE034FkXSI",
        "outputId": "e44d58f3-b20c-467e-ed67-cf0afa82159f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2743, 2.9776, 1.3030, 6.9342, 9.3741], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For getting a random image from our training set.\n",
        "# num = int(np.random.randint(0,len(train_df)-1,(1,))) #Picks a random number.\n",
        "# sample_image = (f'{path}train/{train_df[\"image\"][num]}.jpeg')#Image file.\n",
        "# sample_image = Image.open(sample_image)\n",
        "# plt.imshow(sample_image)\n",
        "# plt.axis('off')\n",
        "# plt.title(f'Class: {train_df[\"level\"][num]}') #Class of the random image.\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "2CAOhlpYklys"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset): # Inherits from the Dataset class.\n",
        "    '''\n",
        "    dataset class overloads the __init__, __len__, __getitem__ methods of the Dataset class.\n",
        "\n",
        "    Attributes :\n",
        "        df:  DataFrame object for the csv file.\n",
        "        data_path: Location of the dataset.\n",
        "        image_transform: Transformations to apply to the image.\n",
        "        train: A boolean indicating whether it is a training_set or not.\n",
        "    '''\n",
        "\n",
        "    def __init__(self,df,data_path,image_transform=None,train=True): # Constructor.\n",
        "        super(Dataset,self).__init__() #Calls the constructor of the Dataset class.\n",
        "        self.df = df\n",
        "        self.data_path = data_path\n",
        "        self.image_transform = image_transform\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df) #Returns the number of samples in the dataset.\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        image_id = self.df['image'][index]\n",
        "        image = Image.open(f'{self.data_path}/{image_id}.jpeg') #Image.\n",
        "        if self.image_transform :\n",
        "            image = self.image_transform(image) #Applies transformation to the image.\n",
        "\n",
        "        if self.train :\n",
        "            label = self.df['level'][index] #Label.\n",
        "            return image,label #If train == True, return image & label.\n",
        "\n",
        "        else:\n",
        "            return image #If train != True, return image.\n"
      ],
      "metadata": {
        "id": "C8rgUjyom5uS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_transform = transforms.Compose([transforms.Resize([512,512]),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) #Transformations to apply to the image.\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "valid_df = valid_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train_set = dataset(train_df,f'{path}train',image_transform=image_transform)\n",
        "test_set = dataset(test_df,f'{path}train',image_transform=image_transform)\n",
        "valid_set = dataset(valid_df,f'{path}train',image_transform=image_transform)"
      ],
      "metadata": {
        "id": "4UsJqLqinRA0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_set,batch_size=16,shuffle=True, num_workers=4) #DataLoader for train_set.\n",
        "valid_dataloader = DataLoader(valid_set,batch_size=16,shuffle=False, num_workers=4) #DataLoader for validation_set.\n",
        "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "rm8l4B2Am0Ry"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50,ResNet50_Weights\n",
        "#Since we've less data, we'll use Transfer learning.\n",
        "model = models.resnet50(weights=ResNet50_Weights.DEFAULT) #Downloads the resnet50 model which is pretrained on Imagenet dataset.\n",
        "# Replace the Final layer of pretrained resnet50 with 2 new layers.\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 5),\n",
        ")"
      ],
      "metadata": {
        "id": "4SXyKyippyDz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device) #Moves the model to the device."
      ],
      "metadata": {
        "id": "r96X5p-_q2YI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "    '''\n",
        "    train function updates the weights of the model based on the\n",
        "    loss using the optimizer in order to get a lower loss.\n",
        "\n",
        "    Args :\n",
        "         dataloader: Iterator for the batches in the data_set.\n",
        "         model: Given an input produces an output by multiplying the input with the model weights.\n",
        "         loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "         optimizer: Updates the model weights.\n",
        "\n",
        "    Returns :\n",
        "         Average loss per batch which is calculated by dividing the losses for all the batches\n",
        "         with the number of batches.\n",
        "    '''\n",
        "\n",
        "    model.train() #Sets the model for training.\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    for batch,(x,y) in enumerate(dataloader): #Iterates through the batches.\n",
        "\n",
        "        output = model(x.to(device)) #model's predictions.\n",
        "        loss   = loss_fn(output,y.to(device)) #loss calculation.\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        total        += y.size(0)\n",
        "        predictions   = output.argmax(dim=1).cpu().detach() #Index for the highest score for all the samples in the batch.\n",
        "        correct      += (predictions == y.cpu().detach()).sum().item() #No.of.cases where model's predictions are equal to the label.\n",
        "        accuracy = 100*(correct/total)\n",
        "\n",
        "        optimizer.zero_grad() #Gradient values are set to zero.\n",
        "        loss.backward() #Calculates the gradients.\n",
        "        optimizer.step() #Updates the model weights.\n",
        "\n",
        "        # x, y = x.cpu(), y.cpu()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Print some information every 10 batches\n",
        "        if batch % 10 == 0:\n",
        "            print(f'Batch {batch}/{len(dataloader)} processed, running loss: {running_loss:.6f}, correct predictions: {correct}, total: {total}')\n",
        "\n",
        "\n",
        "    avg_loss = running_loss/len(dataloader) # Average loss for a single batch\n",
        "\n",
        "    print(f'\\nTraining Loss per batch = {avg_loss:.6f}',end='\\t')\n",
        "    print(f'Accuracy on Training set = {100*(correct/total):.6f}% [{correct}/{total}]') #Prints the Accuracy.\n",
        "\n",
        "    torch.save(model, './DR_ResNet50.pt')\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "OYwzKdDzqier"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(dataloader,model,loss_fn):\n",
        "    '''\n",
        "    validate function calculates the average loss per batch and the accuracy of the model's predictions.\n",
        "\n",
        "    Args :\n",
        "         dataloader: Iterator for the batches in the data_set.\n",
        "         model: Given an input produces an output by multiplying the input with the model weights.\n",
        "         loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "\n",
        "    Returns :\n",
        "         Average loss per batch which is calculated by dividing the losses for all the batches\n",
        "         with the number of batches.\n",
        "    '''\n",
        "\n",
        "    model.eval() #Sets the model for evaluation.\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    with torch.no_grad(): #No need to calculate the gradients.\n",
        "\n",
        "        for x,y in dataloader:\n",
        "\n",
        "            output        = model(x.to(device)) #model's output.\n",
        "            loss          = loss_fn(output,y.to(device)).item() #loss calculation.\n",
        "            running_loss += loss\n",
        "\n",
        "            total        += y.size(0)\n",
        "            predictions   = output.argmax(dim=1).cpu().detach()\n",
        "            correct      += (predictions == y.cpu().detach()).sum().item()\n",
        "            accuracy = 100*(correct/total)\n",
        "\n",
        "    avg_loss = running_loss/len(dataloader) #Average loss per batch.\n",
        "\n",
        "    print(f'\\nValidation Loss per batch = {avg_loss:.6f}',end='\\t')\n",
        "    print(f'Accuracy on Validation set = {100*(correct/total):.6f}% [{correct}/{total}]') #Prints the Accuracy.\n",
        "\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "CG6C4yH-qf48"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize(train_dataloader,valid_dataloader,model,loss_fn,optimizer,nb_epochs, patience):\n",
        "    '''\n",
        "    optimize function calls the train & validate functions for (nb_epochs) times.\n",
        "\n",
        "    Args :\n",
        "        train_dataloader: DataLoader for the train_set.\n",
        "        valid_dataloader: DataLoader for the valid_set.\n",
        "        model: Given an input produces an output by multiplying the input with the model weights.\n",
        "        loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "        optimizer: Updates the model weights.\n",
        "        nb_epochs: Number of epochs.\n",
        "\n",
        "    Returns :\n",
        "        Tuple of lists containing losses for all the epochs.\n",
        "    '''\n",
        "    # Initialize the learning rate scheduler\n",
        "    scheduler = StepLR(optimizer, step_size=4, gamma=0.5)\n",
        "\n",
        "    #Lists to store losses for all the epochs.\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    df = pd.DataFrame(columns=['epoch', 'train_loss', 'train_accuracy', 'valid_loss', 'valid_accuracy'])\n",
        "\n",
        "    best_valid_loss = float('inf')\n",
        "    no_improve_epoch = 0\n",
        "\n",
        "    for epoch in range(nb_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{nb_epochs}')\n",
        "        print('-------------------------------')\n",
        "        print(\"Epoch: %d, Learning Rate: %f \" % (epoch, optimizer.param_groups[0]['lr']))\n",
        "        train_loss, train_accuracy = train(train_dataloader,model,loss_fn,optimizer)\n",
        "        valid_loss, valid_accuracy = validate(valid_dataloader,model,loss_fn)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "        print(f'Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "        # Check if the validation loss improved\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            no_improve_epoch = 0\n",
        "\n",
        "            # Change 5: Save the model when validation loss improves\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "            no_improve_epoch += 1\n",
        "\n",
        "        # If the validation loss did not improve for 'patience' epochs, stop training\n",
        "        if no_improve_epoch >= patience:\n",
        "            print(f'Early stopping at epoch {epoch+1}, the validation loss did not improve for the last {patience} epochs')\n",
        "            break\n",
        "\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        scheduler.step()\n",
        "        df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n",
        "\n",
        "\n",
        "    print('\\nTraining has completed!')\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv('training_validation_metrics.csv', index=False)\n",
        "\n",
        "    return train_losses,valid_losses"
      ],
      "metadata": {
        "id": "U661TQ5wqYGU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn   = nn.CrossEntropyLoss(weight=class_weights) #CrossEntropyLoss with class_weights.\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.005)\n",
        "nb_epochs = 30\n",
        "patience = 4\n",
        "#Call the optimize function.\n",
        "train_losses, valid_losses = optimize(train_dataloader,valid_dataloader,model,loss_fn,optimizer,nb_epochs, patience)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guN3gCYfqFdp",
        "outputId": "5bb5b346-b4fc-4752-ef73-be00b0dba01b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n",
            "-------------------------------\n",
            "Epoch: 0, Learning Rate: 0.005000 \n",
            "Batch 0/317 processed, running loss: 1.653175, correct predictions: 2, total: 16\n",
            "Batch 10/317 processed, running loss: 17.536213, correct predictions: 24, total: 176\n",
            "Batch 20/317 processed, running loss: 33.087919, correct predictions: 47, total: 336\n",
            "Batch 30/317 processed, running loss: 47.898250, correct predictions: 77, total: 496\n",
            "Batch 40/317 processed, running loss: 63.777148, correct predictions: 126, total: 656\n",
            "Batch 50/317 processed, running loss: 80.358757, correct predictions: 198, total: 816\n",
            "Batch 60/317 processed, running loss: 96.518895, correct predictions: 281, total: 976\n",
            "Batch 70/317 processed, running loss: 112.812725, correct predictions: 332, total: 1136\n",
            "Batch 80/317 processed, running loss: 128.457486, correct predictions: 371, total: 1296\n",
            "Batch 90/317 processed, running loss: 144.098414, correct predictions: 434, total: 1456\n",
            "Batch 100/317 processed, running loss: 158.499483, correct predictions: 540, total: 1616\n",
            "Batch 110/317 processed, running loss: 173.680197, correct predictions: 638, total: 1776\n",
            "Batch 120/317 processed, running loss: 189.050929, correct predictions: 753, total: 1936\n",
            "Batch 130/317 processed, running loss: 205.668584, correct predictions: 841, total: 2096\n",
            "Batch 140/317 processed, running loss: 221.349940, correct predictions: 929, total: 2256\n",
            "Batch 150/317 processed, running loss: 237.261953, correct predictions: 1040, total: 2416\n",
            "Batch 160/317 processed, running loss: 253.060238, correct predictions: 1152, total: 2576\n",
            "Batch 170/317 processed, running loss: 268.674048, correct predictions: 1259, total: 2736\n",
            "Batch 180/317 processed, running loss: 284.003473, correct predictions: 1382, total: 2896\n",
            "Batch 190/317 processed, running loss: 299.266395, correct predictions: 1501, total: 3056\n",
            "Batch 200/317 processed, running loss: 315.269948, correct predictions: 1601, total: 3216\n",
            "Batch 210/317 processed, running loss: 330.761395, correct predictions: 1698, total: 3376\n",
            "Batch 220/317 processed, running loss: 345.825957, correct predictions: 1770, total: 3536\n",
            "Batch 230/317 processed, running loss: 361.157021, correct predictions: 1889, total: 3696\n",
            "Batch 240/317 processed, running loss: 377.169040, correct predictions: 1984, total: 3856\n",
            "Batch 250/317 processed, running loss: 392.202354, correct predictions: 2083, total: 4016\n",
            "Batch 260/317 processed, running loss: 407.844500, correct predictions: 2171, total: 4176\n",
            "Batch 270/317 processed, running loss: 422.710418, correct predictions: 2267, total: 4336\n",
            "Batch 280/317 processed, running loss: 437.541036, correct predictions: 2375, total: 4496\n",
            "Batch 290/317 processed, running loss: 452.401738, correct predictions: 2477, total: 4656\n",
            "Batch 300/317 processed, running loss: 467.253973, correct predictions: 2556, total: 4816\n",
            "Batch 310/317 processed, running loss: 481.950934, correct predictions: 2653, total: 4976\n",
            "\n",
            "Training Loss per batch = 1.548305\tAccuracy on Training set = 53.200316% [2693/5062]\n",
            "\n",
            "Validation Loss per batch = 1.435995\tAccuracy on Validation set = 57.015986% [321/563]\n",
            "Train Loss: 1.5483, Train Accuracy: 53.2003\n",
            "Valid Loss: 1.4360, Valid Accuracy: 57.0160\n",
            "\n",
            "Epoch 2/30\n",
            "-------------------------------\n",
            "Epoch: 1, Learning Rate: 0.005000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 1.458285, correct predictions: 7, total: 16\n",
            "Batch 10/317 processed, running loss: 15.870673, correct predictions: 99, total: 176\n",
            "Batch 20/317 processed, running loss: 29.371705, correct predictions: 185, total: 336\n",
            "Batch 30/317 processed, running loss: 42.695684, correct predictions: 288, total: 496\n",
            "Batch 40/317 processed, running loss: 57.633296, correct predictions: 404, total: 656\n",
            "Batch 50/317 processed, running loss: 72.367687, correct predictions: 505, total: 816\n",
            "Batch 60/317 processed, running loss: 86.800993, correct predictions: 606, total: 976\n",
            "Batch 70/317 processed, running loss: 100.531054, correct predictions: 713, total: 1136\n",
            "Batch 80/317 processed, running loss: 114.537930, correct predictions: 815, total: 1296\n",
            "Batch 90/317 processed, running loss: 127.939929, correct predictions: 924, total: 1456\n",
            "Batch 100/317 processed, running loss: 142.414940, correct predictions: 1017, total: 1616\n",
            "Batch 110/317 processed, running loss: 156.165756, correct predictions: 1117, total: 1776\n",
            "Batch 120/317 processed, running loss: 169.188742, correct predictions: 1228, total: 1936\n",
            "Batch 130/317 processed, running loss: 183.565548, correct predictions: 1332, total: 2096\n",
            "Batch 140/317 processed, running loss: 197.072480, correct predictions: 1422, total: 2256\n",
            "Batch 150/317 processed, running loss: 210.300147, correct predictions: 1497, total: 2416\n",
            "Batch 160/317 processed, running loss: 224.113951, correct predictions: 1578, total: 2576\n",
            "Batch 170/317 processed, running loss: 237.684252, correct predictions: 1683, total: 2736\n",
            "Batch 180/317 processed, running loss: 251.704904, correct predictions: 1784, total: 2896\n",
            "Batch 190/317 processed, running loss: 263.700001, correct predictions: 1903, total: 3056\n",
            "Batch 200/317 processed, running loss: 277.145437, correct predictions: 2007, total: 3216\n",
            "Batch 210/317 processed, running loss: 290.592041, correct predictions: 2096, total: 3376\n",
            "Batch 220/317 processed, running loss: 304.115005, correct predictions: 2179, total: 3536\n",
            "Batch 230/317 processed, running loss: 316.534652, correct predictions: 2280, total: 3696\n",
            "Batch 240/317 processed, running loss: 329.949244, correct predictions: 2375, total: 3856\n",
            "Batch 250/317 processed, running loss: 342.826306, correct predictions: 2477, total: 4016\n",
            "Batch 260/317 processed, running loss: 354.964238, correct predictions: 2581, total: 4176\n",
            "Batch 270/317 processed, running loss: 367.523425, correct predictions: 2693, total: 4336\n",
            "Batch 280/317 processed, running loss: 380.853008, correct predictions: 2792, total: 4496\n",
            "Batch 290/317 processed, running loss: 393.236343, correct predictions: 2890, total: 4656\n",
            "Batch 300/317 processed, running loss: 406.429407, correct predictions: 2984, total: 4816\n",
            "Batch 310/317 processed, running loss: 419.845990, correct predictions: 3056, total: 4976\n",
            "\n",
            "Training Loss per batch = 1.345331\tAccuracy on Training set = 61.161596% [3096/5062]\n",
            "\n",
            "Validation Loss per batch = 1.232114\tAccuracy on Validation set = 35.168739% [198/563]\n",
            "Train Loss: 1.3453, Train Accuracy: 61.1616\n",
            "Valid Loss: 1.2321, Valid Accuracy: 35.1687\n",
            "\n",
            "Epoch 3/30\n",
            "-------------------------------\n",
            "Epoch: 2, Learning Rate: 0.005000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 1.138419, correct predictions: 6, total: 16\n",
            "Batch 10/317 processed, running loss: 11.701462, correct predictions: 95, total: 176\n",
            "Batch 20/317 processed, running loss: 22.968112, correct predictions: 198, total: 336\n",
            "Batch 30/317 processed, running loss: 33.392782, correct predictions: 292, total: 496\n",
            "Batch 40/317 processed, running loss: 43.854609, correct predictions: 397, total: 656\n",
            "Batch 50/317 processed, running loss: 56.334195, correct predictions: 516, total: 816\n",
            "Batch 60/317 processed, running loss: 69.501661, correct predictions: 622, total: 976\n",
            "Batch 70/317 processed, running loss: 81.844351, correct predictions: 722, total: 1136\n",
            "Batch 80/317 processed, running loss: 95.266005, correct predictions: 795, total: 1296\n",
            "Batch 90/317 processed, running loss: 105.819633, correct predictions: 889, total: 1456\n",
            "Batch 100/317 processed, running loss: 117.654137, correct predictions: 977, total: 1616\n",
            "Batch 110/317 processed, running loss: 127.768571, correct predictions: 1068, total: 1776\n",
            "Batch 120/317 processed, running loss: 140.093246, correct predictions: 1160, total: 1936\n",
            "Batch 130/317 processed, running loss: 152.214658, correct predictions: 1241, total: 2096\n",
            "Batch 140/317 processed, running loss: 163.843931, correct predictions: 1324, total: 2256\n",
            "Batch 150/317 processed, running loss: 175.228774, correct predictions: 1411, total: 2416\n",
            "Batch 160/317 processed, running loss: 186.826829, correct predictions: 1530, total: 2576\n",
            "Batch 170/317 processed, running loss: 197.798181, correct predictions: 1637, total: 2736\n",
            "Batch 180/317 processed, running loss: 209.093360, correct predictions: 1723, total: 2896\n",
            "Batch 190/317 processed, running loss: 222.524986, correct predictions: 1816, total: 3056\n",
            "Batch 200/317 processed, running loss: 235.030423, correct predictions: 1908, total: 3216\n",
            "Batch 210/317 processed, running loss: 248.846477, correct predictions: 2005, total: 3376\n",
            "Batch 220/317 processed, running loss: 262.064474, correct predictions: 2104, total: 3536\n",
            "Batch 230/317 processed, running loss: 274.615000, correct predictions: 2200, total: 3696\n",
            "Batch 240/317 processed, running loss: 286.515936, correct predictions: 2307, total: 3856\n",
            "Batch 250/317 processed, running loss: 297.421655, correct predictions: 2414, total: 4016\n",
            "Batch 260/317 processed, running loss: 309.511871, correct predictions: 2517, total: 4176\n",
            "Batch 270/317 processed, running loss: 321.377706, correct predictions: 2621, total: 4336\n",
            "Batch 280/317 processed, running loss: 332.999538, correct predictions: 2690, total: 4496\n",
            "Batch 290/317 processed, running loss: 344.315880, correct predictions: 2747, total: 4656\n",
            "Batch 300/317 processed, running loss: 356.574297, correct predictions: 2836, total: 4816\n",
            "Batch 310/317 processed, running loss: 367.553128, correct predictions: 2923, total: 4976\n",
            "\n",
            "Training Loss per batch = 1.180526\tAccuracy on Training set = 58.494666% [2961/5062]\n",
            "\n",
            "Validation Loss per batch = 1.129483\tAccuracy on Validation set = 70.515098% [397/563]\n",
            "Train Loss: 1.1805, Train Accuracy: 58.4947\n",
            "Valid Loss: 1.1295, Valid Accuracy: 70.5151\n",
            "\n",
            "Epoch 4/30\n",
            "-------------------------------\n",
            "Epoch: 3, Learning Rate: 0.005000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 1.159321, correct predictions: 12, total: 16\n",
            "Batch 10/317 processed, running loss: 11.240977, correct predictions: 116, total: 176\n",
            "Batch 20/317 processed, running loss: 22.730172, correct predictions: 201, total: 336\n",
            "Batch 30/317 processed, running loss: 33.779232, correct predictions: 296, total: 496\n",
            "Batch 40/317 processed, running loss: 43.397757, correct predictions: 401, total: 656\n",
            "Batch 50/317 processed, running loss: 57.062772, correct predictions: 488, total: 816\n",
            "Batch 60/317 processed, running loss: 66.683639, correct predictions: 608, total: 976\n",
            "Batch 70/317 processed, running loss: 77.153212, correct predictions: 715, total: 1136\n",
            "Batch 80/317 processed, running loss: 89.902571, correct predictions: 805, total: 1296\n",
            "Batch 90/317 processed, running loss: 102.062816, correct predictions: 902, total: 1456\n",
            "Batch 100/317 processed, running loss: 114.068760, correct predictions: 979, total: 1616\n",
            "Batch 110/317 processed, running loss: 124.275646, correct predictions: 1044, total: 1776\n",
            "Batch 120/317 processed, running loss: 135.729151, correct predictions: 1115, total: 1936\n",
            "Batch 130/317 processed, running loss: 145.782440, correct predictions: 1233, total: 2096\n",
            "Batch 140/317 processed, running loss: 156.762928, correct predictions: 1343, total: 2256\n",
            "Batch 150/317 processed, running loss: 166.430342, correct predictions: 1459, total: 2416\n",
            "Batch 160/317 processed, running loss: 178.161723, correct predictions: 1556, total: 2576\n",
            "Batch 170/317 processed, running loss: 188.842341, correct predictions: 1652, total: 2736\n",
            "Batch 180/317 processed, running loss: 199.153521, correct predictions: 1753, total: 2896\n",
            "Batch 190/317 processed, running loss: 211.668096, correct predictions: 1832, total: 3056\n",
            "Batch 200/317 processed, running loss: 221.368477, correct predictions: 1938, total: 3216\n",
            "Batch 210/317 processed, running loss: 232.160365, correct predictions: 2023, total: 3376\n",
            "Batch 220/317 processed, running loss: 242.927497, correct predictions: 2130, total: 3536\n",
            "Batch 230/317 processed, running loss: 252.330232, correct predictions: 2246, total: 3696\n",
            "Batch 240/317 processed, running loss: 263.162148, correct predictions: 2347, total: 3856\n",
            "Batch 250/317 processed, running loss: 275.269052, correct predictions: 2433, total: 4016\n",
            "Batch 260/317 processed, running loss: 285.017478, correct predictions: 2525, total: 4176\n",
            "Batch 270/317 processed, running loss: 295.160246, correct predictions: 2629, total: 4336\n",
            "Batch 280/317 processed, running loss: 307.205678, correct predictions: 2702, total: 4496\n",
            "Batch 290/317 processed, running loss: 317.193192, correct predictions: 2779, total: 4656\n",
            "Batch 300/317 processed, running loss: 327.618113, correct predictions: 2875, total: 4816\n",
            "Batch 310/317 processed, running loss: 337.736360, correct predictions: 2986, total: 4976\n",
            "\n",
            "Training Loss per batch = 1.082642\tAccuracy on Training set = 60.331885% [3054/5062]\n",
            "\n",
            "Validation Loss per batch = 1.097649\tAccuracy on Validation set = 77.442274% [436/563]\n",
            "Train Loss: 1.0826, Train Accuracy: 60.3319\n",
            "Valid Loss: 1.0976, Valid Accuracy: 77.4423\n",
            "\n",
            "Epoch 5/30\n",
            "-------------------------------\n",
            "Epoch: 4, Learning Rate: 0.002500 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 1.096126, correct predictions: 11, total: 16\n",
            "Batch 10/317 processed, running loss: 10.731792, correct predictions: 129, total: 176\n",
            "Batch 20/317 processed, running loss: 20.067113, correct predictions: 253, total: 336\n",
            "Batch 30/317 processed, running loss: 29.861064, correct predictions: 358, total: 496\n",
            "Batch 40/317 processed, running loss: 39.048565, correct predictions: 479, total: 656\n",
            "Batch 50/317 processed, running loss: 49.424489, correct predictions: 597, total: 816\n",
            "Batch 60/317 processed, running loss: 58.012194, correct predictions: 714, total: 976\n",
            "Batch 70/317 processed, running loss: 67.986476, correct predictions: 813, total: 1136\n",
            "Batch 80/317 processed, running loss: 77.256315, correct predictions: 896, total: 1296\n",
            "Batch 90/317 processed, running loss: 87.016682, correct predictions: 971, total: 1456\n",
            "Batch 100/317 processed, running loss: 96.730724, correct predictions: 1067, total: 1616\n",
            "Batch 110/317 processed, running loss: 106.802006, correct predictions: 1164, total: 1776\n",
            "Batch 120/317 processed, running loss: 117.677155, correct predictions: 1267, total: 1936\n",
            "Batch 130/317 processed, running loss: 126.154708, correct predictions: 1384, total: 2096\n",
            "Batch 140/317 processed, running loss: 136.052236, correct predictions: 1494, total: 2256\n",
            "Batch 150/317 processed, running loss: 145.063995, correct predictions: 1588, total: 2416\n",
            "Batch 160/317 processed, running loss: 155.739024, correct predictions: 1683, total: 2576\n",
            "Batch 170/317 processed, running loss: 165.944426, correct predictions: 1790, total: 2736\n",
            "Batch 180/317 processed, running loss: 175.813922, correct predictions: 1896, total: 2896\n",
            "Batch 190/317 processed, running loss: 185.924658, correct predictions: 2005, total: 3056\n",
            "Batch 200/317 processed, running loss: 194.953883, correct predictions: 2101, total: 3216\n",
            "Batch 210/317 processed, running loss: 204.866924, correct predictions: 2193, total: 3376\n",
            "Batch 220/317 processed, running loss: 214.033484, correct predictions: 2314, total: 3536\n",
            "Batch 230/317 processed, running loss: 223.747891, correct predictions: 2440, total: 3696\n",
            "Batch 240/317 processed, running loss: 233.732633, correct predictions: 2553, total: 3856\n",
            "Batch 250/317 processed, running loss: 243.796436, correct predictions: 2673, total: 4016\n",
            "Batch 260/317 processed, running loss: 253.817703, correct predictions: 2779, total: 4176\n",
            "Batch 270/317 processed, running loss: 263.401991, correct predictions: 2889, total: 4336\n",
            "Batch 280/317 processed, running loss: 273.500490, correct predictions: 2991, total: 4496\n",
            "Batch 290/317 processed, running loss: 281.601827, correct predictions: 3094, total: 4656\n",
            "Batch 300/317 processed, running loss: 290.893453, correct predictions: 3202, total: 4816\n",
            "Batch 310/317 processed, running loss: 301.053360, correct predictions: 3298, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.969896\tAccuracy on Training set = 66.120111% [3347/5062]\n",
            "\n",
            "Validation Loss per batch = 1.024099\tAccuracy on Validation set = 63.055062% [355/563]\n",
            "Train Loss: 0.9699, Train Accuracy: 66.1201\n",
            "Valid Loss: 1.0241, Valid Accuracy: 63.0551\n",
            "\n",
            "Epoch 6/30\n",
            "-------------------------------\n",
            "Epoch: 5, Learning Rate: 0.002500 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.668259, correct predictions: 10, total: 16\n",
            "Batch 10/317 processed, running loss: 10.257778, correct predictions: 104, total: 176\n",
            "Batch 20/317 processed, running loss: 22.073224, correct predictions: 206, total: 336\n",
            "Batch 30/317 processed, running loss: 30.578822, correct predictions: 302, total: 496\n",
            "Batch 40/317 processed, running loss: 38.784549, correct predictions: 418, total: 656\n",
            "Batch 50/317 processed, running loss: 48.250091, correct predictions: 538, total: 816\n",
            "Batch 60/317 processed, running loss: 57.327318, correct predictions: 640, total: 976\n",
            "Batch 70/317 processed, running loss: 65.675317, correct predictions: 731, total: 1136\n",
            "Batch 80/317 processed, running loss: 73.625316, correct predictions: 844, total: 1296\n",
            "Batch 90/317 processed, running loss: 81.939067, correct predictions: 951, total: 1456\n",
            "Batch 100/317 processed, running loss: 90.163284, correct predictions: 1059, total: 1616\n",
            "Batch 110/317 processed, running loss: 98.168192, correct predictions: 1179, total: 1776\n",
            "Batch 120/317 processed, running loss: 107.599851, correct predictions: 1298, total: 1936\n",
            "Batch 130/317 processed, running loss: 116.022920, correct predictions: 1421, total: 2096\n",
            "Batch 140/317 processed, running loss: 124.812327, correct predictions: 1531, total: 2256\n",
            "Batch 150/317 processed, running loss: 133.125135, correct predictions: 1641, total: 2416\n",
            "Batch 160/317 processed, running loss: 141.053409, correct predictions: 1748, total: 2576\n",
            "Batch 170/317 processed, running loss: 149.440723, correct predictions: 1852, total: 2736\n",
            "Batch 180/317 processed, running loss: 157.815407, correct predictions: 1961, total: 2896\n",
            "Batch 190/317 processed, running loss: 167.105267, correct predictions: 2058, total: 3056\n",
            "Batch 200/317 processed, running loss: 176.998925, correct predictions: 2172, total: 3216\n",
            "Batch 210/317 processed, running loss: 185.383770, correct predictions: 2290, total: 3376\n",
            "Batch 220/317 processed, running loss: 192.979476, correct predictions: 2409, total: 3536\n",
            "Batch 230/317 processed, running loss: 202.860326, correct predictions: 2514, total: 3696\n",
            "Batch 240/317 processed, running loss: 212.142510, correct predictions: 2630, total: 3856\n",
            "Batch 250/317 processed, running loss: 221.794786, correct predictions: 2735, total: 4016\n",
            "Batch 260/317 processed, running loss: 230.913027, correct predictions: 2853, total: 4176\n",
            "Batch 270/317 processed, running loss: 238.514310, correct predictions: 2962, total: 4336\n",
            "Batch 280/317 processed, running loss: 245.870502, correct predictions: 3053, total: 4496\n",
            "Batch 290/317 processed, running loss: 254.444054, correct predictions: 3163, total: 4656\n",
            "Batch 300/317 processed, running loss: 262.395536, correct predictions: 3277, total: 4816\n",
            "Batch 310/317 processed, running loss: 270.334560, correct predictions: 3397, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.880731\tAccuracy on Training set = 68.056104% [3445/5062]\n",
            "\n",
            "Validation Loss per batch = 1.077855\tAccuracy on Validation set = 68.561279% [386/563]\n",
            "Train Loss: 0.8807, Train Accuracy: 68.0561\n",
            "Valid Loss: 1.0779, Valid Accuracy: 68.5613\n",
            "\n",
            "Epoch 7/30\n",
            "-------------------------------\n",
            "Epoch: 6, Learning Rate: 0.002500 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.884307, correct predictions: 10, total: 16\n",
            "Batch 10/317 processed, running loss: 8.095816, correct predictions: 111, total: 176\n",
            "Batch 20/317 processed, running loss: 16.170110, correct predictions: 211, total: 336\n",
            "Batch 30/317 processed, running loss: 24.316319, correct predictions: 319, total: 496\n",
            "Batch 40/317 processed, running loss: 32.516294, correct predictions: 419, total: 656\n",
            "Batch 50/317 processed, running loss: 40.325055, correct predictions: 536, total: 816\n",
            "Batch 60/317 processed, running loss: 47.249057, correct predictions: 644, total: 976\n",
            "Batch 70/317 processed, running loss: 55.488066, correct predictions: 760, total: 1136\n",
            "Batch 80/317 processed, running loss: 65.127317, correct predictions: 874, total: 1296\n",
            "Batch 90/317 processed, running loss: 74.928987, correct predictions: 982, total: 1456\n",
            "Batch 100/317 processed, running loss: 82.292369, correct predictions: 1089, total: 1616\n",
            "Batch 110/317 processed, running loss: 89.826161, correct predictions: 1208, total: 1776\n",
            "Batch 120/317 processed, running loss: 97.247949, correct predictions: 1327, total: 1936\n",
            "Batch 130/317 processed, running loss: 104.480259, correct predictions: 1432, total: 2096\n",
            "Batch 140/317 processed, running loss: 112.815644, correct predictions: 1532, total: 2256\n",
            "Batch 150/317 processed, running loss: 120.949460, correct predictions: 1649, total: 2416\n",
            "Batch 160/317 processed, running loss: 128.086582, correct predictions: 1776, total: 2576\n",
            "Batch 170/317 processed, running loss: 137.031875, correct predictions: 1888, total: 2736\n",
            "Batch 180/317 processed, running loss: 144.831628, correct predictions: 1996, total: 2896\n",
            "Batch 190/317 processed, running loss: 153.602900, correct predictions: 2119, total: 3056\n",
            "Batch 200/317 processed, running loss: 162.330338, correct predictions: 2220, total: 3216\n",
            "Batch 210/317 processed, running loss: 170.274950, correct predictions: 2311, total: 3376\n",
            "Batch 220/317 processed, running loss: 180.763022, correct predictions: 2414, total: 3536\n",
            "Batch 230/317 processed, running loss: 188.610139, correct predictions: 2523, total: 3696\n",
            "Batch 240/317 processed, running loss: 196.704963, correct predictions: 2627, total: 3856\n",
            "Batch 250/317 processed, running loss: 205.028638, correct predictions: 2729, total: 4016\n",
            "Batch 260/317 processed, running loss: 213.433256, correct predictions: 2839, total: 4176\n",
            "Batch 270/317 processed, running loss: 220.596107, correct predictions: 2950, total: 4336\n",
            "Batch 280/317 processed, running loss: 228.190291, correct predictions: 3067, total: 4496\n",
            "Batch 290/317 processed, running loss: 237.294351, correct predictions: 3183, total: 4656\n",
            "Batch 300/317 processed, running loss: 245.379708, correct predictions: 3311, total: 4816\n",
            "Batch 310/317 processed, running loss: 254.641002, correct predictions: 3436, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.819335\tAccuracy on Training set = 69.103121% [3498/5062]\n",
            "\n",
            "Validation Loss per batch = 1.040635\tAccuracy on Validation set = 76.376554% [430/563]\n",
            "Train Loss: 0.8193, Train Accuracy: 69.1031\n",
            "Valid Loss: 1.0406, Valid Accuracy: 76.3766\n",
            "\n",
            "Epoch 8/30\n",
            "-------------------------------\n",
            "Epoch: 7, Learning Rate: 0.002500 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.366864, correct predictions: 16, total: 16\n",
            "Batch 10/317 processed, running loss: 7.982557, correct predictions: 129, total: 176\n",
            "Batch 20/317 processed, running loss: 15.855473, correct predictions: 244, total: 336\n",
            "Batch 30/317 processed, running loss: 21.886430, correct predictions: 354, total: 496\n",
            "Batch 40/317 processed, running loss: 30.548176, correct predictions: 465, total: 656\n",
            "Batch 50/317 processed, running loss: 38.292686, correct predictions: 576, total: 816\n",
            "Batch 60/317 processed, running loss: 45.569128, correct predictions: 686, total: 976\n",
            "Batch 70/317 processed, running loss: 52.801581, correct predictions: 791, total: 1136\n",
            "Batch 80/317 processed, running loss: 60.706468, correct predictions: 888, total: 1296\n",
            "Batch 90/317 processed, running loss: 67.804854, correct predictions: 991, total: 1456\n",
            "Batch 100/317 processed, running loss: 75.140391, correct predictions: 1115, total: 1616\n",
            "Batch 110/317 processed, running loss: 81.994740, correct predictions: 1241, total: 1776\n",
            "Batch 120/317 processed, running loss: 90.603091, correct predictions: 1360, total: 1936\n",
            "Batch 130/317 processed, running loss: 97.387587, correct predictions: 1488, total: 2096\n",
            "Batch 140/317 processed, running loss: 103.288962, correct predictions: 1619, total: 2256\n",
            "Batch 150/317 processed, running loss: 110.322073, correct predictions: 1730, total: 2416\n",
            "Batch 160/317 processed, running loss: 118.309779, correct predictions: 1834, total: 2576\n",
            "Batch 170/317 processed, running loss: 124.627525, correct predictions: 1955, total: 2736\n",
            "Batch 180/317 processed, running loss: 130.987470, correct predictions: 2060, total: 2896\n",
            "Batch 190/317 processed, running loss: 138.101469, correct predictions: 2167, total: 3056\n",
            "Batch 200/317 processed, running loss: 145.255268, correct predictions: 2284, total: 3216\n",
            "Batch 210/317 processed, running loss: 152.144681, correct predictions: 2400, total: 3376\n",
            "Batch 220/317 processed, running loss: 160.032285, correct predictions: 2505, total: 3536\n",
            "Batch 230/317 processed, running loss: 167.979773, correct predictions: 2603, total: 3696\n",
            "Batch 240/317 processed, running loss: 175.461438, correct predictions: 2700, total: 3856\n",
            "Batch 250/317 processed, running loss: 183.187569, correct predictions: 2813, total: 4016\n",
            "Batch 260/317 processed, running loss: 191.067867, correct predictions: 2916, total: 4176\n",
            "Batch 270/317 processed, running loss: 199.114518, correct predictions: 3011, total: 4336\n",
            "Batch 280/317 processed, running loss: 207.913636, correct predictions: 3105, total: 4496\n",
            "Batch 290/317 processed, running loss: 214.517162, correct predictions: 3218, total: 4656\n",
            "Batch 300/317 processed, running loss: 221.890777, correct predictions: 3332, total: 4816\n",
            "Batch 310/317 processed, running loss: 228.718337, correct predictions: 3444, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.739680\tAccuracy on Training set = 69.182141% [3502/5062]\n",
            "\n",
            "Validation Loss per batch = 1.066678\tAccuracy on Validation set = 73.712256% [415/563]\n",
            "Train Loss: 0.7397, Train Accuracy: 69.1821\n",
            "Valid Loss: 1.0667, Valid Accuracy: 73.7123\n",
            "\n",
            "Epoch 9/30\n",
            "-------------------------------\n",
            "Epoch: 8, Learning Rate: 0.001250 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.440523, correct predictions: 12, total: 16\n",
            "Batch 10/317 processed, running loss: 8.378478, correct predictions: 132, total: 176\n",
            "Batch 20/317 processed, running loss: 16.635940, correct predictions: 251, total: 336\n",
            "Batch 30/317 processed, running loss: 24.472936, correct predictions: 369, total: 496\n",
            "Batch 40/317 processed, running loss: 30.130442, correct predictions: 492, total: 656\n",
            "Batch 50/317 processed, running loss: 36.739494, correct predictions: 610, total: 816\n",
            "Batch 60/317 processed, running loss: 44.227235, correct predictions: 739, total: 976\n",
            "Batch 70/317 processed, running loss: 50.119220, correct predictions: 865, total: 1136\n",
            "Batch 80/317 processed, running loss: 57.228194, correct predictions: 981, total: 1296\n",
            "Batch 90/317 processed, running loss: 63.973342, correct predictions: 1108, total: 1456\n",
            "Batch 100/317 processed, running loss: 71.574470, correct predictions: 1221, total: 1616\n",
            "Batch 110/317 processed, running loss: 77.921774, correct predictions: 1336, total: 1776\n",
            "Batch 120/317 processed, running loss: 86.507065, correct predictions: 1431, total: 1936\n",
            "Batch 130/317 processed, running loss: 92.707129, correct predictions: 1537, total: 2096\n",
            "Batch 140/317 processed, running loss: 99.526274, correct predictions: 1653, total: 2256\n",
            "Batch 150/317 processed, running loss: 105.856649, correct predictions: 1771, total: 2416\n",
            "Batch 160/317 processed, running loss: 111.920015, correct predictions: 1885, total: 2576\n",
            "Batch 170/317 processed, running loss: 118.786572, correct predictions: 1985, total: 2736\n",
            "Batch 180/317 processed, running loss: 125.040160, correct predictions: 2094, total: 2896\n",
            "Batch 190/317 processed, running loss: 130.962782, correct predictions: 2204, total: 3056\n",
            "Batch 200/317 processed, running loss: 136.290631, correct predictions: 2324, total: 3216\n",
            "Batch 210/317 processed, running loss: 142.068634, correct predictions: 2429, total: 3376\n",
            "Batch 220/317 processed, running loss: 148.011338, correct predictions: 2542, total: 3536\n",
            "Batch 230/317 processed, running loss: 154.261004, correct predictions: 2655, total: 3696\n",
            "Batch 240/317 processed, running loss: 161.088547, correct predictions: 2782, total: 3856\n",
            "Batch 250/317 processed, running loss: 165.549302, correct predictions: 2906, total: 4016\n",
            "Batch 260/317 processed, running loss: 171.909391, correct predictions: 3018, total: 4176\n",
            "Batch 270/317 processed, running loss: 177.392558, correct predictions: 3138, total: 4336\n",
            "Batch 280/317 processed, running loss: 183.948577, correct predictions: 3263, total: 4496\n",
            "Batch 290/317 processed, running loss: 190.344056, correct predictions: 3380, total: 4656\n",
            "Batch 300/317 processed, running loss: 195.874064, correct predictions: 3494, total: 4816\n",
            "Batch 310/317 processed, running loss: 202.167068, correct predictions: 3613, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.651753\tAccuracy on Training set = 72.678783% [3679/5062]\n",
            "\n",
            "Validation Loss per batch = 1.008136\tAccuracy on Validation set = 74.067496% [417/563]\n",
            "Train Loss: 0.6518, Train Accuracy: 72.6788\n",
            "Valid Loss: 1.0081, Valid Accuracy: 74.0675\n",
            "\n",
            "Epoch 10/30\n",
            "-------------------------------\n",
            "Epoch: 9, Learning Rate: 0.001250 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.281973, correct predictions: 15, total: 16\n",
            "Batch 10/317 processed, running loss: 5.987103, correct predictions: 146, total: 176\n",
            "Batch 20/317 processed, running loss: 12.503281, correct predictions: 275, total: 336\n",
            "Batch 30/317 processed, running loss: 19.228552, correct predictions: 391, total: 496\n",
            "Batch 40/317 processed, running loss: 24.833413, correct predictions: 514, total: 656\n",
            "Batch 50/317 processed, running loss: 30.838783, correct predictions: 635, total: 816\n",
            "Batch 60/317 processed, running loss: 37.015245, correct predictions: 751, total: 976\n",
            "Batch 70/317 processed, running loss: 42.672630, correct predictions: 876, total: 1136\n",
            "Batch 80/317 processed, running loss: 48.295395, correct predictions: 1001, total: 1296\n",
            "Batch 90/317 processed, running loss: 55.711838, correct predictions: 1120, total: 1456\n",
            "Batch 100/317 processed, running loss: 61.594987, correct predictions: 1249, total: 1616\n",
            "Batch 110/317 processed, running loss: 67.815647, correct predictions: 1369, total: 1776\n",
            "Batch 120/317 processed, running loss: 73.309784, correct predictions: 1491, total: 1936\n",
            "Batch 130/317 processed, running loss: 79.089173, correct predictions: 1606, total: 2096\n",
            "Batch 140/317 processed, running loss: 85.006737, correct predictions: 1721, total: 2256\n",
            "Batch 150/317 processed, running loss: 91.560706, correct predictions: 1846, total: 2416\n",
            "Batch 160/317 processed, running loss: 98.211659, correct predictions: 1965, total: 2576\n",
            "Batch 170/317 processed, running loss: 104.596933, correct predictions: 2085, total: 2736\n",
            "Batch 180/317 processed, running loss: 110.100174, correct predictions: 2211, total: 2896\n",
            "Batch 190/317 processed, running loss: 116.339356, correct predictions: 2328, total: 3056\n",
            "Batch 200/317 processed, running loss: 121.420509, correct predictions: 2455, total: 3216\n",
            "Batch 210/317 processed, running loss: 126.789860, correct predictions: 2559, total: 3376\n",
            "Batch 220/317 processed, running loss: 132.721664, correct predictions: 2681, total: 3536\n",
            "Batch 230/317 processed, running loss: 137.938739, correct predictions: 2805, total: 3696\n",
            "Batch 240/317 processed, running loss: 144.092017, correct predictions: 2926, total: 3856\n",
            "Batch 250/317 processed, running loss: 150.107149, correct predictions: 3046, total: 4016\n",
            "Batch 260/317 processed, running loss: 157.922089, correct predictions: 3166, total: 4176\n",
            "Batch 270/317 processed, running loss: 163.942891, correct predictions: 3281, total: 4336\n",
            "Batch 280/317 processed, running loss: 168.442456, correct predictions: 3398, total: 4496\n",
            "Batch 290/317 processed, running loss: 174.150234, correct predictions: 3523, total: 4656\n",
            "Batch 300/317 processed, running loss: 180.398302, correct predictions: 3644, total: 4816\n",
            "Batch 310/317 processed, running loss: 186.548128, correct predictions: 3765, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.597327\tAccuracy on Training set = 75.800079% [3837/5062]\n",
            "\n",
            "Validation Loss per batch = 0.994171\tAccuracy on Validation set = 65.896980% [371/563]\n",
            "Train Loss: 0.5973, Train Accuracy: 75.8001\n",
            "Valid Loss: 0.9942, Valid Accuracy: 65.8970\n",
            "\n",
            "Epoch 11/30\n",
            "-------------------------------\n",
            "Epoch: 10, Learning Rate: 0.001250 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.326890, correct predictions: 14, total: 16\n",
            "Batch 10/317 processed, running loss: 5.071904, correct predictions: 136, total: 176\n",
            "Batch 20/317 processed, running loss: 10.685696, correct predictions: 262, total: 336\n",
            "Batch 30/317 processed, running loss: 16.795265, correct predictions: 378, total: 496\n",
            "Batch 40/317 processed, running loss: 22.020424, correct predictions: 491, total: 656\n",
            "Batch 50/317 processed, running loss: 26.429488, correct predictions: 614, total: 816\n",
            "Batch 60/317 processed, running loss: 32.772179, correct predictions: 732, total: 976\n",
            "Batch 70/317 processed, running loss: 42.152377, correct predictions: 845, total: 1136\n",
            "Batch 80/317 processed, running loss: 48.754052, correct predictions: 954, total: 1296\n",
            "Batch 90/317 processed, running loss: 54.949025, correct predictions: 1074, total: 1456\n",
            "Batch 100/317 processed, running loss: 61.687034, correct predictions: 1205, total: 1616\n",
            "Batch 110/317 processed, running loss: 67.333325, correct predictions: 1330, total: 1776\n",
            "Batch 120/317 processed, running loss: 73.164556, correct predictions: 1446, total: 1936\n",
            "Batch 130/317 processed, running loss: 78.817965, correct predictions: 1566, total: 2096\n",
            "Batch 140/317 processed, running loss: 84.820970, correct predictions: 1692, total: 2256\n",
            "Batch 150/317 processed, running loss: 90.206537, correct predictions: 1808, total: 2416\n",
            "Batch 160/317 processed, running loss: 96.983669, correct predictions: 1926, total: 2576\n",
            "Batch 170/317 processed, running loss: 102.902471, correct predictions: 2042, total: 2736\n",
            "Batch 180/317 processed, running loss: 109.968268, correct predictions: 2157, total: 2896\n",
            "Batch 190/317 processed, running loss: 115.605093, correct predictions: 2272, total: 3056\n",
            "Batch 200/317 processed, running loss: 121.210726, correct predictions: 2392, total: 3216\n",
            "Batch 210/317 processed, running loss: 127.730871, correct predictions: 2496, total: 3376\n",
            "Batch 220/317 processed, running loss: 132.899669, correct predictions: 2614, total: 3536\n",
            "Batch 230/317 processed, running loss: 138.808541, correct predictions: 2732, total: 3696\n",
            "Batch 240/317 processed, running loss: 144.814444, correct predictions: 2861, total: 3856\n",
            "Batch 250/317 processed, running loss: 150.725099, correct predictions: 2986, total: 4016\n",
            "Batch 260/317 processed, running loss: 155.369067, correct predictions: 3118, total: 4176\n",
            "Batch 270/317 processed, running loss: 159.686981, correct predictions: 3251, total: 4336\n",
            "Batch 280/317 processed, running loss: 164.602047, correct predictions: 3378, total: 4496\n",
            "Batch 290/317 processed, running loss: 169.101476, correct predictions: 3510, total: 4656\n",
            "Batch 300/317 processed, running loss: 175.629331, correct predictions: 3634, total: 4816\n",
            "Batch 310/317 processed, running loss: 181.245189, correct predictions: 3768, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.585807\tAccuracy on Training set = 75.661794% [3830/5062]\n",
            "\n",
            "Validation Loss per batch = 1.039589\tAccuracy on Validation set = 69.449378% [391/563]\n",
            "Train Loss: 0.5858, Train Accuracy: 75.6618\n",
            "Valid Loss: 1.0396, Valid Accuracy: 69.4494\n",
            "\n",
            "Epoch 12/30\n",
            "-------------------------------\n",
            "Epoch: 11, Learning Rate: 0.001250 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.338427, correct predictions: 15, total: 16\n",
            "Batch 10/317 processed, running loss: 6.234833, correct predictions: 129, total: 176\n",
            "Batch 20/317 processed, running loss: 11.304512, correct predictions: 249, total: 336\n",
            "Batch 30/317 processed, running loss: 16.637125, correct predictions: 368, total: 496\n",
            "Batch 40/317 processed, running loss: 22.474662, correct predictions: 493, total: 656\n",
            "Batch 50/317 processed, running loss: 28.850136, correct predictions: 614, total: 816\n",
            "Batch 60/317 processed, running loss: 33.588104, correct predictions: 754, total: 976\n",
            "Batch 70/317 processed, running loss: 39.763991, correct predictions: 880, total: 1136\n",
            "Batch 80/317 processed, running loss: 45.534149, correct predictions: 1004, total: 1296\n",
            "Batch 90/317 processed, running loss: 50.948426, correct predictions: 1129, total: 1456\n",
            "Batch 100/317 processed, running loss: 57.198277, correct predictions: 1256, total: 1616\n",
            "Batch 110/317 processed, running loss: 62.038848, correct predictions: 1381, total: 1776\n",
            "Batch 120/317 processed, running loss: 66.619581, correct predictions: 1511, total: 1936\n",
            "Batch 130/317 processed, running loss: 71.518541, correct predictions: 1634, total: 2096\n",
            "Batch 140/317 processed, running loss: 76.314455, correct predictions: 1746, total: 2256\n",
            "Batch 150/317 processed, running loss: 80.816525, correct predictions: 1870, total: 2416\n",
            "Batch 160/317 processed, running loss: 86.280922, correct predictions: 1986, total: 2576\n",
            "Batch 170/317 processed, running loss: 90.984242, correct predictions: 2102, total: 2736\n",
            "Batch 180/317 processed, running loss: 96.566971, correct predictions: 2221, total: 2896\n",
            "Batch 190/317 processed, running loss: 102.233811, correct predictions: 2339, total: 3056\n",
            "Batch 200/317 processed, running loss: 108.181129, correct predictions: 2465, total: 3216\n",
            "Batch 210/317 processed, running loss: 113.700438, correct predictions: 2593, total: 3376\n",
            "Batch 220/317 processed, running loss: 118.831808, correct predictions: 2720, total: 3536\n",
            "Batch 230/317 processed, running loss: 123.446410, correct predictions: 2845, total: 3696\n",
            "Batch 240/317 processed, running loss: 129.425802, correct predictions: 2963, total: 3856\n",
            "Batch 250/317 processed, running loss: 135.018383, correct predictions: 3085, total: 4016\n",
            "Batch 260/317 processed, running loss: 140.349819, correct predictions: 3214, total: 4176\n",
            "Batch 270/317 processed, running loss: 145.859377, correct predictions: 3348, total: 4336\n",
            "Batch 280/317 processed, running loss: 151.433959, correct predictions: 3475, total: 4496\n",
            "Batch 290/317 processed, running loss: 156.503824, correct predictions: 3605, total: 4656\n",
            "Batch 300/317 processed, running loss: 160.610106, correct predictions: 3721, total: 4816\n",
            "Batch 310/317 processed, running loss: 165.371369, correct predictions: 3851, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.529512\tAccuracy on Training set = 77.558277% [3926/5062]\n",
            "\n",
            "Validation Loss per batch = 0.977021\tAccuracy on Validation set = 70.515098% [397/563]\n",
            "Train Loss: 0.5295, Train Accuracy: 77.5583\n",
            "Valid Loss: 0.9770, Valid Accuracy: 70.5151\n",
            "\n",
            "Epoch 13/30\n",
            "-------------------------------\n",
            "Epoch: 12, Learning Rate: 0.000625 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.304322, correct predictions: 14, total: 16\n",
            "Batch 10/317 processed, running loss: 5.208061, correct predictions: 141, total: 176\n",
            "Batch 20/317 processed, running loss: 9.432790, correct predictions: 270, total: 336\n",
            "Batch 30/317 processed, running loss: 14.976892, correct predictions: 395, total: 496\n",
            "Batch 40/317 processed, running loss: 20.082021, correct predictions: 529, total: 656\n",
            "Batch 50/317 processed, running loss: 25.114211, correct predictions: 652, total: 816\n",
            "Batch 60/317 processed, running loss: 30.482536, correct predictions: 781, total: 976\n",
            "Batch 70/317 processed, running loss: 35.856019, correct predictions: 912, total: 1136\n",
            "Batch 80/317 processed, running loss: 40.050093, correct predictions: 1041, total: 1296\n",
            "Batch 90/317 processed, running loss: 44.220479, correct predictions: 1170, total: 1456\n",
            "Batch 100/317 processed, running loss: 48.381084, correct predictions: 1294, total: 1616\n",
            "Batch 110/317 processed, running loss: 53.576327, correct predictions: 1417, total: 1776\n",
            "Batch 120/317 processed, running loss: 59.701653, correct predictions: 1536, total: 1936\n",
            "Batch 130/317 processed, running loss: 64.999832, correct predictions: 1656, total: 2096\n",
            "Batch 140/317 processed, running loss: 70.948456, correct predictions: 1781, total: 2256\n",
            "Batch 150/317 processed, running loss: 75.481716, correct predictions: 1903, total: 2416\n",
            "Batch 160/317 processed, running loss: 80.147897, correct predictions: 2019, total: 2576\n",
            "Batch 170/317 processed, running loss: 85.172766, correct predictions: 2141, total: 2736\n",
            "Batch 180/317 processed, running loss: 89.974049, correct predictions: 2255, total: 2896\n",
            "Batch 190/317 processed, running loss: 94.464899, correct predictions: 2384, total: 3056\n",
            "Batch 200/317 processed, running loss: 98.634513, correct predictions: 2509, total: 3216\n",
            "Batch 210/317 processed, running loss: 105.145413, correct predictions: 2614, total: 3376\n",
            "Batch 220/317 processed, running loss: 109.282927, correct predictions: 2737, total: 3536\n",
            "Batch 230/317 processed, running loss: 113.814779, correct predictions: 2866, total: 3696\n",
            "Batch 240/317 processed, running loss: 118.960678, correct predictions: 2990, total: 3856\n",
            "Batch 250/317 processed, running loss: 123.888343, correct predictions: 3116, total: 4016\n",
            "Batch 260/317 processed, running loss: 128.284298, correct predictions: 3247, total: 4176\n",
            "Batch 270/317 processed, running loss: 133.333466, correct predictions: 3372, total: 4336\n",
            "Batch 280/317 processed, running loss: 138.295043, correct predictions: 3492, total: 4496\n",
            "Batch 290/317 processed, running loss: 142.877058, correct predictions: 3621, total: 4656\n",
            "Batch 300/317 processed, running loss: 147.016362, correct predictions: 3748, total: 4816\n",
            "Batch 310/317 processed, running loss: 152.000025, correct predictions: 3878, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.493167\tAccuracy on Training set = 77.913868% [3944/5062]\n",
            "\n",
            "Validation Loss per batch = 0.993651\tAccuracy on Validation set = 69.804618% [393/563]\n",
            "Train Loss: 0.4932, Train Accuracy: 77.9139\n",
            "Valid Loss: 0.9937, Valid Accuracy: 69.8046\n",
            "\n",
            "Epoch 14/30\n",
            "-------------------------------\n",
            "Epoch: 13, Learning Rate: 0.000625 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.410818, correct predictions: 14, total: 16\n",
            "Batch 10/317 processed, running loss: 4.744051, correct predictions: 150, total: 176\n",
            "Batch 20/317 processed, running loss: 9.674851, correct predictions: 282, total: 336\n",
            "Batch 30/317 processed, running loss: 14.341226, correct predictions: 405, total: 496\n",
            "Batch 40/317 processed, running loss: 18.542397, correct predictions: 539, total: 656\n",
            "Batch 50/317 processed, running loss: 22.893195, correct predictions: 672, total: 816\n",
            "Batch 60/317 processed, running loss: 27.052510, correct predictions: 804, total: 976\n",
            "Batch 70/317 processed, running loss: 32.005253, correct predictions: 928, total: 1136\n",
            "Batch 80/317 processed, running loss: 36.901894, correct predictions: 1046, total: 1296\n",
            "Batch 90/317 processed, running loss: 40.869323, correct predictions: 1169, total: 1456\n",
            "Batch 100/317 processed, running loss: 45.892442, correct predictions: 1295, total: 1616\n",
            "Batch 110/317 processed, running loss: 51.188675, correct predictions: 1419, total: 1776\n",
            "Batch 120/317 processed, running loss: 54.860797, correct predictions: 1550, total: 1936\n",
            "Batch 130/317 processed, running loss: 59.640548, correct predictions: 1674, total: 2096\n",
            "Batch 140/317 processed, running loss: 64.188980, correct predictions: 1796, total: 2256\n",
            "Batch 150/317 processed, running loss: 69.795493, correct predictions: 1918, total: 2416\n",
            "Batch 160/317 processed, running loss: 74.488281, correct predictions: 2041, total: 2576\n",
            "Batch 170/317 processed, running loss: 79.326036, correct predictions: 2171, total: 2736\n",
            "Batch 180/317 processed, running loss: 83.713882, correct predictions: 2291, total: 2896\n",
            "Batch 190/317 processed, running loss: 87.690930, correct predictions: 2419, total: 3056\n",
            "Batch 200/317 processed, running loss: 93.347352, correct predictions: 2537, total: 3216\n",
            "Batch 210/317 processed, running loss: 97.776903, correct predictions: 2668, total: 3376\n",
            "Batch 220/317 processed, running loss: 102.899002, correct predictions: 2793, total: 3536\n",
            "Batch 230/317 processed, running loss: 107.512834, correct predictions: 2920, total: 3696\n",
            "Batch 240/317 processed, running loss: 113.021344, correct predictions: 3047, total: 3856\n",
            "Batch 250/317 processed, running loss: 117.985986, correct predictions: 3167, total: 4016\n",
            "Batch 260/317 processed, running loss: 122.581135, correct predictions: 3293, total: 4176\n",
            "Batch 270/317 processed, running loss: 127.863777, correct predictions: 3417, total: 4336\n",
            "Batch 280/317 processed, running loss: 133.435581, correct predictions: 3532, total: 4496\n",
            "Batch 290/317 processed, running loss: 137.389646, correct predictions: 3660, total: 4656\n",
            "Batch 300/317 processed, running loss: 142.554632, correct predictions: 3785, total: 4816\n",
            "Batch 310/317 processed, running loss: 147.056016, correct predictions: 3913, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.474493\tAccuracy on Training set = 78.526274% [3975/5062]\n",
            "\n",
            "Validation Loss per batch = 1.011925\tAccuracy on Validation set = 67.673179% [381/563]\n",
            "Train Loss: 0.4745, Train Accuracy: 78.5263\n",
            "Valid Loss: 1.0119, Valid Accuracy: 67.6732\n",
            "\n",
            "Epoch 15/30\n",
            "-------------------------------\n",
            "Epoch: 14, Learning Rate: 0.000625 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.229932, correct predictions: 12, total: 16\n",
            "Batch 10/317 processed, running loss: 6.115769, correct predictions: 129, total: 176\n",
            "Batch 20/317 processed, running loss: 10.673054, correct predictions: 262, total: 336\n",
            "Batch 30/317 processed, running loss: 15.104730, correct predictions: 382, total: 496\n",
            "Batch 40/317 processed, running loss: 18.769961, correct predictions: 519, total: 656\n",
            "Batch 50/317 processed, running loss: 24.124777, correct predictions: 640, total: 816\n",
            "Batch 60/317 processed, running loss: 28.603211, correct predictions: 766, total: 976\n",
            "Batch 70/317 processed, running loss: 34.080052, correct predictions: 895, total: 1136\n",
            "Batch 80/317 processed, running loss: 40.523862, correct predictions: 1013, total: 1296\n",
            "Batch 90/317 processed, running loss: 45.075308, correct predictions: 1131, total: 1456\n",
            "Batch 100/317 processed, running loss: 49.361779, correct predictions: 1257, total: 1616\n",
            "Batch 110/317 processed, running loss: 53.920159, correct predictions: 1384, total: 1776\n",
            "Batch 120/317 processed, running loss: 58.149583, correct predictions: 1512, total: 1936\n",
            "Batch 130/317 processed, running loss: 62.181662, correct predictions: 1642, total: 2096\n",
            "Batch 140/317 processed, running loss: 65.760409, correct predictions: 1772, total: 2256\n",
            "Batch 150/317 processed, running loss: 71.517486, correct predictions: 1894, total: 2416\n",
            "Batch 160/317 processed, running loss: 74.755082, correct predictions: 2023, total: 2576\n",
            "Batch 170/317 processed, running loss: 79.524088, correct predictions: 2148, total: 2736\n",
            "Batch 180/317 processed, running loss: 83.102261, correct predictions: 2278, total: 2896\n",
            "Batch 190/317 processed, running loss: 87.458223, correct predictions: 2406, total: 3056\n",
            "Batch 200/317 processed, running loss: 93.212459, correct predictions: 2523, total: 3216\n",
            "Batch 210/317 processed, running loss: 97.334167, correct predictions: 2655, total: 3376\n",
            "Batch 220/317 processed, running loss: 102.099068, correct predictions: 2781, total: 3536\n",
            "Batch 230/317 processed, running loss: 107.641704, correct predictions: 2902, total: 3696\n",
            "Batch 240/317 processed, running loss: 111.435913, correct predictions: 3037, total: 3856\n",
            "Batch 250/317 processed, running loss: 115.293353, correct predictions: 3165, total: 4016\n",
            "Batch 260/317 processed, running loss: 120.157713, correct predictions: 3293, total: 4176\n",
            "Batch 270/317 processed, running loss: 124.491326, correct predictions: 3418, total: 4336\n",
            "Batch 280/317 processed, running loss: 128.675218, correct predictions: 3553, total: 4496\n",
            "Batch 290/317 processed, running loss: 132.692451, correct predictions: 3689, total: 4656\n",
            "Batch 300/317 processed, running loss: 137.446934, correct predictions: 3818, total: 4816\n",
            "Batch 310/317 processed, running loss: 141.499581, correct predictions: 3943, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.454297\tAccuracy on Training set = 79.257211% [4012/5062]\n",
            "\n",
            "Validation Loss per batch = 1.022476\tAccuracy on Validation set = 69.094139% [389/563]\n",
            "Train Loss: 0.4543, Train Accuracy: 79.2572\n",
            "Valid Loss: 1.0225, Valid Accuracy: 69.0941\n",
            "\n",
            "Epoch 16/30\n",
            "-------------------------------\n",
            "Epoch: 15, Learning Rate: 0.000625 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/317 processed, running loss: 0.599872, correct predictions: 12, total: 16\n",
            "Batch 10/317 processed, running loss: 4.658945, correct predictions: 142, total: 176\n",
            "Batch 20/317 processed, running loss: 8.912083, correct predictions: 266, total: 336\n",
            "Batch 30/317 processed, running loss: 12.789699, correct predictions: 397, total: 496\n",
            "Batch 40/317 processed, running loss: 18.336751, correct predictions: 519, total: 656\n",
            "Batch 50/317 processed, running loss: 22.883664, correct predictions: 643, total: 816\n",
            "Batch 60/317 processed, running loss: 27.293884, correct predictions: 780, total: 976\n",
            "Batch 70/317 processed, running loss: 32.369691, correct predictions: 909, total: 1136\n",
            "Batch 80/317 processed, running loss: 37.267414, correct predictions: 1043, total: 1296\n",
            "Batch 90/317 processed, running loss: 40.810013, correct predictions: 1180, total: 1456\n",
            "Batch 100/317 processed, running loss: 45.107441, correct predictions: 1309, total: 1616\n",
            "Batch 110/317 processed, running loss: 49.082234, correct predictions: 1438, total: 1776\n",
            "Batch 120/317 processed, running loss: 52.891222, correct predictions: 1569, total: 1936\n",
            "Batch 130/317 processed, running loss: 57.298065, correct predictions: 1683, total: 2096\n",
            "Batch 140/317 processed, running loss: 62.127515, correct predictions: 1811, total: 2256\n",
            "Batch 150/317 processed, running loss: 67.854887, correct predictions: 1934, total: 2416\n",
            "Batch 160/317 processed, running loss: 71.800070, correct predictions: 2061, total: 2576\n",
            "Batch 170/317 processed, running loss: 75.443335, correct predictions: 2194, total: 2736\n",
            "Batch 180/317 processed, running loss: 79.611082, correct predictions: 2314, total: 2896\n",
            "Batch 190/317 processed, running loss: 83.269729, correct predictions: 2433, total: 3056\n",
            "Batch 200/317 processed, running loss: 87.796847, correct predictions: 2559, total: 3216\n",
            "Batch 210/317 processed, running loss: 92.057408, correct predictions: 2679, total: 3376\n",
            "Batch 220/317 processed, running loss: 97.345108, correct predictions: 2804, total: 3536\n",
            "Batch 230/317 processed, running loss: 101.075747, correct predictions: 2934, total: 3696\n",
            "Batch 240/317 processed, running loss: 105.167078, correct predictions: 3057, total: 3856\n",
            "Batch 250/317 processed, running loss: 109.173721, correct predictions: 3190, total: 4016\n",
            "Batch 260/317 processed, running loss: 114.142656, correct predictions: 3307, total: 4176\n",
            "Batch 270/317 processed, running loss: 118.016718, correct predictions: 3437, total: 4336\n",
            "Batch 280/317 processed, running loss: 121.738050, correct predictions: 3573, total: 4496\n",
            "Batch 290/317 processed, running loss: 126.134068, correct predictions: 3710, total: 4656\n",
            "Batch 300/317 processed, running loss: 129.956358, correct predictions: 3852, total: 4816\n",
            "Batch 310/317 processed, running loss: 133.480570, correct predictions: 3990, total: 4976\n",
            "\n",
            "Training Loss per batch = 0.428917\tAccuracy on Training set = 80.205452% [4060/5062]\n",
            "\n",
            "Validation Loss per batch = 1.035401\tAccuracy on Validation set = 71.758437% [404/563]\n",
            "Train Loss: 0.4289, Train Accuracy: 80.2055\n",
            "Valid Loss: 1.0354, Valid Accuracy: 71.7584\n",
            "Early stopping at epoch 16, the validation loss did not improve for the last 4 epochs\n",
            "\n",
            "Training has completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Store all the model predictions for the test set\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# No need to track gradients for evaluation, saves memory and computations\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "I1AcQn3ikQyD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "26QT6jxWj_07"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(classification_report(all_labels, all_preds))\n",
        "\n",
        "# For multiclass case:\n",
        "num_classes = cm.shape[0]  # assuming cm is a square matrix\n",
        "\n",
        "for i in range(num_classes):\n",
        "    tp = cm[i, i]\n",
        "    fn = cm[i, :].sum() - tp  # sum across the row, excluding the diagonal element\n",
        "    fp = cm[:, i].sum() - tp  # sum down the column, excluding the diagonal element\n",
        "    tn = cm.sum() - fn - fp - tp\n",
        "\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    print(f\"For class {i}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n"
      ],
      "metadata": {
        "id": "7I92W90hYTAe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "outputId": "d9a0b9ab-536f-4321-ba41-0617568148fa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxEAAAJaCAYAAABQj8p9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcWElEQVR4nO3de3zP9f//8ft7xjC2NWyzHONTLGeKlfJJCyXxoaTQivRLo1gUn0+OyaSkVCiVQyVRkZTDzCkshyHnQ6g57cCaZbX3Du/37w9f78/7/XF476Xt/drhdv1cXpdL7+fr+X6/H9vbZ/Z0fx4sdrvdLgAAAADIJy+zCwAAAABQvDCIAAAAAGAIgwgAAAAAhjCIAAAAAGAIgwgAAAAAhjCIAAAAAGAIgwgAAAAAhjCIAAAAAGAIgwgAAAAAhnibXUBhyDl7zOwS4EG3N+prdgnwoBRrutklwIOSM9PNLgEeZDG7AHhUTvYps0u4Kk/+Llm26k0ee6+CRBIBAAAAwJASmUQAAAAA182WZ3YFRR5JBAAAAABDSCIAAAAAZ3ab2RUUeSQRAAAAAAwhiQAAAACc2Ugi3CGJAAAAAGAISQQAAADgxM6aCLdIIgAAAAAYQhIBAAAAOGNNhFskEQAAAAAMIYkAAAAAnLEmwi2SCAAAAACGkEQAAAAAzmx5ZldQ5JFEAAAAADCEQQQAAAAAQ5jOBAAAADhjYbVbJBEAAAAADCGJAAAAAJxx2JxbJBEAAAAADCGJAAAAAJzYWRPhFkkEAAAAAENIIgAAAABnrIlwiyQCAAAAgCEkEQAAAIAz1kS4RRIBAAAAFAN5eXkaNWqU6tatqwoVKqhevXp69dVXZbfbHX3sdrtGjx6t6tWrq0KFCoqIiNCRI0dcXictLU29e/eWn5+fAgIC1L9/f124cMFQLQwiAAAAAGe2PM9dBrz++uuaMWOG3nvvPR04cECvv/66Jk+erHfffdfRZ/LkyZo2bZpmzpypLVu2yNfXVx07dlRWVpajT+/evbVv3z7FxsZq2bJl2rBhg5555hlDtVjszkOXEiLn7DGzS4AH3d6or9klwINSrOlmlwAPSs5MN7sEeJDF7ALgUTnZp8wu4aqsB9d77L18GrTLd98HH3xQwcHB+vjjjx1tPXr0UIUKFfTZZ5/JbrcrNDRUL774ooYNGyZJOn/+vIKDgzVnzhz16tVLBw4cUFhYmLZt26ZWrVpJklasWKEHHnhAJ0+eVGhoaL5qIYkAAAAAnNltHrusVqsyMjJcLqvVesWy7rjjDsXFxenw4cOSpJ9//lkbN27U/fffL0k6fvy4kpKSFBER4XiOv7+/Wrdurfj4eElSfHy8AgICHAMISYqIiJCXl5e2bNmS728RgwgAAADAJDExMfL393e5YmJirth3xIgR6tWrlxo0aKCyZcuqefPmGjJkiHr37i1JSkpKkiQFBwe7PC84ONhxLykpSUFBQS73vb29FRgY6OiTH+zOBAAAADjz4DkRI0eOVHR0tEubj4/PFfsuXLhQn3/+uebPn69bb71Vu3bt0pAhQxQaGqrIyEhPlOvAIAIAAAAwiY+Pz1UHDf9r+PDhjjRCkho3bqzffvtNMTExioyMVEhIiCQpOTlZ1atXdzwvOTlZzZo1kySFhIQoJSXF5XVzc3OVlpbmeH5+MJ0JAAAAcObBNRFG/Pnnn/Lycv31vUyZMrL9X3JSt25dhYSEKC4uznE/IyNDW7ZsUXh4uCQpPDxc6enpSkhIcPRZs2aNbDabWrdune9aSCIAAACAYqBLly567bXXVKtWLd16663auXOn3nrrLfXr10+SZLFYNGTIEE2YMEH/+Mc/VLduXY0aNUqhoaHq1q2bJKlhw4bq1KmTBgwYoJkzZyonJ0eDBg1Sr1698r0zk8QgAgAAACgW3n33XY0aNUrPPfecUlJSFBoaqv/3//6fRo8e7ejz0ksvKTMzU88884zS09PVtm1brVixQuXLl3f0+fzzzzVo0CDde++98vLyUo8ePTRt2jRDtXBOBIo9zokoXTgnonThnIjShXMiSpcifU7E7pUeey+fJh099l4FiTURAAAAAAxhOhMAAADgxG7PM7uEIo8kAgAAAIAhJBEAAACAM4Nbr5ZGJBEAAAAADCGJAAAAAJzZSCLcIYkAAAAAYAhJBAAAAOCMNRFukUQAAAAAMIQkAgAAAHBm45wId0giAAAAABjCIKIIy8vL07sfzlPHh59Uy3u6qtMjT2nm7Pmy2+1X7D9u8rtqdOf9+vTLxS7tvyae1OCXx6ntA4+q9X3d1Xfgi9qa8LMnvgQY1KJNU70973Wt2vWtdiZt0j873XVZn4EvPa1VP3+r+ONrNHPh26pVt8ZlfdpGhGveDx8q/vgarT+4XG/NjvFE+fibol9+Tqd+3+dyrd/ynSSpRs3Qy+5duh7s2sHkylGQBj4bqV8O/6QLGUe1eeN3uq1VM7NLggcMHx6lnOxTmvLmOLNLgXRxTYSnrmKK6UxF2MefLdKXS77Xa6+8qPp1a2vfwcN65bWpqlTJV30e6erSd/X6Tdq976CCqla57HWiXhqrWjVC9fG0SSrvU06fLlyiqJfGaPnCT1S1SqCnvhzkQ4WKFXR43y/69ovvr/iL/5ODeuux/g9r9PMTdCrxjJ57eYDeX/CWetzdR9nWbEnSvZ3/qVFvvqz3Yj7Q1o0J8vYuo3oNbvL0l4LrdPDAEfXq9rTjcW5uriTp9KkkNbulnUvf3pGPaODgp7Rm9UaP1ojC88gjD+nNN8bouagR2rptp54f/LR++P5zhTW6W6mp58wuD4WkVcumGvB0H+3evd/sUoB8I4kownbtPaB77mqjdnfcrhurB6vDPXfpjttbaM/+Qy79klPPKmbqDL0+5iV5e5dxufd7+nn9duKUnu7TU7fUr6vaNW/U0Gef0l9ZVh059psnvxzkw6Y1P2n667O0dvmGK95/fEBPzXp7rtat3KgjB45q1OBXVS24qu75v8SiTJkyGv7qC3p7/Pv6at4SJR47oWOHf1Xs0jWe/DLwN+Tl5ik15azj+j0tXZJks9lc2lNTzur+B+/Vd0tW6M/MP80tGgVm6AsD9NHH8zV33kIdOHBEz0WN0J9//qWnnuxldmkoJL6+FTV33nt6duBL+v33dLPLwSU2m+euYsrUQcTZs2c1efJk/etf/1J4eLjCw8P1r3/9S2+88YZSU1PNLK1IaNaoobZs36VfE09Kkg4eOaYdu/fprjatHH1sNptGjn9TTz7+sOrfVPuy1wjw91PdWjW0dEWc/vwrS7m5eVr47Q8KvCFAYbfU99jXgr/vxlqhqhZcVVs2bHe0XfgjU3t37leTVo0kSQ2a3Kzg0CDZ7DZ9ETtbq37+Vu/Nf1P1GtQ1q2wYVPemWkrYv1abd67Qux++rtAa1a/Yr3HTMDVq0lALPvvGwxWisJQtW1YtWjRR3JofHW12u11xazaqTZuWJlaGwvTutIla/kOc1jh97kBxYNp0pm3btqljx46qWLGiIiIidPPNN0uSkpOTNW3aNE2aNEkrV65Uq1at3LxSyfV0357K/PNPdXn8GZXx8lKezabnn4nUgx3bO/p8/NkilSnjddn0pkssFotmvTNRz494Va3v6y4vL4sCAwL0wVuvyt+vsqe+FBSAqkEXp56lpaa5tJ9LTVOVoIvT2GrUCpUkPTusv6aMeVenT5xR32d7adbX76nbnb2Ukf6HZ4uGITsTdmto1H909JdfFRRcTdEvD9TiH+ap/R1dlXnBNW14rG8PHT54VNu37jKnWBS4qlUD5e3trZTksy7tKSmpanBLPZOqQmHq2fMhNW/eSG3CO5tdCv5XMV6r4CmmDSIGDx6sRx55RDNnzpTFYnG5Z7fb9eyzz2rw4MGKj4+/5utYrVZZrVaXNi+rVT4+PgVes6etWLNBy1at1etjX1L9urV18Mgxvf7OBwqqGqiuD9ynfQeP6LNF32rRJ+9e9j28xG6367Up01XlBn/Nnf6Gyvv46OvvVmjQS2O14KNpqlaVNRElicXrYrj40dtzFff9OknSmCETtXLnYt3Xpb2+/vRbE6uDO2ud1jYc2HdYO7fv1pY9serSrZNL4lC+vI+6PfyA3nljphllAigANWqE6q0p43X/A49d9nsMUByYNoj4+eefNWfOnCv+8muxWDR06FA1b97c7evExMRo3DjXnQxeGf68Rr/0QoHVapYp73+sp/v01AMR/5Qk3Vyvrs4kpeijTxeq6wP3acfPe5X2e7ru6/GE4zl5eTa98d5H+nThEq36eq62JOzS+s1btXnFQlXy9ZUkhd0ySPHbdurb5av1dN+eZnxpuA5nUy4mEIHVAnU25b8LLKtUC9ShvUf+r8/F9mOHf3Xcz8nO0cnfTivkxmDPFYsCkZHxh4798pvq3FTLpb1z1w6qUKGCFi1YalJlKAxnz6YpNzdXQcFVXdqDgqopKZkpviVNixaNFRxcTVu3rHC0eXt766672ui5556Ub6W6shXj+fLFHt97t0wbRISEhGjr1q1q0KDBFe9v3bpVwcHuf+kZOXKkoqOjXdq8/jhVIDWaLSvLKouX6yDLy8tLtv/b4rVLp3vV5jbXgdb/G/qKunRqr24PdHC8hiR5WVyXv3hZLPxwKmZOJZ5WavJZtb6rpQ7vuzho8K1UUY2ah2nRnIvb+h74+aCsWVbVqVdLu7buliR5e5dRaM3qOnMyybTacX0q+lZU7bo19fWXroOFXn26K3b5WqWd+92kylAYcnJytGPHbrW/p62WLl0p6eI/qrW/p62mz5htcnUoaGvWbFSz5u1d2j6a9ZYOHTqqN958n7+jUeSZNogYNmyYnnnmGSUkJOjee+91DBiSk5MVFxenWbNm6c0333T7Oj4+PpdNXcrJPnuV3sXLP+9srVlzF6h6cJDq162tA4d/0bwvv9G/Ol8cIAT4+ynA38/lOd7eZVQ18AbVrX3x7ICmjRrKr3Il/XvCFD371OMq71NOXy1doZNnknX3Hbd7/GvCtVWoWEE1nc59uLFWqG6+9R/KSM9Q0qlkzZ+1UE8PiVTisZM6lXhaz708QKnJZ7V2xcUFeZkX/tRX877Vs8P7K+l0is6cTFLkc49LkmK/W2vK14T8GzV+mGJXrNPJE6cVUj1IL46Iki0vT0u+/sHRp07dWmpzRyv17TnQxEpRWKa+M0uzP56qhB27tW3bTj0/eIB8fStoztwvzS4NBezChUzt2+e622Jm5p86d+73y9qBosi0QURUVJSqVq2qqVOnavr06crLu3i8eJkyZdSyZUvNmTNHPXuW7qk2/x46UO/OmqcJb76vtN/TVa1qoB7p+oAGPvV4vl/jhgB/zZzyqqZ9OFf9nx+h3Nxc1a9bW+9OGq0G/+DsgKImrFkDffTNe47Hw8Y/L0la+uUPGvPCa5rz3ueqULGCXnnzJVX2q6RdW3cr6rEXHWdESNLb499TXl6uJrw3Sj7lfbR3x3498/Dz+uM8i6qLuuo3Buv9j97QDYEBSjubpq1bdqjLfY+7JA69+vxLZ04na/2aTSZWisKyaNFSVasaqLGjhykkpJp+/nmfOj/YRykpJeMfx4BigyTILYv9ascfe1BOTo7Onr34A7Jq1aoqW7bs33u9s8cKoiwUE7c36mt2CfCgFGu62SXAg5Iz080uAR505S1CUFLlZBfd6edZP37qsfcqf1fx/D2mSJxYXbZsWVWvfuW90AEAAABPstvzzC6hyOPEagAAAACGFIkkAgAAACgyWBPhFkkEAAAAAENIIgAAAABndpIId0giAAAAABhCEgEAAAA4Y02EWyQRAAAAAAwhiQAAAACcsSbCLZIIAAAAAIaQRAAAAADOWBPhFkkEAAAAAENIIgAAAABnrIlwiyQCAAAAgCEkEQAAAIAz1kS4RRIBAAAAwBAGEQAAAAAMYToTAAAA4IzpTG6RRAAAAAAwhCQCAAAAcMYWr26RRAAAAAAwhCQCAAAAcMaaCLdIIgAAAAAYQhIBAAAAOGNNhFskEQAAAAAMIYkAAAAAnLEmwi2SCAAAAACGkEQAAAAAzlgT4RZJBAAAAABDSCIAAAAAZ6yJcIskAgAAAIAhDCIAAAAAZzab5y4D6tSpI4vFctkVFRUlScrKylJUVJSqVKmiSpUqqUePHkpOTnZ5jcTERHXu3FkVK1ZUUFCQhg8frtzcXMPfIgYRAAAAQDGwbds2nTlzxnHFxsZKkh555BFJ0tChQ/Xdd99p0aJFWr9+vU6fPq3u3bs7np+Xl6fOnTsrOztbmzdv1ty5czVnzhyNHj3acC0Wu91uL5gvq+jIOXvM7BLgQbc36mt2CfCgFGu62SXAg5Iz080uAR5kMbsAeFRO9imzS7iqv74c57H3qvDomOt+7pAhQ7Rs2TIdOXJEGRkZqlatmubPn6+HH35YknTw4EE1bNhQ8fHxatOmjZYvX64HH3xQp0+fVnBwsCRp5syZevnll5Wamqpy5crl+71JIgAAAACTWK1WZWRkuFxWq9Xt87Kzs/XZZ5+pX79+slgsSkhIUE5OjiIiIhx9GjRooFq1aik+Pl6SFB8fr8aNGzsGEJLUsWNHZWRkaN++fYbqZhABAAAAOPPgmoiYmBj5+/u7XDExMW5LXLJkidLT0/Xkk09KkpKSklSuXDkFBAS49AsODlZSUpKjj/MA4tL9S/eMYItXAAAAwCQjR45UdHS0S5uPj4/b53388ce6//77FRoaWlilXRODCAAAAMAkPj4++Ro0OPvtt9+0evVqffPNN462kJAQZWdnKz093SWNSE5OVkhIiKPP1q1bXV7r0u5Nl/rkF9OZAAAAAGdFdIvXS2bPnq2goCB17tzZ0dayZUuVLVtWcXFxjrZDhw4pMTFR4eHhkqTw8HDt2bNHKSkpjj6xsbHy8/NTWFiYoRpIIgAAAIBiwmazafbs2YqMjJS3939/lff391f//v0VHR2twMBA+fn5afDgwQoPD1ebNm0kSR06dFBYWJj69u2ryZMnKykpSa+88oqioqIMpyEMIgAAAABn9utLCDxh9erVSkxMVL9+/S67N3XqVHl5ealHjx6yWq3q2LGjpk+f7rhfpkwZLVu2TAMHDlR4eLh8fX0VGRmp8ePHG66DcyJQ7HFOROnCORGlC+dElC6cE1G6FOlzIj77j8feq0Kf1zz2XgWJJAIAAABwdp1rFUoTFlYDAAAAMIQkAgAAAHBW8mb7FziSCAAAAACGkEQAAAAAzlgT4RZJBAAAAABDSCIAAAAAZyQRbpXIQcQtDXqYXQI86PSFc2aXAA+yi8VuQEnF/7uB4qNEDiIAAACA61aET6wuKlgTAQAAAMAQkggAAADAid3G5Dp3SCIAAAAAGEISAQAAADhjdya3SCIAAAAAGMIgAgAAAIAhTGcCAAAAnLHFq1skEQAAAAAMIYkAAAAAnLHFq1skEQAAAAAMIYkAAAAAnLHFq1skEQAAAAAMIYkAAAAAnJFEuEUSAQAAAMAQkggAAADAmZ3dmdwhiQAAAABgCEkEAAAA4Iw1EW6RRAAAAAAwhCQCAAAAcMaJ1W6RRAAAAAAwhCQCAAAAcGZnTYQ7JBEAAAAADCGJAAAAAJyxJsItkggAAAAAhpBEAAAAAE7snBPhFkkEAAAAAEMYRAAAAAAwhOlMAAAAgDMWVrtFEgEAAADAEJIIAAAAwBmHzblFEgEAAADAEJIIAAAAwBlrItwiiQAAAABgCEkEAAAA4IzD5twiiQAAAABgCEkEAAAA4Iw1EW6RRAAAAAAwhCQCAAAAcMY5EW6RRAAAAAAwhCQCAAAAcMaaCLdIIgAAAAAYQhIBAAAAOLFzToRbJBEAAAAADGEQAQAAADiz2T13GXTq1Cn16dNHVapUUYUKFdS4cWNt377dcd9ut2v06NGqXr26KlSooIiICB05csTlNdLS0tS7d2/5+fkpICBA/fv314ULFwzVwSACAAAAKAZ+//133XnnnSpbtqyWL1+u/fv3a8qUKbrhhhscfSZPnqxp06Zp5syZ2rJli3x9fdWxY0dlZWU5+vTu3Vv79u1TbGysli1bpg0bNuiZZ54xVIvFbreXuOXnN1VtbnYJ8KDTF86ZXQI8yK4S9yML15DHvGSgxMrNPmV2CVd14eXuHnuvSq9/k+++I0aM0KZNm/Tjjz9e8b7dbldoaKhefPFFDRs2TJJ0/vx5BQcHa86cOerVq5cOHDigsLAwbdu2Ta1atZIkrVixQg888IBOnjyp0NDQfNVCElHMbNjxvY6d3XnZNe71EZf1/WTBezp2dqfuu/+fni8UBaJt29v19def6NixbcrKSlSXLh1c7s+aNUVZWYku19Kl80yqFn9X27at9c3Xn+j4se2yZp3QQ106utzv2rWTvl/2uU6f2i1r1gk1aRJmUqUoTAOfjdQvh3/ShYyj2rzxO93WqpnZJaEQ3NW2tZYsnqPEXxOUm31KDz3U0f2T4DkenM5ktVqVkZHhclmt1iuWtXTpUrVq1UqPPPKIgoKC1Lx5c82aNctx//jx40pKSlJERISjzd/fX61bt1Z8fLwkKT4+XgEBAY4BhCRFRETIy8tLW7Zsyfe3iEFEMdPtvj66PSzCcfXt/qwk6YelsS79+j3bWyp5IVOpU7FiRe3Zs19Dhrxy1T4rV65V7dotHdcTTwz2YIUoSL4VK2j3ngN64Sqft69vRW3avFX/eWWihyuDpzzyyEN6840xenXCW7qtdSf9vHu/fvj+c1WrVsXs0lDAfH0ravfu/Rr8wn/MLgUmi4mJkb+/v8sVExNzxb7Hjh3TjBkz9I9//EMrV67UwIED9fzzz2vu3LmSpKSkJElScHCwy/OCg4Md95KSkhQUFORy39vbW4GBgY4++cEWr8VM2rnfXR4PfP4p/XosUVs2JTjaGja6Wf2f66uuEb21df9qT5eIArRq1TqtWrXumn2s1mwlJ6d6piAUqpWr1mnlNT7v+fMvRt61a9fwUEXwtKEvDNBHH8/X3HkLJUnPRY3QA/ffq6ee7KXJb7xvcnUoSCtWrtWKlWvNLgNXY/fcVMqRI0cqOjrapc3Hx+eKfW02m1q1aqWJEy/+Y1Lz5s21d+9ezZw5U5GRkYVeqzOSiGKsbFlvdX3kAX01/1tHW/kK5fX2BzEa8/IknU1hrUBpcPfdbZSYuEO7d6/VtGmvKTAwwOySAFyHsmXLqkWLJopb89+5zna7XXFrNqpNm5YmVgagMPn4+MjPz8/lutogonr16goLc53K2rBhQyUmJkqSQkJCJEnJyckufZKTkx33QkJClJKS4nI/NzdXaWlpjj75UaQHESdOnFC/fv2u2edK88jsHhw9mum+B+6Rn39lfbXgO0fbKxNe1I5tP2v18nXmFQaPWbVqnfr3j9b99z+m//wnRnfd1UbffjtPXl5F+v/aAK6gatVAeXt7KyX5rEt7SkqqQoKrmVQVUEoV0S1e77zzTh06dMil7fDhw6pdu7YkqW7dugoJCVFcXJzjfkZGhrZs2aLw8HBJUnh4uNLT05WQ8N9ZLGvWrJHNZlPr1q3zXUuRns6UlpamuXPn6pNPPrlqn5iYGI0bN86lLaBCsG6oWL2wyzNdz97dtD5uk1KSLk5lubdTO91x1+168J5eJlcGT1m06L8DyH37Dmnv3oM6cGCj2rUL19q1m0ysDAAAFLShQ4fqjjvu0MSJE9WzZ09t3bpVH374oT788ENJksVi0ZAhQzRhwgT94x//UN26dTVq1CiFhoaqW7duki4mF506ddKAAQM0c+ZM5eTkaNCgQerVq1e+d2aSTB5ELF269Jr3jx075vY1rjSPrGndu/5WXcVBaI3qurNdaw18cpij7Y62t6lWnRradXSDS9/pc97Utp926vGuAzxdJjzs+PFEpaaeU716dRhEAMXM2bNpys3NVVBwVZf2oKBqSmLdE+BR9us4BM4TbrvtNi1evFgjR47U+PHjVbduXb399tvq3bu3o89LL72kzMxMPfPMM0pPT1fbtm21YsUKlS9f3tHn888/16BBg3TvvffKy8tLPXr00LRp0wzVYuogolu3brJYLLrWURUWi+War+Hj43PZvDGLpeRP5Xjk8Yd07mya1q7679zZGdNm68vPFrv0W7HxK014ZYriVq73dIkwwY03hqhKlRt05kyK+84AipScnBzt2LFb7e9pq6VLV0q6+Hdg+3vaavqM2SZXB6CoePDBB/Xggw9e9b7FYtH48eM1fvz4q/YJDAzU/Pnz/1Ydpg4iqlevrunTp6tr165XvL9r1y61bMlisv9lsVj08GNd9c2CZcrLy3O0n005d8XF1KdPntHJxNOeLBEFxNe3ourVq+N4XKdOTTVpEqbff09XWlq6/vOfIVqyZLmSk1N100219dpr/9bRo78qNpZBY3F0rc/7xInTuuGGANWsGarQ6he37rv55nqSpOTkVHboKiGmvjNLsz+eqoQdu7Vt2049P3iAfH0raM7cL80uDQXM17ei6tev63hct04tNW16q9LSfteJE/ydbboimkQUJaYOIlq2bKmEhISrDiLcpRSl1Z3tWuvGmtW1aP4Ss0tBIWvZsolWrVroePzGG2MkSZ9+ukiDB/9bjRs3VJ8+DysgwE9nziRr9eofNW7cm8rOzjarZPwNLVs2UeyqRY7Hlz7veZ8u0oAB0Xrwwfv00ay3HPc//2y6JOnVCW9pwoSpni0WhWLRoqWqVjVQY0cPU0hINf388z51frCPUlLOun8yipVWLZsqbvVXjsdT3hwrSZo7b6H6Pz3UpKqA/LPYTfwt/ccff1RmZqY6dep0xfuZmZnavn272rVrZ+h1b6ravCDKQzFx+gJb2ZYmdvEPC6VJnq107LYHlEa52afMLuGq/hj0gMfeq/J7P3jsvQqSqUnEXXddewG0r6+v4QEEAAAAgMJVpLd4BQAAADyONRFulfxtjAAAAAAUKJIIAAAAwBlJhFskEQAAAAAMIYkAAAAAnHDEgHskEQAAAAAMIYkAAAAAnLEmwi2SCAAAAACGMIgAAAAAYAjTmQAAAABnTGdyiyQCAAAAgCEkEQAAAIATO0mEWyQRAAAAAAwhiQAAAACckUS4RRIBAAAAwBCSCAAAAMCZzewCij6SCAAAAACGkEQAAAAATtidyT2SCAAAAACGkEQAAAAAzkgi3CKJAAAAAGAISQQAAADgjN2Z3CKJAAAAAGAISQQAAADghN2Z3COJAAAAAGAISQQAAADgjDURbpFEAAAAADCEQQQAAAAAQ5jOBAAAADhhYbV7JBEAAAAADCGJAAAAAJyxsNotkggAAAAAhpBEAAAAAE7sJBFukUQAAAAAMIQkAgAAAHBGEuEWSQQAAAAAQ0giAAAAACesiXCPJAIAAACAISQRAAAAgDOSCLdIIgAAAAAYQhIBAAAAOGFNhHskEQAAAAAMIYkAAAAAnJBEuEcSAQAAAMAQkggAAADACUmEeyQRAAAAAAwhiQAAAACc2S1mV1DklchBRK4t1+wSABSSsIBaZpcAD9qfnmh2CQCAK2A6EwAAAABDGEQAAAAATuw2z11GjB07VhaLxeVq0KCB435WVpaioqJUpUoVVapUST169FBycrLLayQmJqpz586qWLGigoKCNHz4cOXmGp/FUyKnMwEAAAAl0a233qrVq1c7Hnt7//fX+aFDh+r777/XokWL5O/vr0GDBql79+7atGmTJCkvL0+dO3dWSEiINm/erDNnzuiJJ55Q2bJlNXHiREN1MIgAAAAAnNhtRXdhtbe3t0JCQi5rP3/+vD7++GPNnz9f7du3lyTNnj1bDRs21E8//aQ2bdpo1apV2r9/v1avXq3g4GA1a9ZMr776ql5++WWNHTtW5cqVy3cdTGcCAAAATGK1WpWRkeFyWa3Wq/Y/cuSIQkNDddNNN6l3795KTLy4AUVCQoJycnIUERHh6NugQQPVqlVL8fHxkqT4+Hg1btxYwcHBjj4dO3ZURkaG9u3bZ6huBhEAAACAE0+uiYiJiZG/v7/LFRMTc8W6WrdurTlz5mjFihWaMWOGjh8/rrvuukt//PGHkpKSVK5cOQUEBLg8Jzg4WElJSZKkpKQklwHEpfuX7hnBdCYAAADAJCNHjlR0dLRLm4+PzxX73n///Y7/btKkiVq3bq3atWtr4cKFqlChQqHW+b9IIgAAAAAndrvFY5ePj4/8/PxcrqsNIv5XQECAbr75Zv3yyy8KCQlRdna20tPTXfokJyc71lCEhIRctlvTpcdXWmdxLQwiAAAAgGLowoULOnr0qKpXr66WLVuqbNmyiouLc9w/dOiQEhMTFR4eLkkKDw/Xnj17lJKS4ugTGxsrPz8/hYWFGXpvpjMBAAAAToye3+Apw4YNU5cuXVS7dm2dPn1aY8aMUZkyZfTYY4/J399f/fv3V3R0tAIDA+Xn56fBgwcrPDxcbdq0kSR16NBBYWFh6tu3ryZPnqykpCS98sorioqKynf6cQmDCAAAAKAYOHnypB577DGdO3dO1apVU9u2bfXTTz+pWrVqkqSpU6fKy8tLPXr0kNVqVceOHTV9+nTH88uUKaNly5Zp4MCBCg8Pl6+vryIjIzV+/HjDtVjsdru9wL6yIqJWYGOzS4AHpfx53uwS4EENA2qaXQI8aH96otklACgk1qwTZpdwVSduu9dj71VzW5z7TkUQayIAAAAAGMJ0JgAAAMBJyZunU/BIIgAAAAAYQhIBAAAAOLHbLGaXUOSRRAAAAAAwhCQCAAAAcEIS4R5JBAAAAABDGEQAAAAAMITpTAAAAIATtnh1jyQCAAAAgCEkEQAAAIATFla7RxIBAAAAwBCSCAAAAMCJ3U4S4Q5JBAAAAABDSCIAAAAAJ3ab2RUUfSQRAAAAAAwhiQAAAACc2FgT4RZJBAAAAABDSCIAAAAAJ+zO5B5JBAAAAABDSCIAAAAAJ5xY7R5JBAAAAABDSCIAAAAAJ3a72RUUfSQRAAAAAAwhiQAAAACcsCbCveseRGRnZyslJUU2m+u54LVq1frbRQEAAAAougwPIo4cOaJ+/fpp8+bNLu12u10Wi0V5eXkFVhwAAADgaZxY7Z7hQcSTTz4pb29vLVu2TNWrV5fFwjcZAAAAKE0MDyJ27dqlhIQENWjQoDDqAQAAAFDEGR5EhIWF6ezZs4VRCwAAAGA6O9OZ3MrXFq8ZGRmO6/XXX9dLL72kdevW6dy5cy73MjIyCrteAAAAACbLVxIREBDgsvbBbrfr3nvvdenDwmoAAACUBBw2516+BhFr164t7DoAAAAAFBP5GkS0a9fO8d+JiYmqWbPmZbsy2e12nThxomCrAwAAADyMLV7dy9eaCGd169ZVamrqZe1paWmqW7dugRQFAAAAoOgyvDvTpbUP/+vChQsqX758gRQFAAAAmIXdmdzLdxIRHR2t6OhoWSwWjRo1yvE4OjpaL7zwgh599FE1a9asEEuFJAVXD9LbM2P08y8/6vCpbVq18Rs1aRbm0qf+zXX18efTtPfXzTp4You+W/2FQm8MMali/B1t296ur7/+RMeObVNWVqK6dOlw1b7vvjtRWVmJGjSovwcrxN/Rok1TvT3vda3a9a12Jm3SPzvddVmfgS89rVU/f6v442s0c+HbqlW3hsv9WjfV1NQ5k7Rm3/f68cgqffLtdLW6s4WnvgT8DW3bttY3X3+i48e2y5p1Qg916ei45+3trdcmjFTC9lilnTuk48e26+OPp6p69WATK8bfca3PW5K6du2k75d9rtOndsuadUJNmoRd5ZWAoiHfg4idO3dq586dstvt2rNnj+Pxzp07dfDgQTVt2lRz5swpxFLh7++nb5bPU25urp7oOVD3hnfTq6Pe0Pn0/26tW7tODX39wzwdPXJcj3bpp4539dC0Nz+Q1ZptYuW4XhUrVtSePfs1ZMgr1+z30EMddfvtzXXqVJKHKkNBqFCxgg7v+0UxI6dc8f6Tg3rrsf4Pa+JLb+iJBwborz+z9P6Ct1TOp5yjz7RPJ6uMdxn9v4efV+8O/XR4/y+a9ulkVakW6KkvA9fJt2IF7d5zQC9c4f/fFStWUPPmjTQx5h21aXO/Hu01QDf/o56+/uoTEypFQbjW5y1Jvr4VtWnzVv3nlYkergxXYrd77iqu8j2d6dIOTU899ZTeeecd+fn5FVpRuLKBL/TTmVNJGjZolKPtROIplz7DX3lea2N/1MSxUx1tv/160mM1omCtWrVOq1atu2af0NBgvfXWeHXp0ldLlsz2TGEoEJvW/KRNa3666v3HB/TUrLfnat3KjZKkUYNf1eo93+meTndp5bdxCgj0V+16tTQuepKOHDgqSZo2YaYefaqH6je4SedS0zzydeD6rFy1Tiuv8v/vjIw/9EDn3i5tQ4aO0uZNy1SzZqhOnDjtgQpRkK71eUvS/PnfSJJq165x1T5AUWJ4YfXs2bMZQJjkvvv/qd279mvG7CnacWidfli3UI890cNx32KxqP19d+vY0d/06VcztePQOn0b+7k6PNDexKpRmCwWiz755G1NnfqBDhw4bHY5KEA31gpVteCq2rJhu6Ptwh+Z2rtzv5q0aiRJSk87r+NHftODj3RS+YrlVaZMGfV4oqvOpaZp/+5DZpWOQuLvX1k2m03p6RzsChQ2m93isau4Mrywun37a/9CumbNGkOv99dffykhIUGBgYEKC3Od/5eVlaWFCxfqiSeeuOrzrVarrFarS5vdbpPFYnh8VOTVrF1DfZ7qqY+mz9N7b81S0xaNNC5mhHKyc/TVgqWqWi1QlSr76rkX+umNie8pZuxU/fPetvpw3lQ9+lB/bdm83f2boFgZNuw55ebm6f33meJQ0lQNujgdKe1/0oRzqWmqElTF8fjZni9o6pxJ2vRLrGw2m34/m66ox6L1x/k/PFovCpePj49emzBSXy78Vn/8ccHscgDA+CCiadOmLo9zcnK0a9cu7d27V5GRkYZe6/Dhw+rQoYMSExNlsVjUtm1bLViwQNWrV5cknT9/Xk899dQ1BxExMTEaN26cS5tf+Wryr1DyFp95eXlp9659mjxhmiRp356DuqVBffV+qqe+WrBUXl4XB06rlq/TxzM+lSTt33tILW9vqj5PPcIgooRp3ryxoqKeUnh4Z7NLgYlGxryotLO/q1/X52TNsupfvbvonXmT1afT0zqbcs7s8lAAvL29Nf/zGbJYLBo8+N9mlwOUCuzO5J7hQcTUqVOv2D527FhduGDsX0defvllNWrUSNu3b1d6erqGDBmiO++8U+vWrVOtWrXy9RojR45UdHS0S9uttcMN1VFcpCSn6sihoy5tRw4f0/1dIiRJaed+V05OzmV9fjl8XLe1ae6xOuEZd955u4KCqurIkXhHm7e3t15//RUNHtxPt9xyp4nV4e86m3IxgQisFugyGKhSLVCH9h6RJN3etqXuuu8OtbulkzIv/ClJihkxRW3uvk1det6v2e995vnCUaAuDSBq1bpRHTs9SgoBoMgwPIi4mj59+uj222/Xm2++me/nbN68WatXr1bVqlVVtWpVfffdd3ruued01113ae3atfL19XX7Gj4+PvLx8XFpK4lTmSRp+5Zdqle/jkvbTfXr6OTJM5KknJxc/bxz32V96tarrZMnznioSnjK/Plfa82aH13avvvuM82f/43mzVtoUlUoKKcSTys1+axa39VSh/ddHDT4VqqoRs3DtGjOYklS+QoXz+ax2Vy397DZ7LJ4lcyfg6XJpQFE/fp11aFjT6WlpZtdElBqFOe1Cp5SYIOI+Ph4w4fN/fXXX/L2/m8JFotFM2bM0KBBg9SuXTvNnz+/oMorET6aMU+LV3yqqKFPa9mSlWrWorEef6KHRgwd7+jzwbuz9f7Hb2pLfII2/7hV/7y3rSI6tdOjXfqZWDmul69vRdWrV8fxuE6dmmrSJEy//56uEydOX/ZLRW5ujpKTU3XkyDHPForrUqFiBdV0OvfhxlqhuvnWfygjPUNJp5I1f9ZCPT0kUonHTupU4mk99/IApSaf1doVFwePuxP2KiP9D7067RV9+NZsZWVZ1b3PQ7qxVnVtXL3ZrC8L+XSt/3+fOZOiBV98oGbNG+lf/3pSZcqUUXBwNUlSWlq6cnJyTKoa18vdz/MbbghQzZqhCv2/s0BuvrmeJCk5OVXJyalmlAxck8VuN7ZDbffu3V0e2+12nTlzRtu3b9eoUaM0ZsyYfL/W7bffrsGDB6tv376X3Rs0aJA+//xzZWRkKC8vz0iJqhXY2FD/4uTeDnfr5dFDVOemWjqReEofTZ+nL+Z97dKnZ+9uihrytKqHBuvoL7/qrUnTFbt8rUkVF76UP8+bXUKhufvuNlq16vJU4dNPF2nAgBcvaz90aJPeffcTvffex54ozxQNA2qaXUKBaXlHc330zXuXtS/98geNeeE1SRcPm+ve5yFV9qukXVt3a+KIKUo8dsLRN6xpA0WNeEZhTRvIu6y3jh06rg/fmn3NrWOLk/3piWaXUGjuvruNYlctuqx93qeLNGHCWzp8KP4Kz5Lu6/CINmwoGZ9vaXKtz3vAgGj17fuIPpr11mX3X53wliZMuPJU8uLOmnXCfSeT/BTa3X2nAtLm9Dcee6+CZHgQ8dRTT7k89vLyUrVq1dS+fXt16HD103SvJCYmRj/++KN++OGHK95/7rnnNHPmTNlsNkOvW5IHEbhcSR5E4HIlaRAB90ryIAIo7RhEXFQqBhF5eXnatGmTGjdurBtuuKEw6/pbGESULgwiShcGEaULgwig5GIQcVFxHUQYWnlXpkwZdejQQenp6YVUDgAAAGAuDptzz/D2HY0aNdKxYyzaBAAAAEorw4OICRMmaNiwYVq2bJnOnDmjjIwMlwsAAAAozux2i8eu4irfW7yOHz9eL774oh544AFJ0kMPPSSL5b9fuN1ul8ViMbyTEgAAAIDiJd9JxLhx45SZmam1a9c6rjVr1jiuS48BAACA4szmwet6TZo0SRaLRUOGDHG0ZWVlKSoqSlWqVFGlSpXUo0cPJScnuzwvMTFRnTt3VsWKFRUUFKThw4crNzfX8PvnO4m4tIlTu3btDL8JAAAAgIKxbds2ffDBB2rSpIlL+9ChQ/X9999r0aJF8vf316BBg9S9e3dt2rRJ0sWdVjt37qyQkBBt3rxZZ86c0RNPPKGyZctq4sSJhmowtCbCefoSAAAAUBLZZfHYZdSFCxfUu3dvzZo1y+XIhfPnz+vjjz/WW2+9pfbt26tly5aaPXu2Nm/erJ9+unhA5apVq7R//3599tlnatasme6//369+uqrev/995WdnW2oDkODiJtvvlmBgYHXvAAAAADkj9VqvWyjIqvVetX+UVFR6ty5syIiIlzaExISlJOT49LeoEED1apVS/Hx8ZKk+Ph4NW7cWMHBwY4+HTt2VEZGhvbt22eo7nxPZ5Iurovw9/c39AYAAABAcWLL91HMf19MTIzGjRvn0jZmzBiNHTv2sr4LFizQjh07tG3btsvuJSUlqVy5cgoICHBpDw4OVlJSkqOP8wDi0v1L94wwNIjo1auXgoKCDL0BAAAAgCsbOXKkoqOjXdp8fHwu63fixAm98MILio2NVfny5T1V3lXlezoT6yEAAABQGthk8djl4+MjPz8/l+tKg4iEhASlpKSoRYsW8vb2lre3t9avX69p06bJ29tbwcHBys7OVnp6usvzkpOTFRISIkkKCQm5bLemS48v9cmvfA8iLu3OBAAAAMCz7r33Xu3Zs0e7du1yXK1atVLv3r0d/122bFnFxcU5nnPo0CElJiYqPDxckhQeHq49e/YoJSXF0Sc2NlZ+fn4KCwszVE++pzPZbH9nJ1sAAACgeLieXZMKW+XKldWoUSOXNl9fX1WpUsXR3r9/f0VHRyswMFB+fn4aPHiwwsPD1aZNG0lShw4dFBYWpr59+2ry5MlKSkrSK6+8oqioqCumH9diaE0EAAAAgKJp6tSp8vLyUo8ePWS1WtWxY0dNnz7dcb9MmTJatmyZBg4cqPDwcPn6+ioyMlLjx483/F4Wewmcp1QrsLHZJcCDUv48b3YJ8KCGATXNLgEetD890ewSABQSa9YJs0u4qtjgRz32Xvclf+mx9ypIhs6JAAAAAACmMwEAAABOiuKaiKKGJAIAAACAISQRAAAAgBP2JHWPJAIAAACAIQwiAAAAABjCdCYAAADACdOZ3COJAAAAAGAISQQAAADghC1e3SOJAAAAAGAISQQAAADgxEYQ4RZJBAAAAABDSCIAAAAAJzbWRLhFEgEAAADAEJIIAAAAwInd7AKKAZIIAAAAAIaQRAAAAABOOLHaPZIIAAAAAIaQRAAAAABObBZ2Z3KHJAIAAACAISQRAAAAgBN2Z3KPJAIAAACAISQRAAAAgBN2Z3KPJAIAAACAIQwiAAAAABjCdCYAAADAiY0dXt0iiQAAAABgCEkEAAAA4MQmogh3SCIAAAAAGEISAQAAADjhsDn3SCIAAAAAGEISAQAAADhhdyb3SuQg4syFNLNLgAcROZYuB9JPmF0CPMjC4sZSJc+WZ3YJAPKpRA4iAAAAgOtlM7uAYoA1EQAAAAAMIYkAAAAAnDBV2j2SCAAAAACGkEQAAAAATtidyT2SCAAAAACGkEQAAAAATtidyT2SCAAAAACGkEQAAAAATkgi3COJAAAAAGAISQQAAADgxM7uTG6RRAAAAAAwhEEEAAAAAEOYzgQAAAA4YWG1eyQRAAAAAAwhiQAAAACckES4RxIBAAAAwBCSCAAAAMCJ3ewCigGSCAAAAACGkEQAAAAATmwcNucWSQQAAABQDMyYMUNNmjSRn5+f/Pz8FB4eruXLlzvuZ2VlKSoqSlWqVFGlSpXUo0cPJScnu7xGYmKiOnfurIoVKyooKEjDhw9Xbm6u4VoYRAAAAABObB68jKhRo4YmTZqkhIQEbd++Xe3bt1fXrl21b98+SdLQoUP13XffadGiRVq/fr1Onz6t7t27O56fl5enzp07Kzs7W5s3b9bcuXM1Z84cjR492vD3yGK320vc2pGy5W40uwR4UIn7A4xr8vYqY3YJAApJni3P7BLgQTnZp8wu4aqm1urjsfcamvjZ33p+YGCg3njjDT388MOqVq2a5s+fr4cffliSdPDgQTVs2FDx8fFq06aNli9frgcffFCnT59WcHCwJGnmzJl6+eWXlZqaqnLlyuX7fUkiAAAAACeeTCKsVqsyMjJcLqvV6rbGvLw8LViwQJmZmQoPD1dCQoJycnIUERHh6NOgQQPVqlVL8fHxkqT4+Hg1btzYMYCQpI4dOyojI8ORZuQXgwgAAADAJDExMfL393e5YmJirtp/z549qlSpknx8fPTss89q8eLFCgsLU1JSksqVK6eAgACX/sHBwUpKSpIkJSUluQwgLt2/dM8IdmcCAAAAnHhyqvTIkSMVHR3t0ubj43PV/rfccot27dql8+fP66uvvlJkZKTWr19f2GVehkEEAAAAYBIfH59rDhr+V7ly5VS/fn1JUsuWLbVt2za98847evTRR5Wdna309HSXNCI5OVkhISGSpJCQEG3dutXl9S7t3nSpT34xnQkAAABwYrN47vrbtdpsslqtatmypcqWLau4uDjHvUOHDikxMVHh4eGSpPDwcO3Zs0cpKSmOPrGxsfLz81NYWJih9yWJAAAAAIqBkSNH6v7771etWrX0xx9/aP78+Vq3bp1Wrlwpf39/9e/fX9HR0QoMDJSfn58GDx6s8PBwtWnTRpLUoUMHhYWFqW/fvpo8ebKSkpL0yiuvKCoqylAaIjGIAAAAAFwYPb/BU1JSUvTEE0/ozJkz8vf3V5MmTbRy5Urdd999kqSpU6fKy8tLPXr0kNVqVceOHTV9+nTH88uUKaNly5Zp4MCBCg8Pl6+vryIjIzV+/HjDtXBOBIq9EvcHGNfEORFAycU5EaVLUT4nYlJtz50TMeK3v3dOhFlYEwEAAADAEKYzAQAAAE6Y5eAeSQQAAAAAQ0giAAAAACc2sgi3SCIAAAAAGEISAQAAADgpqlu8FiUkEQAAAAAMIYkAAAAAnLAiwj2SCAAAAACGkEQAAAAATlgT4R5JBAAAAABDSCIAAAAAJzaL2RUUfSQRAAAAAAwhiQAAAACccGK1eyQRAAAAAAwhiQAAAACckEO4RxJRwgwfHqWc7FOa8uY4s0tBIXj5pUGK3/y9fj93SKdP/qyvv/pYN99cz+yyUEDatr1dX3/9iY4d26asrER16dLB5f6sWVOUlZXoci1dOs+kavF38XmXbqNGRSsn+5TLtWfPerPLAvKNJKIEadWyqQY83Ue7d+83uxQUkrvvaqMZM+Zqe8IueXt7a8L4EVr+/Xw1bvpP/fnnX2aXh7+pYsWK2rNnv+bO/VILF866Yp+VK9fqmWeGOR5brdmeKg8FjM8be/cdVKdOvRyPc3NzTawGzjgnwj0GESWEr29FzZ33np4d+JL+PfJ5s8tBIencpY/L435PD1HS6T1q2aKJfty4xaSqUFBWrVqnVavWXbOP1Zqt5ORUzxSEQsXnjbzcPD5fFFtMZyoh3p02Uct/iNOaNT+aXQo8yN/fT5KU9nu6uYXAY+6+u40SE3do9+61mjbtNQUGBphdEgoRn3fJVr9+Xf32a4IOHdyseXPfVc2aoWaXhP9jk91jV3FFElEC9Oz5kJo3b6Q24Z3NLgUeZLFY9Nab47Rp01bt23fI7HLgAatWrdOSJSv066+Juumm2ho//mV9++08tWvXTTYb4XtJw+ddsm3dulP9nx6qw4ePKiQkSKNeidbaNYvVrHl7XbiQaXZ5gFumDyIOHDign376SeHh4WrQoIEOHjyod955R1arVX369FH79u2v+Xyr1Sqr1erSZrfbZbGUjqMGa9QI1VtTxuv+Bx677PuAku3daRN16623qN09/zK7FHjIokXfOf57375D2rv3oA4c2Kh27cK1du0mEytDYeDzLtlWrlzr+O89ew5o69adOvrLFj3ycBfNnrPAxMqA/DF1OtOKFSvUrFkzDRs2TM2bN9eKFSt0991365dfftFvv/2mDh06aM2aNdd8jZiYGPn7+7tcNtsfHvoKzNeiRWMFB1fT1i0r9Nefv+mvP39Tu3Z3aNCgfvrrz9/k5cWMtZLonbcnqPMDEYro8IhOnTpjdjkwyfHjiUpNPad69eqYXQo8gM+7ZDt/PkNHjhxTvfp1zC4FurjFq6eu4srU3zDHjx+v4cOH69y5c5o9e7Yef/xxDRgwQLGxsYqLi9Pw4cM1adKka77GyJEjdf78eZfLy6uyh74C861Zs1HNmrdXq9s6OK7t23fpiy8Wq9VtHYi8S6B33p6gbl076b6OPfXrryfMLgcmuvHGEFWpcoPOnEkxuxR4AJ93yebrW1E33VRbSXy+KCZMnc60b98+zZt3cc/rnj17qm/fvnr44Ycd93v37q3Zs2df8zV8fHzk4+Pj0lZapjJJ0oULmZfNh8/M/FPnzv3OPPkS6N1pE/VYr27q3qOf/vjjgoKDq0mSzp//Q1lZWSZXh7/L17eiy78y16lTU02ahOn339OVlpau//xniJYsWa7k5FTddFNtvfbav3X06K+KjWVv+eKIz7t0e33SKC37PlaJiScVWj1Eo0e/qLw8mxZ8ucTs0iC2eM0P09dEXPqF38vLS+XLl5e/v7/jXuXKlXX+/HmzSgOKnIHPRkqS1sR97dLer/9Qzft0oRkloQC1bNlEq1b993N8440xkqRPP12kwYP/rcaNG6pPn4cVEOCnM2eStXr1jxo37k1lZ3N2QHHE51263Vijuj779H1VqXKDUlPTtGnzVrW9q4vOnk0zuzQgXyx2u9206VhNmzbV66+/rk6dOkmS9u7dqwYNGsjb++LY5scff1RkZKSOHTtm6HXLlruxwGtF0VWc5xPCOG+vMmaXAKCQ5NnyzC4BHpSTfcrsEq4quk4v950KyFu/Fs+F9KYmEQMHDlRe3n9/YDRq1Mjl/vLly93uzgQAAADAs0xNIgoLSUTpUuL+AOOaSCKAkoskonQpyknEUA8mEVOLaRLB/p8AAAAADDF9YTUAAABQlLA7k3skEQAAAAAMIYkAAAAAnNhZcekWSQQAAAAAQ0giAAAAACesiXCPJAIAAACAISQRAAAAgBMbayLcIokAAAAAYAhJBAAAAOCEHMI9kggAAAAAhjCIAAAAAGAI05kAAAAAJyysdo8kAgAAAIAhJBEAAACAEw6bc48kAgAAAIAhJBEAAACAEztrItwiiQAAAABgCEkEAAAA4IQ1Ee6RRAAAAAAwhCQCAAAAcMKaCPdIIgAAAAAYQhIBAAAAOGFNhHskEQAAAEAxEBMTo9tuu02VK1dWUFCQunXrpkOHDrn0ycrKUlRUlKpUqaJKlSqpR48eSk5OdumTmJiozp07q2LFigoKCtLw4cOVm5trqBYGEQAAAIATm93uscuI9evXKyoqSj/99JNiY2OVk5OjDh06KDMz09Fn6NCh+u6777Ro0SKtX79ep0+fVvfu3R338/Ly1LlzZ2VnZ2vz5s2aO3eu5syZo9GjRxuqxWK3G6y+GChb7kazS4AHlbg/wLgmb68yZpcAoJDk2fLMLgEelJN9yuwSrqpv7e7uOxWQT3/75rqfm5qaqqCgIK1fv1533323zp8/r2rVqmn+/Pl6+OGHJUkHDx5Uw4YNFR8frzZt2mj58uV68MEHdfr0aQUHB0uSZs6cqZdfflmpqakqV65cvt6bJAIAAABwYvfg9XecP39ekhQYGChJSkhIUE5OjiIiIhx9GjRooFq1aik+Pl6SFB8fr8aNGzsGEJLUsWNHZWRkaN++ffl+bxZWAwAAACaxWq2yWq0ubT4+PvLx8bnm82w2m4YMGaI777xTjRo1kiQlJSWpXLlyCggIcOkbHByspKQkRx/nAcSl+5fu5RdJBAAAAODEJrvHrpiYGPn7+7tcMTExbmuMiorS3r17tWDBAg98Ry5HEgEAAACYZOTIkYqOjnZpc5dCDBo0SMuWLdOGDRtUo0YNR3tISIiys7OVnp7ukkYkJycrJCTE0Wfr1q0ur3dp96ZLffKDJAIAAABwYvfg/3x8fOTn5+dyXW0QYbfbNWjQIC1evFhr1qxR3bp1Xe63bNlSZcuWVVxcnKPt0KFDSkxMVHh4uCQpPDxce/bsUUpKiqNPbGys/Pz8FBYWlu/vEUkEAAAAUAxERUVp/vz5+vbbb1W5cmXHGgZ/f39VqFBB/v7+6t+/v6KjoxUYGCg/Pz8NHjxY4eHhatOmjSSpQ4cOCgsLU9++fTV58mQlJSXplVdeUVRUlNsExBlbvKLYK3F/gHFNbPEKlFxs8Vq6FOUtXh+r3c1j7/XFb0vy3ddisVyxffbs2XryySclXTxs7sUXX9QXX3whq9Wqjh07avr06S5TlX777TcNHDhQ69atk6+vryIjIzVp0iR5e+c/X2AQgWKvxP0BxjUxiABKLgYRpUtRHkQ86sFBxJcGBhFFCWsiAAAAABjCmggAAADAiY15Dm6RRAAAAAAwhCQCAAAAcGIniXCLJAIAAACAISQRAAAAgBOb2QUUAyQRAAAAAAwhiQAAAACclMBj1AocSQQAAAAAQ0giAAAAACecE+EeSQQAAAAAQ0giAAAAACfszuQeSQQAAAAAQ0giABQrNjv/PlSasENK6VLGq4zZJQCSOLE6P0giAAAAABhCEgEAAAA4YXcm90giAAAAABjCIAIAAACAIUxnAgAAAJywqYN7JBEAAAAADCGJAAAAAJywmbh7JBEAAAAADCGJAAAAAJxw2Jx7JBEAAAAADCGJAAAAAJxw2Jx7JBEAAAAADCGJAAAAAJxwToR7JBEAAAAADCGJAAAAAJywJsI9kggAAAAAhpBEAAAAAE44J8I9kggAAAAAhpBEAAAAAE5s7M7kFkkEAAAAAENIIgAAAAAn5BDukUQAAAAAMIRBBAAAAABDmM4EAAAAOOGwOfdIIgAAAAAYQhIBAAAAOCGJcI8kAgAAAIAhJBEAAACAEzuHzblFEgEAAADAEJIIAAAAwAlrItwjiQAAAABgCEkEAAAA4MROEuEWSQQAAAAAQ0giAAAAACfszuQeSQQAAAAAQ0giAAAAACfszuQeSQQAAAAAQ0giAAAAACesiXCPJAIAAACAIQwiAAAAACc22T12GbFhwwZ16dJFoaGhslgsWrJkict9u92u0aNHq3r16qpQoYIiIiJ05MgRlz5paWnq3bu3/Pz8FBAQoP79++vChQuGv0cMIgAAAIBiIDMzU02bNtX7779/xfuTJ0/WtGnTNHPmTG3ZskW+vr7q2LGjsrKyHH169+6tffv2KTY2VsuWLdOGDRv0zDPPGK7FYi+Bk77KlrvR7BLgQSXuDzCuyctiMbsEeFAJ/CsK11DGq4zZJcCDsrISzS7hqpqEhHvsvXYnxV/X8ywWixYvXqxu3bpJuvjzMjQ0VC+++KKGDRsmSTp//ryCg4M1Z84c9erVSwcOHFBYWJi2bdumVq1aSZJWrFihBx54QCdPnlRoaGi+358kAgAAADCJ1WpVRkaGy2W1Wg2/zvHjx5WUlKSIiAhHm7+/v1q3bq34+IsDlfj4eAUEBDgGEJIUEREhLy8vbdmyxdD7MYgAAAAATBITEyN/f3+XKyYmxvDrJCUlSZKCg4Nd2oODgx33kpKSFBQU5HLf29tbgYGBjj75xRavAAAAgBObB6dSjhw5UtHR0S5tPj4+Hnv/68UgAgAAADCJj49PgQwaQkJCJEnJycmqXr26oz05OVnNmjVz9ElJSXF5Xm5urtLS0hzPzy+mMwEAAABO7B78X0GpW7euQkJCFBcX52jLyMjQli1bFB5+caF4eHi40tPTlZCQ4OizZs0a2Ww2tW7d2tD7MYgoYYYPj1JO9ilNeXOc2aWgEA18NlK/HP5JFzKOavPG73Rbq2Zml4RCUqmSr958c6yOHP5J59N/0fp1S9SyZVOzy4IH8PO8ZGnb9nZ9/fUnOnZsm7KyEtWlSweX+7NmTVFWVqLLtXTpPJOqRVF14cIF7dq1S7t27ZJ0cTH1rl27lJiYKIvFoiFDhmjChAlaunSp9uzZoyeeeEKhoaGOHZwaNmyoTp06acCAAdq6das2bdqkQYMGqVevXoZ2ZpKYzlSitGrZVAOe7qPdu/ebXQoK0SOPPKQ33xij56JGaOu2nXp+8NP64fvPFdbobqWmnjO7PBSwD2a+oVtvvUVP9XtBZ84k6/HHumvF8i/UtFl7nT5tbBEcig9+npc8FStW1J49+zV37pdauHDWFfusXLlWzzwzzPHYas32VHn4H55cE2HE9u3bdc899zgeX1pLERkZqTlz5uill15SZmamnnnmGaWnp6tt27ZasWKFypcv73jO559/rkGDBunee++Vl5eXevTooWnTphmupcidE2G322X5m/vAl8ZzInx9K2rr1pUaPPjf+vfI5/Xzz/v14rAxZpflEUXqD7AHbN74nbZt/1kvDHlF0sV9on89tk3vT5+tyW9c+fCZkqQ0nRNRvnx5pZ07qB4P99Py5Wsc7T/F/6CVK9dqzNg3TKzOM4rYX1EeUZp/npeWcyKyshL1yCNP67vvVjnaZs2aIn9/P/XsOcDEyjyrKJ8T0TDodo+914GUrR57r4JU5KYz+fj46MCBA2aXUey8O22ilv8QpzVrfjS7FBSismXLqkWLJopz+pztdrvi1mxUmzYtTawMhcHbu4y8vb2VleW6X/hff2Xpjjs89xccPIuf56XX3Xe3UWLiDu3evVbTpr2mwMAAs0sqtYrjmghPM2060/9uZXVJXl6eJk2apCpVqkiS3nrrLU+WVSz17PmQmjdvpDbhnc0uBYWsatVAeXt7KyX5rEt7SkqqGtxSz6SqUFguXMhUfPx2/XvkEB08+IuSk1PV69FuatOmpY4e/dXs8lAI+Hleeq1atU5LlqzQr78m6qabamv8+Jf17bfz1K5dN9lsNrPLAy5j2iDi7bffVtOmTRUQEODSbrfbdeDAAfn6+uZrWpPVar3sVL+CmBJVXNSoEaq3pozX/Q88dl2nGwIo2p7q94I+/GCKfvs1Qbm5udq5c6++/PJbtWjR2OzSUMD4eV66LVr0neO/9+07pL17D+rAgY1q1y5ca9duMrGy0qmorokoSkwbREycOFEffvihpkyZovbt2zvay5Ytqzlz5igsLCxfrxMTE6Nx41x3rrB4VVKZMn4FWm9R1aJFYwUHV9PWLSscbd7e3rrrrjZ67rkn5VupLv+CUYKcPZum3NxcBQVXdWkPCqqmpORUk6pCYTp27DdF3PewKlasID+/ykpKStHnn03XseNFdy4xrg8/z+Hs+PFEpaaeU716dRhEoEgybU3EiBEj9OWXX2rgwIEaNmyYcnJyrut1Ro4cqfPnz7tcXl6VC7jaomvNmo1q1ry9Wt3WwXFt375LX3yxWK1u68BfOCVMTk6OduzYrfb3tHW0WSwWtb+nrX76KeEaz0Rx9+effykpKUUBAf667752LgsyUTLw8xzObrwxRFWq3KAzZ1Lcd0aBY02Ee6Zu8XrbbbcpISFBUVFRatWqlT7//HPD05CudMpfaZnKJF2cM71v3yGXtszMP3Xu3O+XtaNkmPrOLM3+eKoSduzWtm079fzgAfL1raA5c780uzQUgvvuayeLxaLDh4+qXr06mhTzig4dOqq5fN4lDj/PSzZf34qqV6+O43GdOjXVpEmYfv89XWlp6frPf4ZoyZLlSk5O1U031dZrr/1bR4/+qtjY9eYVDVyD6edEVKpUSXPnztWCBQsUERGhvLw8s0sCirRFi5aqWtVAjR09TCEh1fTzz/vU+cE+Skk56/7JKHb8/Srr1QkjVOPG6kpLS9fiJcs1evTrys3NNbs0AAa0bNlEq1YtdDx+442L2/Z++ukiDR78bzVu3FB9+jysgAA/nTmTrNWrf9S4cW8qO5uzIszAmgj3itQ5ESdPnlRCQoIiIiLk6+t73a9TGs+JKM2KzB9geERpOicCpfOciNKstJwTgYuK8jkR9aq28Nh7HT27w2PvVZBMTyKc1ahRQzVq1DC7DAAAAJRixXmtgqcUucPmAAAAABRtRSqJAAAAAMxmt7MbmjskEQAAAAAMYRABAAAAwBCmMwEAAABObCysdoskAgAAAIAhJBEAAACAE86ocY8kAgAAAIAhJBEAAACAE9ZEuEcSAQAAAMAQkggAAADACWsi3COJAAAAAGAISQQAAADgxEYS4RZJBAAAAABDSCIAAAAAJ3Z2Z3KLJAIAAACAISQRAAAAgBN2Z3KPJAIAAACAISQRAAAAgBNOrHaPJAIAAACAISQRAAAAgBPWRLhHEgEAAADAEJIIAAAAwAknVrtHEgEAAADAEAYRAAAAAAxhOhMAAADghIXV7pFEAAAAADCEJAIAAABwwmFz7pFEAAAAADCEJAIAAABwwpoI90giAAAAABhCEgEAAAA44bA590giAAAAABhCEgEAAAA4sbM7k1skEQAAAAAMIYkAAAAAnLAmwj2SCAAAAACGkEQAAAAATjgnwj2SCAAAAACGkEQAAAAATtidyT2SCAAAAACGkEQAAAAATlgT4R5JBAAAAABDGEQAAAAAxcj777+vOnXqqHz58mrdurW2bt3q8RoYRAAAAABO7Ha7xy6jvvzyS0VHR2vMmDHasWOHmjZtqo4dOyolJaUQvhNXZ7GXwElfZcvdaHYJ8KAS9wcY1+RlsZhdAjyoBP4VhWso41XG7BLgQVlZiWaXcFWe/F0yJ/uUof6tW7fWbbfdpvfee0+SZLPZVLNmTQ0ePFgjRowojBKviCQCAAAAcGL34GVEdna2EhISFBER4Wjz8vJSRESE4uPjr+dLvW7szgQAAACYxGq1ymq1urT5+PjIx8fnsr5nz55VXl6egoODXdqDg4N18ODBQq3zf5XIQYTRWKgksFqtiomJ0ciRI6/4hw4lC5936cLnXbrweZcufN5FU64Hf5ccO3asxo0b59I2ZswYjR071mM1XI8SuSaiNMrIyJC/v7/Onz8vPz8/s8tBIePzLl34vEsXPu/Shc8bRpKI7OxsVaxYUV999ZW6devmaI+MjFR6erq+/fbbwi7XgTURAAAAgEl8fHzk5+fncl0tlSpXrpxatmypuLg4R5vNZlNcXJzCw8M9VbKkEjqdCQAAACiJoqOjFRkZqVatWun222/X22+/rczMTD311FMerYNBBAAAAFBMPProo0pNTdXo0aOVlJSkZs2aacWKFZctti5sDCJKCB8fH40ZM4ZFWaUEn3fpwudduvB5ly583rgegwYN0qBBg0ytgYXVAAAAAAxhYTUAAAAAQxhEAAAAADCEQQQAAAAAQxhEAAAAADCEQUQJ8f7776tOnToqX768Wrdura1bt5pdEgrBhg0b1KVLF4WGhspisWjJkiVml4RCFBMTo9tuu02VK1dWUFCQunXrpkOHDpldFgrJjBkz1KRJE8dhU+Hh4Vq+fLnZZcFDJk2aJIvFoiFDhphdCpAvDCJKgC+//FLR0dEaM2aMduzYoaZNm6pjx45KSUkxuzQUsMzMTDVt2lTvv/++2aXAA9avX6+oqCj99NNPio2NVU5Ojjp06KDMzEyzS0MhqFGjhiZNmqSEhARt375d7du3V9euXbVv3z6zS0Mh27Ztmz744AM1adLE7FKAfGOL1xKgdevWuu222/Tee+9Junj8ec2aNTV48GCNGDHC5OpQWCwWixYvXqxu3bqZXQo8JDU1VUFBQVq/fr3uvvtus8uBBwQGBuqNN95Q//79zS4FheTChQtq0aKFpk+frgkTJqhZs2Z6++23zS4LcIskopjLzs5WQkKCIiIiHG1eXl6KiIhQfHy8iZUBKGjnz5+XdPEXS5RseXl5WrBggTIzMxUeHm52OShEUVFR6ty5s8vf40BxwInVxdzZs2eVl5d32VHnwcHBOnjwoElVAShoNptNQ4YM0Z133qlGjRqZXQ4KyZ49exQeHq6srCxVqlRJixcvVlhYmNlloZAsWLBAO3bs0LZt28wuBTCMQQQAFANRUVHau3evNm7caHYpKES33HKLdu3apfPnz+urr75SZGSk1q9fz0CiBDpx4oReeOEFxcbGqnz58maXAxjGIKKYq1q1qsqUKaPk5GSX9uTkZIWEhJhUFYCCNGjQIC1btkwbNmxQjRo1zC4HhahcuXKqX7++JKlly5batm2b3nnnHX3wwQcmV4aClpCQoJSUFLVo0cLRlpeXpw0bNui9996T1WpVmTJlTKwQuDbWRBRz5cqVU8uWLRUXF+dos9lsiouLYx4tUMzZ7XYNGjRIixcv1po1a1S3bl2zS4KH2Ww2Wa1Ws8tAIbj33nu1Z88e7dq1y3G1atVKvXv31q5duxhAoMgjiSgBoqOjFRkZqVatWun222/X22+/rczMTD311FNml4YCduHCBf3yyy+Ox8ePH9euXbsUGBioWrVqmVgZCkNUVJTmz5+vb7/9VpUrV1ZSUpIkyd/fXxUqVDC5OhS0kSNH6v7771etWrX0xx9/aP78+Vq3bp1WrlxpdmkoBJUrV75sfZOvr6+qVKnCuicUCwwiSoBHH31UqampGj16tJKSktSsWTOtWLHissXWKP62b9+ue+65x/E4OjpakhQZGak5c+aYVBUKy4wZMyRJ//znP13aZ8+erSeffNLzBaFQpaSk6IknntCZM2fk7++vJk2aaOXKlbrvvvvMLg0ALsM5EQAAAAAMYU0EAAAAAEMYRAAAAAAwhEEEAAAAAEMYRAAAAAAwhEEEAAAAAEMYRAAAAAAwhEEEAAAAAEMYRABAEfPkk0+qW7dujsf//Oc/NWTIEI/XsW7dOlksFqWnp3v8vQEARRuDCADIpyeffFIWi0UWi0XlypVT/fr1NX78eOXm5hbq+37zzTd69dVX89WXX/wBAJ7gbXYBAFCcdOrUSbNnz5bVatUPP/ygqKgolS1bViNHjnTpl52drXLlyhXIewYGBhbI6wAAUFBIIgDAAB8fH4WEhKh27doaOHCgIiIitHTpUscUpNdee02hoaG65ZZbJEknTpxQz549FRAQoMDAQHXt2lW//vqr4/Xy8vIUHR2tgIAAValSRS+99JLsdrvLe/7vdCar1aqXX35ZNWvWlI+Pj+rXr6+PP/5Yv/76q+655x5J0g033CCLxaInn3xSkmSz2RQTE6O6deuqQoUKatq0qb766iuX9/nhhx908803q0KFCrrnnntc6gQAwBmDCAD4GypUqKDs7GxJUlxcnA4dOqTY2FgtW7ZMOTk56tixoypXrqwff/xRmzZtUqVKldSpUyfHc6ZMmaI5c+bok08+0caNG5WWlqbFixdf8z2feOIJffHFF5o2bZoOHDigDz74QJUqVVLNmjX19ddfS5IOHTqkM2fO6J133pEkxcTEaN68eZo5c6b27dunoUOHqk+fPlq/fr2ki4Od7t27q0uXLtq1a5eefvppjRgxorC+bQCAYo7pTABwHex2u+Li4rRy5UoNHjxYqamp8vX11UcffeSYxvTZZ5/JZrPpo48+ksVikSTNnj1bAQEBWrdunTp06KC3335bI0eOVPfu3SVJM2fO1MqVK6/6vocPH9bChQsVGxuriIgISdJNN93kuH9p6lNQUJACAgIkXUwuJk6cqNWrVys8PNzxnI0bN+qDDz5Qu3btNGPGDNWrV09TpkyRJN1yyy3as2ePXn/99QL8rgEASgoGEQBgwLJly1SpUiXl5OTIZrPp8ccf19ixYxUVFaXGjRu7rIP4+eef9csvv6hy5cour5GVlaWjR4/q/PnzOnPmjFq3bu245+3trVatWl02pemSXbt2qUyZMmrXrl2+a/7ll1/0559/6r777nNpz87OVvPmzSVJBw4ccKlDkmPAAQDA/2IQAQAG3HPPPZoxY4bKlSun0NBQeXv/98eor6+vS98LFy6oZcuW+vzzzy97nWrVql3X+1eoUMHwcy5cuCBJ+v7773XjjTe63PPx8bmuOgAApRuDCAAwwNfXV/Xr189X3xYtWujLL79UUFCQ/Pz8rtinevXq2rJli+6++25JUm5urhISEtSiRYsr9m/cuLFsNpvWr1/vmM7k7FISkpeX52gLCwuTj4+PEhMTr5pgNGzYUEuXLnVp++mnn9x/kQCAUomF1QBQSHr37q2qVauqa9eu+vHHH3X8+HGtW7dOzz//vE6ePClJeuGFFzRp0iQtWbJEBw8e1HPPPXfNMx7q1KmjyMhI9evXT0uWLHG85sKFCyVJtWvXlsVi0bJly5SamqoLFy6ocuXKGjZsmIYOHaq5c+fq6NGj2rFjh959913NnTtXkvTss8/qyJEjGj58uA4dOqT58+drzpw5hf0tAgAUUwwiAKCQVKxYURs2bFCtWrXUvXt3NWzYUP3791dWVpYjmXjxxRfVt29fRUZGKjw8XJUrV9a//vWva77ujBkz9PDDD+u5555TgwYNNGDAAGVmZkqSbrzxRo0bN04jRoxQcHCwBg0aJEl69dVXNWrUKMXExKhhw4bq1KmTvv/+e9WtW1eSVKtWLX399ddasmSJmjZtqpkzZ2rixImF+N0BABRnFvvVVu8BAAAAwBWQRAAAAAAwhEEEAAAAAEMYRAAAAAAwhEEEAAAAAEMYRAAAAAAwhEEEAAAAAEMYRAAAAAAwhEEEAAAAAEMYRAAAAAAwhEEEAAAAAEMYRAAAAAAwhEEEAAAAAEP+P6BUpr8J/X7fAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84      1015\n",
            "           1       0.11      0.15      0.13       101\n",
            "           2       0.54      0.51      0.53       211\n",
            "           3       0.48      0.37      0.42        41\n",
            "           4       0.42      0.47      0.44        32\n",
            "\n",
            "    accuracy                           0.71      1400\n",
            "   macro avg       0.48      0.47      0.47      1400\n",
            "weighted avg       0.73      0.71      0.72      1400\n",
            "\n",
            "For class 0, Sensitivity: 0.8354679802955665, Specificity: 0.6155844155844156\n",
            "For class 1, Sensitivity: 0.1485148514851485, Specificity: 0.9060816012317167\n",
            "For class 2, Sensitivity: 0.5118483412322274, Specificity: 0.9226240538267452\n",
            "For class 3, Sensitivity: 0.36585365853658536, Specificity: 0.9882266372332598\n",
            "For class 4, Sensitivity: 0.46875, Specificity: 0.9846491228070176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "grmA2x5vW406"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0OulKlKU_m4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ug7vI984UA0E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WTotw6mzRe_e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEUo1d9LRah0"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}