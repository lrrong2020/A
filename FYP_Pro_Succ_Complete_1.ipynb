{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lrrong2020/A/blob/main/FYP_Pro_Succ_Complete_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjeGEXN7MH4C"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwK1YvMFL9Xz",
        "outputId": "4e105742-c1f4-4b73-9a10-d34930ed2938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT_n6JPqMeCj"
      },
      "source": [
        "Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWJglFbYMmEr",
        "outputId": "d75d60d8-2eff-421b-de55-83ba5e8a582b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Kaggle/unzip\n",
            "cp: cannot create regular file '/root/.kaggle/': Not a directory\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Kaggle/unzip/\n",
        "!cp ../kaggle.json /root/.kaggle/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Y1lyGWiJAU"
      },
      "source": [
        "GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqAFoYKfjQHr",
        "outputId": "dc28a19e-e7b0-495e-8a87-5d6af1ac33ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ae879b2e790>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd #For reading csv files.\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt #For plotting.\n",
        "\n",
        "import PIL.Image as Image #For working with image files.\n",
        "\n",
        "#Importing torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset,DataLoader #For working with data.\n",
        "\n",
        "from torchvision import models,transforms #For pretrained models,image transformations.\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "torch.manual_seed(3407)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-dPSwwujHvj",
        "outputId": "14238df0-22dc-473d-bc5a-0c2a62329969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Use GPU if it's available or else use CPU.\n",
        "print(device) #Prints the device we're using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrT4r4xvM09a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjkojF_kawHd",
        "outputId": "4c263300-24d7-49fe-c0ea-61ebe4c53b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.of.training_samples: 25313\n",
            "No.of.testing_samples: 7000\n",
            "No.of.val_samples: 2813\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/gdrive/MyDrive/Kaggle/unzip/\"\n",
        "\n",
        "all_df = pd.read_csv(f\"{path}allLabels.csv\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# subset\n",
        "# sub_df, depre_df = train_test_split(all_df, test_size=0.9, random_state=42)\n",
        "\n",
        "# Assuming train_df is your original training DataFrame\n",
        "train_df, test_df = train_test_split(all_df, test_size=7000, random_state=42)\n",
        "\n",
        "# Now split the remaining training data into training and validation sets\n",
        "train_df, valid_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "print(f'No.of.training_samples: {len(train_df)}')\n",
        "print(f'No.of.testing_samples: {len(test_df)}')\n",
        "print(f'No.of.val_samples: {len(valid_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "yQVZJzjXkBwP",
        "outputId": "da7d6012-cb75-4bf1-a73e-6e7ff3ad7ec6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Histogram of label counts.\n",
        "train_df.level.hist()\n",
        "plt.xticks([0,1,2,3,4])\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYrE034FkXSI",
        "outputId": "efa2dbab-547c-4e92-cfdf-c33865751a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.2725,  2.8506,  1.3249,  7.9601, 10.1455], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "#As you can see,the data is imbalanced.\n",
        "#So we've to calculate weights for each class,which can be used in calculating loss.\n",
        "\n",
        "from sklearn.utils import class_weight #For calculating weights for each class.\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.array([0,1,2,3,4]),y=train_df['level'].values)\n",
        "class_weights = torch.tensor(class_weights,dtype=torch.float).to(device)\n",
        "\n",
        "print(class_weights) #Prints the calculated weights for the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "2CAOhlpYklys",
        "outputId": "a946129b-6465-47fb-e5f1-c13bb3754c8e"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-36f268529b43>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Picks a random number.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}train/{train_df[\"image\"][num]}.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#Image file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#For getting a random image from our training set.\n",
        "num = int(np.random.randint(0,len(train_df)-1,(1,))) #Picks a random number.\n",
        "sample_image = (f'{path}train/{train_df[\"image\"][num]}.jpeg')#Image file.\n",
        "sample_image = Image.open(sample_image)\n",
        "plt.imshow(sample_image)\n",
        "plt.axis('off')\n",
        "plt.title(f'Class: {train_df[\"level\"][num]}') #Class of the random image.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "C8rgUjyom5uS"
      },
      "outputs": [],
      "source": [
        "class dataset(Dataset): # Inherits from the Dataset class.\n",
        "    '''\n",
        "    dataset class overloads the __init__, __len__, __getitem__ methods of the Dataset class.\n",
        "\n",
        "    Attributes :\n",
        "        df:  DataFrame object for the csv file.\n",
        "        data_path: Location of the dataset.\n",
        "        image_transform: Transformations to apply to the image.\n",
        "        train: A boolean indicating whether it is a training_set or not.\n",
        "    '''\n",
        "\n",
        "    def __init__(self,df,data_path,image_transform=None,train=True): # Constructor.\n",
        "        super(Dataset,self).__init__() #Calls the constructor of the Dataset class.\n",
        "        self.df = df\n",
        "        self.data_path = data_path\n",
        "        self.image_transform = image_transform\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df) #Returns the number of samples in the dataset.\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        image_id = self.df['image'][index]\n",
        "        image = Image.open(f'{self.data_path}/{image_id}.jpeg') #Image.\n",
        "        if self.image_transform :\n",
        "            image = self.image_transform(image) #Applies transformation to the image.\n",
        "\n",
        "        if self.train :\n",
        "            label = self.df['level'][index] #Label.\n",
        "            return image,label #If train == True, return image & label.\n",
        "\n",
        "        else:\n",
        "            return image #If train != True, return image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4UsJqLqinRA0"
      },
      "outputs": [],
      "source": [
        "image_transform = transforms.Compose([transforms.Resize([512,512]),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) #Transformations to apply to the image.\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "valid_df = valid_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train_set = dataset(train_df,f'{path}train',image_transform=image_transform)\n",
        "test_set = dataset(test_df,f'{path}train',image_transform=image_transform)\n",
        "valid_set = dataset(valid_df,f'{path}train',image_transform=image_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rm8l4B2Am0Ry"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_set,batch_size=16,shuffle=True, num_workers=4) #DataLoader for train_set.\n",
        "valid_dataloader = DataLoader(valid_set,batch_size=16,shuffle=False, num_workers=4) #DataLoader for validation_set.\n",
        "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SXyKyippyDz",
        "outputId": "4421f4d8-36d2-4e9f-dc83-15f5aa1ffc58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 74.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import resnet50,ResNet50_Weights\n",
        "#Since we've less data, we'll use Transfer learning.\n",
        "model = models.resnet50(weights=ResNet50_Weights.DEFAULT) #Downloads the resnet50 model which is pretrained on Imagenet dataset.\n",
        "# Replace the Final layer of pretrained resnet50 with 2 new layers.\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 5),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r96X5p-_q2YI"
      },
      "outputs": [],
      "source": [
        "model = model.to(device) #Moves the model to the device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYwzKdDzqier"
      },
      "outputs": [],
      "source": [
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "    '''\n",
        "    train function updates the weights of the model based on the\n",
        "    loss using the optimizer in order to get a lower loss.\n",
        "\n",
        "    Args :\n",
        "         dataloader: Iterator for the batches in the data_set.\n",
        "         model: Given an input produces an output by multiplying the input with the model weights.\n",
        "         loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "         optimizer: Updates the model weights.\n",
        "\n",
        "    Returns :\n",
        "         Average loss per batch which is calculated by dividing the losses for all the batches\n",
        "         with the number of batches.\n",
        "    '''\n",
        "\n",
        "    model.train() #Sets the model for training.\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    for batch,(x,y) in enumerate(dataloader): #Iterates through the batches.\n",
        "\n",
        "        output = model(x.to(device)) #model's predictions.\n",
        "        loss   = loss_fn(output,y.to(device)) #loss calculation.\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        total        += y.size(0)\n",
        "        predictions   = output.argmax(dim=1).cpu().detach() #Index for the highest score for all the samples in the batch.\n",
        "        correct      += (predictions == y.cpu().detach()).sum().item() #No.of.cases where model's predictions are equal to the label.\n",
        "        accuracy = 100*(correct/total)\n",
        "\n",
        "        optimizer.zero_grad() #Gradient values are set to zero.\n",
        "        loss.backward() #Calculates the gradients.\n",
        "        optimizer.step() #Updates the model weights.\n",
        "\n",
        "        # x, y = x.cpu(), y.cpu()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Print some information every 10 batches\n",
        "        if batch % 10 == 0:\n",
        "            print(f'Batch {batch}/{len(dataloader)} processed, running loss: {running_loss:.6f}, correct predictions: {correct}, total: {total}')\n",
        "\n",
        "\n",
        "    avg_loss = running_loss/len(dataloader) # Average loss for a single batch\n",
        "\n",
        "    print(f'\\nTraining Loss per batch = {avg_loss:.6f}',end='\\t')\n",
        "    print(f'Accuracy on Training set = {100*(correct/total):.6f}% [{correct}/{total}]') #Prints the Accuracy.\n",
        "\n",
        "    torch.save(model, './DR_ResNet50.pt')\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG6C4yH-qf48"
      },
      "outputs": [],
      "source": [
        "def validate(dataloader,model,loss_fn):\n",
        "    '''\n",
        "    validate function calculates the average loss per batch and the accuracy of the model's predictions.\n",
        "\n",
        "    Args :\n",
        "         dataloader: Iterator for the batches in the data_set.\n",
        "         model: Given an input produces an output by multiplying the input with the model weights.\n",
        "         loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "\n",
        "    Returns :\n",
        "         Average loss per batch which is calculated by dividing the losses for all the batches\n",
        "         with the number of batches.\n",
        "    '''\n",
        "\n",
        "    model.eval() #Sets the model for evaluation.\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    with torch.no_grad(): #No need to calculate the gradients.\n",
        "\n",
        "        for x,y in dataloader:\n",
        "\n",
        "            output        = model(x.to(device)) #model's output.\n",
        "            loss          = loss_fn(output,y.to(device)).item() #loss calculation.\n",
        "            running_loss += loss\n",
        "\n",
        "            total        += y.size(0)\n",
        "            predictions   = output.argmax(dim=1).cpu().detach()\n",
        "            correct      += (predictions == y.cpu().detach()).sum().item()\n",
        "            accuracy = 100*(correct/total)\n",
        "\n",
        "    avg_loss = running_loss/len(dataloader) #Average loss per batch.\n",
        "\n",
        "    print(f'\\nValidation Loss per batch = {avg_loss:.6f}',end='\\t')\n",
        "    print(f'Accuracy on Validation set = {100*(correct/total):.6f}% [{correct}/{total}]') #Prints the Accuracy.\n",
        "\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U661TQ5wqYGU"
      },
      "outputs": [],
      "source": [
        "def optimize(train_dataloader,valid_dataloader,model,loss_fn,optimizer,nb_epochs, patience):\n",
        "    '''\n",
        "    optimize function calls the train & validate functions for (nb_epochs) times.\n",
        "\n",
        "    Args :\n",
        "        train_dataloader: DataLoader for the train_set.\n",
        "        valid_dataloader: DataLoader for the valid_set.\n",
        "        model: Given an input produces an output by multiplying the input with the model weights.\n",
        "        loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "        optimizer: Updates the model weights.\n",
        "        nb_epochs: Number of epochs.\n",
        "\n",
        "    Returns :\n",
        "        Tuple of lists containing losses for all the epochs.\n",
        "    '''\n",
        "    # Initialize the learning rate scheduler\n",
        "    scheduler = StepLR(optimizer, step_size=4, gamma=0.5)\n",
        "\n",
        "    #Lists to store losses for all the epochs.\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    df = pd.DataFrame(columns=['epoch', 'train_loss', 'train_accuracy', 'valid_loss', 'valid_accuracy'])\n",
        "\n",
        "    best_valid_loss = float('inf')\n",
        "    no_improve_epoch = 0\n",
        "\n",
        "    for epoch in range(nb_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{nb_epochs}')\n",
        "        print('-------------------------------')\n",
        "        print(\"Epoch: %d, Learning Rate: %f \" % (epoch, optimizer.param_groups[0]['lr']))\n",
        "        train_loss, train_accuracy = train(train_dataloader,model,loss_fn,optimizer)\n",
        "        valid_loss, valid_accuracy = validate(valid_dataloader,model,loss_fn)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "        print(f'Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "        # Check if the validation loss improved\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            no_improve_epoch = 0\n",
        "\n",
        "            # Change 5: Save the model when validation loss improves\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "            no_improve_epoch += 1\n",
        "\n",
        "        # If the validation loss did not improve for 'patience' epochs, stop training\n",
        "        if no_improve_epoch >= patience:\n",
        "            print(f'Early stopping at epoch {epoch+1}, the validation loss did not improve for the last {patience} epochs')\n",
        "            break\n",
        "\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        scheduler.step()\n",
        "        df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n",
        "\n",
        "\n",
        "    print('\\nTraining has completed!')\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv('training_validation_metrics.csv', index=False)\n",
        "\n",
        "    return train_losses,valid_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "guN3gCYfqFdp",
        "outputId": "0cd6f19b-87ff-4173-d152-08d5d809e3c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/30\n",
            "-------------------------------\n",
            "Epoch: 0, Learning Rate: 0.005000 \n",
            "Batch 0/1583 processed, running loss: 1.642791, correct predictions: 0, total: 16\n",
            "Batch 10/1583 processed, running loss: 18.061366, correct predictions: 20, total: 176\n",
            "Batch 20/1583 processed, running loss: 34.284159, correct predictions: 115, total: 336\n",
            "Batch 30/1583 processed, running loss: 49.992826, correct predictions: 212, total: 496\n",
            "Batch 40/1583 processed, running loss: 66.044379, correct predictions: 252, total: 656\n",
            "Batch 50/1583 processed, running loss: 81.977790, correct predictions: 305, total: 816\n",
            "Batch 60/1583 processed, running loss: 97.340372, correct predictions: 376, total: 976\n",
            "Batch 70/1583 processed, running loss: 111.831909, correct predictions: 500, total: 1136\n",
            "Batch 80/1583 processed, running loss: 128.132394, correct predictions: 595, total: 1296\n",
            "Batch 90/1583 processed, running loss: 143.744915, correct predictions: 698, total: 1456\n",
            "Batch 100/1583 processed, running loss: 159.618642, correct predictions: 817, total: 1616\n",
            "Batch 110/1583 processed, running loss: 175.567172, correct predictions: 908, total: 1776\n",
            "Batch 120/1583 processed, running loss: 191.333777, correct predictions: 1029, total: 1936\n",
            "Batch 130/1583 processed, running loss: 207.234107, correct predictions: 1144, total: 2096\n",
            "Batch 140/1583 processed, running loss: 222.401737, correct predictions: 1243, total: 2256\n",
            "Batch 150/1583 processed, running loss: 237.743470, correct predictions: 1350, total: 2416\n",
            "Batch 160/1583 processed, running loss: 253.743670, correct predictions: 1448, total: 2576\n",
            "Batch 170/1583 processed, running loss: 269.847180, correct predictions: 1484, total: 2736\n",
            "Batch 180/1583 processed, running loss: 285.225234, correct predictions: 1543, total: 2896\n",
            "Batch 190/1583 processed, running loss: 301.101815, correct predictions: 1593, total: 3056\n",
            "Batch 200/1583 processed, running loss: 316.377667, correct predictions: 1632, total: 3216\n",
            "Batch 210/1583 processed, running loss: 331.159502, correct predictions: 1681, total: 3376\n",
            "Batch 220/1583 processed, running loss: 345.734040, correct predictions: 1745, total: 3536\n",
            "Batch 230/1583 processed, running loss: 361.319646, correct predictions: 1833, total: 3696\n",
            "Batch 240/1583 processed, running loss: 375.921426, correct predictions: 1917, total: 3856\n",
            "Batch 250/1583 processed, running loss: 390.989618, correct predictions: 2018, total: 4016\n",
            "Batch 260/1583 processed, running loss: 405.956987, correct predictions: 2113, total: 4176\n",
            "Batch 270/1583 processed, running loss: 420.732368, correct predictions: 2216, total: 4336\n",
            "Batch 280/1583 processed, running loss: 436.372913, correct predictions: 2309, total: 4496\n",
            "Batch 290/1583 processed, running loss: 451.469039, correct predictions: 2376, total: 4656\n",
            "Batch 300/1583 processed, running loss: 466.230953, correct predictions: 2475, total: 4816\n",
            "Batch 310/1583 processed, running loss: 480.852831, correct predictions: 2572, total: 4976\n",
            "Batch 320/1583 processed, running loss: 495.279546, correct predictions: 2668, total: 5136\n",
            "Batch 330/1583 processed, running loss: 509.677136, correct predictions: 2767, total: 5296\n",
            "Batch 340/1583 processed, running loss: 523.841203, correct predictions: 2866, total: 5456\n",
            "Batch 350/1583 processed, running loss: 537.055542, correct predictions: 2962, total: 5616\n",
            "Batch 360/1583 processed, running loss: 551.528127, correct predictions: 3049, total: 5776\n",
            "Batch 370/1583 processed, running loss: 565.579451, correct predictions: 3127, total: 5936\n",
            "Batch 380/1583 processed, running loss: 579.261156, correct predictions: 3185, total: 6096\n",
            "Batch 390/1583 processed, running loss: 592.850722, correct predictions: 3282, total: 6256\n",
            "Batch 400/1583 processed, running loss: 606.786845, correct predictions: 3374, total: 6416\n",
            "Batch 410/1583 processed, running loss: 621.249870, correct predictions: 3464, total: 6576\n",
            "Batch 420/1583 processed, running loss: 635.335695, correct predictions: 3555, total: 6736\n",
            "Batch 430/1583 processed, running loss: 648.969967, correct predictions: 3654, total: 6896\n",
            "Batch 440/1583 processed, running loss: 662.114518, correct predictions: 3755, total: 7056\n",
            "Batch 450/1583 processed, running loss: 675.171864, correct predictions: 3832, total: 7216\n",
            "Batch 460/1583 processed, running loss: 688.886282, correct predictions: 3931, total: 7376\n",
            "Batch 470/1583 processed, running loss: 702.842432, correct predictions: 4040, total: 7536\n",
            "Batch 480/1583 processed, running loss: 718.209386, correct predictions: 4149, total: 7696\n",
            "Batch 490/1583 processed, running loss: 730.906710, correct predictions: 4242, total: 7856\n",
            "Batch 500/1583 processed, running loss: 743.247547, correct predictions: 4341, total: 8016\n",
            "Batch 510/1583 processed, running loss: 757.109256, correct predictions: 4402, total: 8176\n",
            "Batch 520/1583 processed, running loss: 769.299326, correct predictions: 4501, total: 8336\n",
            "Batch 530/1583 processed, running loss: 782.209904, correct predictions: 4603, total: 8496\n",
            "Batch 540/1583 processed, running loss: 795.957470, correct predictions: 4707, total: 8656\n",
            "Batch 550/1583 processed, running loss: 809.108152, correct predictions: 4810, total: 8816\n",
            "Batch 560/1583 processed, running loss: 822.708930, correct predictions: 4908, total: 8976\n",
            "Batch 570/1583 processed, running loss: 837.104435, correct predictions: 5016, total: 9136\n",
            "Batch 580/1583 processed, running loss: 850.753860, correct predictions: 5135, total: 9296\n",
            "Batch 590/1583 processed, running loss: 862.462819, correct predictions: 5208, total: 9456\n",
            "Batch 600/1583 processed, running loss: 876.237302, correct predictions: 5315, total: 9616\n",
            "Batch 610/1583 processed, running loss: 888.556636, correct predictions: 5426, total: 9776\n",
            "Batch 620/1583 processed, running loss: 901.636688, correct predictions: 5540, total: 9936\n",
            "Batch 630/1583 processed, running loss: 915.559227, correct predictions: 5647, total: 10096\n",
            "Batch 640/1583 processed, running loss: 928.131603, correct predictions: 5762, total: 10256\n",
            "Batch 650/1583 processed, running loss: 939.607024, correct predictions: 5861, total: 10416\n",
            "Batch 660/1583 processed, running loss: 951.916904, correct predictions: 5966, total: 10576\n",
            "Batch 670/1583 processed, running loss: 965.316885, correct predictions: 6044, total: 10736\n",
            "Batch 680/1583 processed, running loss: 978.476286, correct predictions: 6118, total: 10896\n",
            "Batch 690/1583 processed, running loss: 989.472892, correct predictions: 6192, total: 11056\n",
            "Batch 700/1583 processed, running loss: 1004.008078, correct predictions: 6273, total: 11216\n",
            "Batch 710/1583 processed, running loss: 1015.568264, correct predictions: 6373, total: 11376\n",
            "Batch 720/1583 processed, running loss: 1027.076197, correct predictions: 6440, total: 11536\n",
            "Batch 730/1583 processed, running loss: 1038.028112, correct predictions: 6500, total: 11696\n",
            "Batch 740/1583 processed, running loss: 1051.162734, correct predictions: 6558, total: 11856\n",
            "Batch 750/1583 processed, running loss: 1064.579412, correct predictions: 6652, total: 12016\n",
            "Batch 760/1583 processed, running loss: 1077.064478, correct predictions: 6739, total: 12176\n",
            "Batch 770/1583 processed, running loss: 1089.826886, correct predictions: 6848, total: 12336\n",
            "Batch 780/1583 processed, running loss: 1102.008817, correct predictions: 6953, total: 12496\n",
            "Batch 790/1583 processed, running loss: 1117.624591, correct predictions: 7062, total: 12656\n",
            "Batch 800/1583 processed, running loss: 1129.731378, correct predictions: 7174, total: 12816\n",
            "Batch 810/1583 processed, running loss: 1141.231424, correct predictions: 7274, total: 12976\n",
            "Batch 820/1583 processed, running loss: 1152.896628, correct predictions: 7372, total: 13136\n",
            "Batch 830/1583 processed, running loss: 1165.641143, correct predictions: 7453, total: 13296\n",
            "Batch 840/1583 processed, running loss: 1176.491906, correct predictions: 7556, total: 13456\n",
            "Batch 850/1583 processed, running loss: 1188.916988, correct predictions: 7649, total: 13616\n",
            "Batch 860/1583 processed, running loss: 1202.574872, correct predictions: 7721, total: 13776\n",
            "Batch 870/1583 processed, running loss: 1215.313246, correct predictions: 7779, total: 13936\n",
            "Batch 880/1583 processed, running loss: 1227.206806, correct predictions: 7844, total: 14096\n",
            "Batch 890/1583 processed, running loss: 1240.684799, correct predictions: 7892, total: 14256\n",
            "Batch 900/1583 processed, running loss: 1252.888278, correct predictions: 7951, total: 14416\n",
            "Batch 910/1583 processed, running loss: 1263.812464, correct predictions: 8037, total: 14576\n",
            "Batch 920/1583 processed, running loss: 1275.484706, correct predictions: 8127, total: 14736\n",
            "Batch 930/1583 processed, running loss: 1286.460767, correct predictions: 8245, total: 14896\n",
            "Batch 940/1583 processed, running loss: 1297.164432, correct predictions: 8365, total: 15056\n",
            "Batch 950/1583 processed, running loss: 1309.691681, correct predictions: 8485, total: 15216\n",
            "Batch 960/1583 processed, running loss: 1322.739144, correct predictions: 8594, total: 15376\n",
            "Batch 970/1583 processed, running loss: 1334.592019, correct predictions: 8700, total: 15536\n",
            "Batch 980/1583 processed, running loss: 1347.350468, correct predictions: 8765, total: 15696\n",
            "Batch 990/1583 processed, running loss: 1359.053396, correct predictions: 8857, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 1371.460562, correct predictions: 8961, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 1381.798660, correct predictions: 9072, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 1394.758572, correct predictions: 9154, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 1406.383397, correct predictions: 9255, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 1416.966312, correct predictions: 9361, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 1428.042421, correct predictions: 9472, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 1439.238999, correct predictions: 9591, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 1450.302536, correct predictions: 9669, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 1462.425787, correct predictions: 9745, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 1473.352637, correct predictions: 9843, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 1487.243336, correct predictions: 9917, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 1500.238952, correct predictions: 9992, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 1511.358226, correct predictions: 10104, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 1523.485993, correct predictions: 10214, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 1535.027378, correct predictions: 10316, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 1549.555732, correct predictions: 10426, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 1561.825433, correct predictions: 10525, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 1574.430337, correct predictions: 10630, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 1586.211537, correct predictions: 10736, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 1598.851607, correct predictions: 10855, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 1609.633044, correct predictions: 10956, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 1620.995563, correct predictions: 11042, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 1634.400574, correct predictions: 11139, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 1645.151336, correct predictions: 11241, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 1657.354453, correct predictions: 11353, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 1668.725997, correct predictions: 11464, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 1679.930689, correct predictions: 11577, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 1692.733747, correct predictions: 11689, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 1705.184622, correct predictions: 11782, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 1717.700937, correct predictions: 11890, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 1729.229298, correct predictions: 12000, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 1739.940124, correct predictions: 12097, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 1750.557375, correct predictions: 12205, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 1762.885375, correct predictions: 12304, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 1774.254864, correct predictions: 12400, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 1785.046991, correct predictions: 12473, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 1797.032654, correct predictions: 12579, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 1808.489429, correct predictions: 12695, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 1820.325946, correct predictions: 12806, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 1832.662672, correct predictions: 12908, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 1844.413108, correct predictions: 13011, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 1856.324974, correct predictions: 13123, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 1867.055636, correct predictions: 13232, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 1878.839565, correct predictions: 13333, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 1890.850152, correct predictions: 13447, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 1902.509361, correct predictions: 13547, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 1913.499815, correct predictions: 13631, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 1926.314983, correct predictions: 13722, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 1938.689049, correct predictions: 13810, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 1951.392117, correct predictions: 13908, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 1962.678387, correct predictions: 14003, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 1973.576815, correct predictions: 14102, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 1983.542271, correct predictions: 14213, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 1997.046491, correct predictions: 14295, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 2007.683519, correct predictions: 14408, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 2019.632408, correct predictions: 14487, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 2031.136309, correct predictions: 14573, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 2042.855733, correct predictions: 14689, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 2054.938851, correct predictions: 14806, total: 25296\n",
            "\n",
            "Training Loss per batch = 1.299474\tAccuracy on Training set = 58.543041% [14819/25313]\n",
            "\n",
            "Validation Loss per batch = 1.088248\tAccuracy on Validation set = 69.640953% [1959/2813]\n",
            "Train Loss: 1.2995, Train Accuracy: 58.5430\n",
            "Valid Loss: 1.0882, Valid Accuracy: 69.6410\n",
            "\n",
            "Epoch 2/30\n",
            "-------------------------------\n",
            "Epoch: 1, Learning Rate: 0.005000 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0/1583 processed, running loss: 0.657905, correct predictions: 9, total: 16\n",
            "Batch 10/1583 processed, running loss: 10.840776, correct predictions: 112, total: 176\n",
            "Batch 20/1583 processed, running loss: 23.189543, correct predictions: 198, total: 336\n",
            "Batch 30/1583 processed, running loss: 34.359543, correct predictions: 292, total: 496\n",
            "Batch 40/1583 processed, running loss: 45.876104, correct predictions: 401, total: 656\n",
            "Batch 50/1583 processed, running loss: 58.009153, correct predictions: 494, total: 816\n",
            "Batch 60/1583 processed, running loss: 68.518908, correct predictions: 591, total: 976\n",
            "Batch 70/1583 processed, running loss: 79.806683, correct predictions: 685, total: 1136\n",
            "Batch 80/1583 processed, running loss: 91.060184, correct predictions: 770, total: 1296\n",
            "Batch 90/1583 processed, running loss: 101.665053, correct predictions: 858, total: 1456\n",
            "Batch 100/1583 processed, running loss: 113.171650, correct predictions: 966, total: 1616\n",
            "Batch 110/1583 processed, running loss: 122.304023, correct predictions: 1092, total: 1776\n",
            "Batch 120/1583 processed, running loss: 135.759106, correct predictions: 1207, total: 1936\n",
            "Batch 130/1583 processed, running loss: 147.515314, correct predictions: 1316, total: 2096\n",
            "Batch 140/1583 processed, running loss: 158.947524, correct predictions: 1416, total: 2256\n",
            "Batch 150/1583 processed, running loss: 172.180124, correct predictions: 1513, total: 2416\n",
            "Batch 160/1583 processed, running loss: 183.098880, correct predictions: 1613, total: 2576\n",
            "Batch 170/1583 processed, running loss: 193.643495, correct predictions: 1721, total: 2736\n",
            "Batch 180/1583 processed, running loss: 203.475564, correct predictions: 1820, total: 2896\n",
            "Batch 190/1583 processed, running loss: 217.504301, correct predictions: 1924, total: 3056\n",
            "Batch 200/1583 processed, running loss: 228.154546, correct predictions: 2029, total: 3216\n",
            "Batch 210/1583 processed, running loss: 239.558549, correct predictions: 2138, total: 3376\n",
            "Batch 220/1583 processed, running loss: 248.849948, correct predictions: 2252, total: 3536\n",
            "Batch 230/1583 processed, running loss: 259.807376, correct predictions: 2353, total: 3696\n",
            "Batch 240/1583 processed, running loss: 271.445965, correct predictions: 2454, total: 3856\n",
            "Batch 250/1583 processed, running loss: 281.407597, correct predictions: 2556, total: 4016\n",
            "Batch 260/1583 processed, running loss: 292.321080, correct predictions: 2668, total: 4176\n",
            "Batch 270/1583 processed, running loss: 302.753108, correct predictions: 2762, total: 4336\n",
            "Batch 280/1583 processed, running loss: 314.236378, correct predictions: 2842, total: 4496\n",
            "Batch 290/1583 processed, running loss: 324.261674, correct predictions: 2958, total: 4656\n",
            "Batch 300/1583 processed, running loss: 333.930338, correct predictions: 3063, total: 4816\n",
            "Batch 310/1583 processed, running loss: 345.813404, correct predictions: 3167, total: 4976\n",
            "Batch 320/1583 processed, running loss: 355.245582, correct predictions: 3268, total: 5136\n",
            "Batch 330/1583 processed, running loss: 366.209262, correct predictions: 3340, total: 5296\n",
            "Batch 340/1583 processed, running loss: 378.910906, correct predictions: 3430, total: 5456\n",
            "Batch 350/1583 processed, running loss: 389.209881, correct predictions: 3539, total: 5616\n",
            "Batch 360/1583 processed, running loss: 399.079992, correct predictions: 3647, total: 5776\n",
            "Batch 370/1583 processed, running loss: 411.326795, correct predictions: 3732, total: 5936\n",
            "Batch 380/1583 processed, running loss: 423.018446, correct predictions: 3843, total: 6096\n",
            "Batch 390/1583 processed, running loss: 433.719955, correct predictions: 3957, total: 6256\n",
            "Batch 400/1583 processed, running loss: 444.413239, correct predictions: 4058, total: 6416\n",
            "Batch 410/1583 processed, running loss: 456.211785, correct predictions: 4161, total: 6576\n",
            "Batch 420/1583 processed, running loss: 467.687987, correct predictions: 4271, total: 6736\n",
            "Batch 430/1583 processed, running loss: 479.411567, correct predictions: 4375, total: 6896\n",
            "Batch 440/1583 processed, running loss: 490.767984, correct predictions: 4489, total: 7056\n",
            "Batch 450/1583 processed, running loss: 501.346981, correct predictions: 4611, total: 7216\n",
            "Batch 460/1583 processed, running loss: 512.152796, correct predictions: 4719, total: 7376\n",
            "Batch 470/1583 processed, running loss: 521.295639, correct predictions: 4839, total: 7536\n",
            "Batch 480/1583 processed, running loss: 530.336955, correct predictions: 4967, total: 7696\n",
            "Batch 490/1583 processed, running loss: 541.686295, correct predictions: 5078, total: 7856\n",
            "Batch 500/1583 processed, running loss: 554.153228, correct predictions: 5180, total: 8016\n",
            "Batch 510/1583 processed, running loss: 564.024435, correct predictions: 5282, total: 8176\n",
            "Batch 520/1583 processed, running loss: 574.851292, correct predictions: 5384, total: 8336\n",
            "Batch 530/1583 processed, running loss: 586.659231, correct predictions: 5498, total: 8496\n",
            "Batch 540/1583 processed, running loss: 599.913435, correct predictions: 5590, total: 8656\n",
            "Batch 550/1583 processed, running loss: 611.683186, correct predictions: 5682, total: 8816\n",
            "Batch 560/1583 processed, running loss: 622.433454, correct predictions: 5789, total: 8976\n",
            "Batch 570/1583 processed, running loss: 633.236751, correct predictions: 5876, total: 9136\n",
            "Batch 580/1583 processed, running loss: 642.984268, correct predictions: 5962, total: 9296\n",
            "Batch 590/1583 processed, running loss: 652.612135, correct predictions: 6047, total: 9456\n",
            "Batch 600/1583 processed, running loss: 665.482657, correct predictions: 6126, total: 9616\n",
            "Batch 610/1583 processed, running loss: 677.164694, correct predictions: 6217, total: 9776\n",
            "Batch 620/1583 processed, running loss: 687.787329, correct predictions: 6333, total: 9936\n",
            "Batch 630/1583 processed, running loss: 697.483572, correct predictions: 6448, total: 10096\n",
            "Batch 640/1583 processed, running loss: 708.562146, correct predictions: 6570, total: 10256\n",
            "Batch 650/1583 processed, running loss: 720.152418, correct predictions: 6692, total: 10416\n",
            "Batch 660/1583 processed, running loss: 731.169566, correct predictions: 6806, total: 10576\n",
            "Batch 670/1583 processed, running loss: 742.176440, correct predictions: 6923, total: 10736\n",
            "Batch 680/1583 processed, running loss: 753.739837, correct predictions: 7039, total: 10896\n",
            "Batch 690/1583 processed, running loss: 762.707848, correct predictions: 7157, total: 11056\n",
            "Batch 700/1583 processed, running loss: 772.886996, correct predictions: 7267, total: 11216\n",
            "Batch 710/1583 processed, running loss: 785.015695, correct predictions: 7366, total: 11376\n",
            "Batch 720/1583 processed, running loss: 796.797856, correct predictions: 7472, total: 11536\n",
            "Batch 730/1583 processed, running loss: 810.923563, correct predictions: 7559, total: 11696\n",
            "Batch 740/1583 processed, running loss: 822.212675, correct predictions: 7640, total: 11856\n",
            "Batch 750/1583 processed, running loss: 834.350971, correct predictions: 7713, total: 12016\n",
            "Batch 760/1583 processed, running loss: 848.998898, correct predictions: 7809, total: 12176\n",
            "Batch 770/1583 processed, running loss: 860.028862, correct predictions: 7913, total: 12336\n",
            "Batch 780/1583 processed, running loss: 874.150331, correct predictions: 8007, total: 12496\n",
            "Batch 790/1583 processed, running loss: 886.994058, correct predictions: 8091, total: 12656\n",
            "Batch 800/1583 processed, running loss: 897.613206, correct predictions: 8186, total: 12816\n",
            "Batch 810/1583 processed, running loss: 910.260880, correct predictions: 8263, total: 12976\n",
            "Batch 820/1583 processed, running loss: 922.561478, correct predictions: 8330, total: 13136\n",
            "Batch 830/1583 processed, running loss: 933.876340, correct predictions: 8420, total: 13296\n",
            "Batch 840/1583 processed, running loss: 946.209678, correct predictions: 8501, total: 13456\n",
            "Batch 850/1583 processed, running loss: 959.174955, correct predictions: 8585, total: 13616\n",
            "Batch 860/1583 processed, running loss: 968.707888, correct predictions: 8682, total: 13776\n",
            "Batch 870/1583 processed, running loss: 983.162391, correct predictions: 8761, total: 13936\n",
            "Batch 880/1583 processed, running loss: 994.700935, correct predictions: 8839, total: 14096\n",
            "Batch 890/1583 processed, running loss: 1004.367299, correct predictions: 8956, total: 14256\n",
            "Batch 900/1583 processed, running loss: 1014.207282, correct predictions: 9072, total: 14416\n",
            "Batch 910/1583 processed, running loss: 1024.401024, correct predictions: 9193, total: 14576\n",
            "Batch 920/1583 processed, running loss: 1035.406691, correct predictions: 9303, total: 14736\n",
            "Batch 930/1583 processed, running loss: 1045.690129, correct predictions: 9426, total: 14896\n",
            "Batch 940/1583 processed, running loss: 1054.888944, correct predictions: 9545, total: 15056\n",
            "Batch 950/1583 processed, running loss: 1063.520015, correct predictions: 9656, total: 15216\n",
            "Batch 960/1583 processed, running loss: 1073.365874, correct predictions: 9758, total: 15376\n",
            "Batch 970/1583 processed, running loss: 1083.526907, correct predictions: 9875, total: 15536\n",
            "Batch 980/1583 processed, running loss: 1093.876805, correct predictions: 9991, total: 15696\n",
            "Batch 990/1583 processed, running loss: 1104.942774, correct predictions: 10109, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 1118.841587, correct predictions: 10226, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 1130.003570, correct predictions: 10340, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 1139.314718, correct predictions: 10451, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 1148.903009, correct predictions: 10533, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 1159.784597, correct predictions: 10612, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 1169.337326, correct predictions: 10690, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 1178.033957, correct predictions: 10778, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 1190.699506, correct predictions: 10866, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 1199.933112, correct predictions: 10946, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 1213.584463, correct predictions: 11025, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 1221.957668, correct predictions: 11118, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 1234.429977, correct predictions: 11213, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 1244.216505, correct predictions: 11300, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 1253.828636, correct predictions: 11400, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 1263.213427, correct predictions: 11515, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 1272.430278, correct predictions: 11629, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 1283.492466, correct predictions: 11731, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 1294.183517, correct predictions: 11830, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 1308.087885, correct predictions: 11937, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 1317.016667, correct predictions: 12067, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 1326.247936, correct predictions: 12191, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 1337.859549, correct predictions: 12319, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 1347.395734, correct predictions: 12434, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 1358.681280, correct predictions: 12526, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 1365.709129, correct predictions: 12640, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 1374.442698, correct predictions: 12749, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 1386.777797, correct predictions: 12831, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 1397.009426, correct predictions: 12930, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 1408.583670, correct predictions: 13038, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 1419.365605, correct predictions: 13141, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 1430.817397, correct predictions: 13258, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 1440.513151, correct predictions: 13366, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 1451.150830, correct predictions: 13492, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 1461.529305, correct predictions: 13616, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 1472.473518, correct predictions: 13742, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 1483.373224, correct predictions: 13864, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 1495.614824, correct predictions: 13982, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 1505.819022, correct predictions: 14092, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 1518.013924, correct predictions: 14214, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 1528.320170, correct predictions: 14331, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 1538.415889, correct predictions: 14434, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 1548.870950, correct predictions: 14540, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 1559.806099, correct predictions: 14620, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 1568.336926, correct predictions: 14722, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 1582.425708, correct predictions: 14834, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 1591.175824, correct predictions: 14948, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 1601.904055, correct predictions: 15062, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 1611.842101, correct predictions: 15168, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 1623.522424, correct predictions: 15279, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 1631.259631, correct predictions: 15403, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 1641.643816, correct predictions: 15510, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 1653.214431, correct predictions: 15621, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 1664.103482, correct predictions: 15737, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 1673.920045, correct predictions: 15858, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 1683.537712, correct predictions: 15980, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 1693.346508, correct predictions: 16102, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 1703.410711, correct predictions: 16218, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 1714.106281, correct predictions: 16312, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 1724.553373, correct predictions: 16417, total: 25296\n",
            "\n",
            "Training Loss per batch = 1.090609\tAccuracy on Training set = 64.903409% [16429/25313]\n",
            "\n",
            "Validation Loss per batch = 1.123875\tAccuracy on Validation set = 76.964095% [2165/2813]\n",
            "Train Loss: 1.0906, Train Accuracy: 64.9034\n",
            "Valid Loss: 1.1239, Valid Accuracy: 76.9641\n",
            "\n",
            "Epoch 3/30\n",
            "-------------------------------\n",
            "Epoch: 2, Learning Rate: 0.005000 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0/1583 processed, running loss: 2.067342, correct predictions: 11, total: 16\n",
            "Batch 10/1583 processed, running loss: 12.187900, correct predictions: 116, total: 176\n",
            "Batch 20/1583 processed, running loss: 22.609892, correct predictions: 233, total: 336\n",
            "Batch 30/1583 processed, running loss: 34.045887, correct predictions: 354, total: 496\n",
            "Batch 40/1583 processed, running loss: 43.137078, correct predictions: 472, total: 656\n",
            "Batch 50/1583 processed, running loss: 52.605964, correct predictions: 589, total: 816\n",
            "Batch 60/1583 processed, running loss: 61.032610, correct predictions: 714, total: 976\n",
            "Batch 70/1583 processed, running loss: 70.565035, correct predictions: 832, total: 1136\n",
            "Batch 80/1583 processed, running loss: 79.042812, correct predictions: 958, total: 1296\n",
            "Batch 90/1583 processed, running loss: 87.232590, correct predictions: 1093, total: 1456\n",
            "Batch 100/1583 processed, running loss: 96.698353, correct predictions: 1209, total: 1616\n",
            "Batch 110/1583 processed, running loss: 106.347206, correct predictions: 1312, total: 1776\n",
            "Batch 120/1583 processed, running loss: 115.876253, correct predictions: 1418, total: 1936\n",
            "Batch 130/1583 processed, running loss: 125.499314, correct predictions: 1502, total: 2096\n",
            "Batch 140/1583 processed, running loss: 136.836920, correct predictions: 1597, total: 2256\n",
            "Batch 150/1583 processed, running loss: 147.036336, correct predictions: 1704, total: 2416\n",
            "Batch 160/1583 processed, running loss: 156.377596, correct predictions: 1811, total: 2576\n",
            "Batch 170/1583 processed, running loss: 166.943288, correct predictions: 1904, total: 2736\n",
            "Batch 180/1583 processed, running loss: 176.403847, correct predictions: 2003, total: 2896\n",
            "Batch 190/1583 processed, running loss: 187.166524, correct predictions: 2118, total: 3056\n",
            "Batch 200/1583 processed, running loss: 196.181784, correct predictions: 2231, total: 3216\n",
            "Batch 210/1583 processed, running loss: 207.636846, correct predictions: 2345, total: 3376\n",
            "Batch 220/1583 processed, running loss: 216.676466, correct predictions: 2463, total: 3536\n",
            "Batch 230/1583 processed, running loss: 227.762181, correct predictions: 2575, total: 3696\n",
            "Batch 240/1583 processed, running loss: 237.214846, correct predictions: 2698, total: 3856\n",
            "Batch 250/1583 processed, running loss: 248.104541, correct predictions: 2809, total: 4016\n",
            "Batch 260/1583 processed, running loss: 256.377411, correct predictions: 2934, total: 4176\n",
            "Batch 270/1583 processed, running loss: 267.127484, correct predictions: 3055, total: 4336\n",
            "Batch 280/1583 processed, running loss: 276.745482, correct predictions: 3166, total: 4496\n",
            "Batch 290/1583 processed, running loss: 287.285935, correct predictions: 3276, total: 4656\n",
            "Batch 300/1583 processed, running loss: 298.522891, correct predictions: 3387, total: 4816\n",
            "Batch 310/1583 processed, running loss: 307.726625, correct predictions: 3494, total: 4976\n",
            "Batch 320/1583 processed, running loss: 318.063183, correct predictions: 3598, total: 5136\n",
            "Batch 330/1583 processed, running loss: 327.596472, correct predictions: 3698, total: 5296\n",
            "Batch 340/1583 processed, running loss: 338.044046, correct predictions: 3796, total: 5456\n",
            "Batch 350/1583 processed, running loss: 347.553516, correct predictions: 3900, total: 5616\n",
            "Batch 360/1583 processed, running loss: 358.816818, correct predictions: 4006, total: 5776\n",
            "Batch 370/1583 processed, running loss: 369.751365, correct predictions: 4122, total: 5936\n",
            "Batch 380/1583 processed, running loss: 378.535883, correct predictions: 4232, total: 6096\n",
            "Batch 390/1583 processed, running loss: 388.531417, correct predictions: 4341, total: 6256\n",
            "Batch 400/1583 processed, running loss: 398.934512, correct predictions: 4445, total: 6416\n",
            "Batch 410/1583 processed, running loss: 410.819376, correct predictions: 4530, total: 6576\n",
            "Batch 420/1583 processed, running loss: 420.607569, correct predictions: 4628, total: 6736\n",
            "Batch 430/1583 processed, running loss: 430.939536, correct predictions: 4735, total: 6896\n",
            "Batch 440/1583 processed, running loss: 441.096660, correct predictions: 4850, total: 7056\n",
            "Batch 450/1583 processed, running loss: 451.343853, correct predictions: 4956, total: 7216\n",
            "Batch 460/1583 processed, running loss: 463.293452, correct predictions: 5061, total: 7376\n",
            "Batch 470/1583 processed, running loss: 472.903065, correct predictions: 5183, total: 7536\n",
            "Batch 480/1583 processed, running loss: 482.951641, correct predictions: 5303, total: 7696\n",
            "Batch 490/1583 processed, running loss: 493.931655, correct predictions: 5411, total: 7856\n",
            "Batch 500/1583 processed, running loss: 505.792403, correct predictions: 5511, total: 8016\n",
            "Batch 510/1583 processed, running loss: 515.228168, correct predictions: 5631, total: 8176\n",
            "Batch 520/1583 processed, running loss: 525.630041, correct predictions: 5758, total: 8336\n",
            "Batch 530/1583 processed, running loss: 537.020540, correct predictions: 5867, total: 8496\n",
            "Batch 540/1583 processed, running loss: 545.122095, correct predictions: 5988, total: 8656\n",
            "Batch 550/1583 processed, running loss: 555.932583, correct predictions: 6090, total: 8816\n",
            "Batch 560/1583 processed, running loss: 566.250575, correct predictions: 6185, total: 8976\n",
            "Batch 570/1583 processed, running loss: 576.639550, correct predictions: 6277, total: 9136\n",
            "Batch 580/1583 processed, running loss: 586.888453, correct predictions: 6381, total: 9296\n",
            "Batch 590/1583 processed, running loss: 596.856872, correct predictions: 6490, total: 9456\n",
            "Batch 600/1583 processed, running loss: 606.052212, correct predictions: 6603, total: 9616\n",
            "Batch 610/1583 processed, running loss: 615.168312, correct predictions: 6725, total: 9776\n",
            "Batch 620/1583 processed, running loss: 624.249337, correct predictions: 6848, total: 9936\n",
            "Batch 630/1583 processed, running loss: 633.471589, correct predictions: 6943, total: 10096\n",
            "Batch 640/1583 processed, running loss: 645.964509, correct predictions: 7035, total: 10256\n",
            "Batch 650/1583 processed, running loss: 655.312742, correct predictions: 7128, total: 10416\n",
            "Batch 660/1583 processed, running loss: 664.140328, correct predictions: 7224, total: 10576\n",
            "Batch 670/1583 processed, running loss: 673.199311, correct predictions: 7324, total: 10736\n",
            "Batch 680/1583 processed, running loss: 683.034247, correct predictions: 7432, total: 10896\n",
            "Batch 690/1583 processed, running loss: 692.389309, correct predictions: 7551, total: 11056\n",
            "Batch 700/1583 processed, running loss: 703.021489, correct predictions: 7678, total: 11216\n",
            "Batch 710/1583 processed, running loss: 714.478011, correct predictions: 7810, total: 11376\n",
            "Batch 720/1583 processed, running loss: 723.143384, correct predictions: 7934, total: 11536\n",
            "Batch 730/1583 processed, running loss: 732.492051, correct predictions: 8053, total: 11696\n",
            "Batch 740/1583 processed, running loss: 742.905047, correct predictions: 8158, total: 11856\n",
            "Batch 750/1583 processed, running loss: 753.853397, correct predictions: 8253, total: 12016\n",
            "Batch 760/1583 processed, running loss: 763.499019, correct predictions: 8359, total: 12176\n",
            "Batch 770/1583 processed, running loss: 774.153432, correct predictions: 8472, total: 12336\n",
            "Batch 780/1583 processed, running loss: 784.385911, correct predictions: 8581, total: 12496\n",
            "Batch 790/1583 processed, running loss: 796.779842, correct predictions: 8687, total: 12656\n",
            "Batch 800/1583 processed, running loss: 807.972722, correct predictions: 8796, total: 12816\n",
            "Batch 810/1583 processed, running loss: 818.746137, correct predictions: 8914, total: 12976\n",
            "Batch 820/1583 processed, running loss: 830.497019, correct predictions: 9026, total: 13136\n",
            "Batch 830/1583 processed, running loss: 839.219214, correct predictions: 9147, total: 13296\n",
            "Batch 840/1583 processed, running loss: 849.417317, correct predictions: 9252, total: 13456\n",
            "Batch 850/1583 processed, running loss: 858.416508, correct predictions: 9378, total: 13616\n",
            "Batch 860/1583 processed, running loss: 869.409440, correct predictions: 9480, total: 13776\n",
            "Batch 870/1583 processed, running loss: 879.694773, correct predictions: 9609, total: 13936\n",
            "Batch 880/1583 processed, running loss: 891.763264, correct predictions: 9727, total: 14096\n",
            "Batch 890/1583 processed, running loss: 901.398555, correct predictions: 9836, total: 14256\n",
            "Batch 900/1583 processed, running loss: 910.850702, correct predictions: 9947, total: 14416\n",
            "Batch 910/1583 processed, running loss: 923.280358, correct predictions: 10067, total: 14576\n",
            "Batch 920/1583 processed, running loss: 932.470412, correct predictions: 10178, total: 14736\n",
            "Batch 930/1583 processed, running loss: 942.472697, correct predictions: 10270, total: 14896\n",
            "Batch 940/1583 processed, running loss: 952.240249, correct predictions: 10377, total: 15056\n",
            "Batch 950/1583 processed, running loss: 962.783007, correct predictions: 10487, total: 15216\n",
            "Batch 960/1583 processed, running loss: 972.041499, correct predictions: 10608, total: 15376\n",
            "Batch 970/1583 processed, running loss: 981.725202, correct predictions: 10725, total: 15536\n",
            "Batch 980/1583 processed, running loss: 994.770030, correct predictions: 10835, total: 15696\n",
            "Batch 990/1583 processed, running loss: 1006.278329, correct predictions: 10946, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 1013.341481, correct predictions: 11076, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 1022.895334, correct predictions: 11189, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 1032.897185, correct predictions: 11272, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 1042.384799, correct predictions: 11368, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 1050.542229, correct predictions: 11485, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 1060.994978, correct predictions: 11600, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 1068.747492, correct predictions: 11707, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 1078.827515, correct predictions: 11814, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 1089.800421, correct predictions: 11920, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 1098.433497, correct predictions: 12036, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 1106.999938, correct predictions: 12154, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 1116.607037, correct predictions: 12263, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 1125.095391, correct predictions: 12380, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 1133.238856, correct predictions: 12500, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 1141.432600, correct predictions: 12622, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 1150.601410, correct predictions: 12735, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 1160.176316, correct predictions: 12850, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 1168.235361, correct predictions: 12969, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 1180.787681, correct predictions: 13087, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 1190.139388, correct predictions: 13189, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 1203.499607, correct predictions: 13293, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 1212.874132, correct predictions: 13409, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 1221.104839, correct predictions: 13511, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 1228.697099, correct predictions: 13627, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 1239.727359, correct predictions: 13747, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 1249.181094, correct predictions: 13872, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 1258.716131, correct predictions: 13998, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 1270.145072, correct predictions: 14129, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 1278.647668, correct predictions: 14238, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 1289.768310, correct predictions: 14344, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 1298.042934, correct predictions: 14459, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 1306.954745, correct predictions: 14555, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 1316.916450, correct predictions: 14653, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 1328.226299, correct predictions: 14763, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 1338.219239, correct predictions: 14868, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 1348.054320, correct predictions: 14966, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 1357.329740, correct predictions: 15067, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 1368.752196, correct predictions: 15156, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 1378.012054, correct predictions: 15265, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 1388.056628, correct predictions: 15367, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 1397.241107, correct predictions: 15470, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 1406.720796, correct predictions: 15575, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 1416.082251, correct predictions: 15689, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 1428.186146, correct predictions: 15810, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 1438.229632, correct predictions: 15933, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 1448.021956, correct predictions: 16044, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 1459.124744, correct predictions: 16158, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 1467.234016, correct predictions: 16272, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 1475.523270, correct predictions: 16389, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 1485.683738, correct predictions: 16507, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 1496.440683, correct predictions: 16612, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 1505.955880, correct predictions: 16726, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 1516.733905, correct predictions: 16839, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 1526.389769, correct predictions: 16944, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 1533.923116, correct predictions: 17048, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 1544.327049, correct predictions: 17148, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 1551.696534, correct predictions: 17254, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 1562.496284, correct predictions: 17355, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 1570.894467, correct predictions: 17472, total: 25296\n",
            "\n",
            "Training Loss per batch = 0.994653\tAccuracy on Training set = 69.063327% [17482/25313]\n",
            "\n",
            "Validation Loss per batch = 1.020978\tAccuracy on Validation set = 76.608603% [2155/2813]\n",
            "Train Loss: 0.9947, Train Accuracy: 69.0633\n",
            "Valid Loss: 1.0210, Valid Accuracy: 76.6086\n",
            "\n",
            "Epoch 4/30\n",
            "-------------------------------\n",
            "Epoch: 3, Learning Rate: 0.005000 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0/1583 processed, running loss: 0.768942, correct predictions: 14, total: 16\n",
            "Batch 10/1583 processed, running loss: 10.755578, correct predictions: 129, total: 176\n",
            "Batch 20/1583 processed, running loss: 21.250722, correct predictions: 243, total: 336\n",
            "Batch 30/1583 processed, running loss: 30.284439, correct predictions: 363, total: 496\n",
            "Batch 40/1583 processed, running loss: 38.361496, correct predictions: 481, total: 656\n",
            "Batch 50/1583 processed, running loss: 45.949482, correct predictions: 609, total: 816\n",
            "Batch 60/1583 processed, running loss: 53.093271, correct predictions: 738, total: 976\n",
            "Batch 70/1583 processed, running loss: 62.492937, correct predictions: 854, total: 1136\n",
            "Batch 80/1583 processed, running loss: 70.235005, correct predictions: 977, total: 1296\n",
            "Batch 90/1583 processed, running loss: 78.246013, correct predictions: 1092, total: 1456\n",
            "Batch 100/1583 processed, running loss: 87.376869, correct predictions: 1217, total: 1616\n",
            "Batch 110/1583 processed, running loss: 98.555548, correct predictions: 1330, total: 1776\n",
            "Batch 120/1583 processed, running loss: 107.040349, correct predictions: 1443, total: 1936\n",
            "Batch 130/1583 processed, running loss: 115.599073, correct predictions: 1557, total: 2096\n",
            "Batch 140/1583 processed, running loss: 125.772766, correct predictions: 1667, total: 2256\n",
            "Batch 150/1583 processed, running loss: 136.207953, correct predictions: 1767, total: 2416\n",
            "Batch 160/1583 processed, running loss: 146.915369, correct predictions: 1877, total: 2576\n",
            "Batch 170/1583 processed, running loss: 154.973495, correct predictions: 1981, total: 2736\n",
            "Batch 180/1583 processed, running loss: 164.201437, correct predictions: 2094, total: 2896\n",
            "Batch 190/1583 processed, running loss: 174.045862, correct predictions: 2207, total: 3056\n",
            "Batch 200/1583 processed, running loss: 181.769749, correct predictions: 2334, total: 3216\n",
            "Batch 210/1583 processed, running loss: 193.491383, correct predictions: 2461, total: 3376\n",
            "Batch 220/1583 processed, running loss: 202.947324, correct predictions: 2578, total: 3536\n",
            "Batch 230/1583 processed, running loss: 211.454104, correct predictions: 2698, total: 3696\n",
            "Batch 240/1583 processed, running loss: 220.709722, correct predictions: 2812, total: 3856\n",
            "Batch 250/1583 processed, running loss: 229.361510, correct predictions: 2922, total: 4016\n",
            "Batch 260/1583 processed, running loss: 240.415403, correct predictions: 3031, total: 4176\n",
            "Batch 270/1583 processed, running loss: 249.904906, correct predictions: 3135, total: 4336\n",
            "Batch 280/1583 processed, running loss: 258.642510, correct predictions: 3242, total: 4496\n",
            "Batch 290/1583 processed, running loss: 266.096881, correct predictions: 3372, total: 4656\n",
            "Batch 300/1583 processed, running loss: 275.486929, correct predictions: 3484, total: 4816\n",
            "Batch 310/1583 processed, running loss: 286.009938, correct predictions: 3592, total: 4976\n",
            "Batch 320/1583 processed, running loss: 295.467848, correct predictions: 3706, total: 5136\n",
            "Batch 330/1583 processed, running loss: 304.011125, correct predictions: 3836, total: 5296\n",
            "Batch 340/1583 processed, running loss: 312.600296, correct predictions: 3952, total: 5456\n",
            "Batch 350/1583 processed, running loss: 321.969696, correct predictions: 4059, total: 5616\n",
            "Batch 360/1583 processed, running loss: 329.342340, correct predictions: 4167, total: 5776\n",
            "Batch 370/1583 processed, running loss: 338.968112, correct predictions: 4271, total: 5936\n",
            "Batch 380/1583 processed, running loss: 346.917582, correct predictions: 4389, total: 6096\n",
            "Batch 390/1583 processed, running loss: 356.605993, correct predictions: 4492, total: 6256\n",
            "Batch 400/1583 processed, running loss: 363.630132, correct predictions: 4601, total: 6416\n",
            "Batch 410/1583 processed, running loss: 373.314830, correct predictions: 4717, total: 6576\n",
            "Batch 420/1583 processed, running loss: 383.566885, correct predictions: 4838, total: 6736\n",
            "Batch 430/1583 processed, running loss: 392.512533, correct predictions: 4966, total: 6896\n",
            "Batch 440/1583 processed, running loss: 402.110671, correct predictions: 5092, total: 7056\n",
            "Batch 450/1583 processed, running loss: 411.719729, correct predictions: 5221, total: 7216\n",
            "Batch 460/1583 processed, running loss: 420.466866, correct predictions: 5341, total: 7376\n",
            "Batch 470/1583 processed, running loss: 431.565815, correct predictions: 5466, total: 7536\n",
            "Batch 480/1583 processed, running loss: 440.033802, correct predictions: 5590, total: 7696\n",
            "Batch 490/1583 processed, running loss: 450.201801, correct predictions: 5712, total: 7856\n",
            "Batch 500/1583 processed, running loss: 458.121275, correct predictions: 5839, total: 8016\n",
            "Batch 510/1583 processed, running loss: 465.513362, correct predictions: 5960, total: 8176\n",
            "Batch 520/1583 processed, running loss: 475.054508, correct predictions: 6068, total: 8336\n",
            "Batch 530/1583 processed, running loss: 483.808636, correct predictions: 6190, total: 8496\n",
            "Batch 540/1583 processed, running loss: 493.913209, correct predictions: 6298, total: 8656\n",
            "Batch 550/1583 processed, running loss: 504.492827, correct predictions: 6424, total: 8816\n",
            "Batch 560/1583 processed, running loss: 512.417972, correct predictions: 6528, total: 8976\n",
            "Batch 570/1583 processed, running loss: 522.611840, correct predictions: 6616, total: 9136\n",
            "Batch 580/1583 processed, running loss: 532.142023, correct predictions: 6736, total: 9296\n",
            "Batch 590/1583 processed, running loss: 540.010645, correct predictions: 6869, total: 9456\n",
            "Batch 600/1583 processed, running loss: 549.773740, correct predictions: 6992, total: 9616\n",
            "Batch 610/1583 processed, running loss: 558.511610, correct predictions: 7109, total: 9776\n",
            "Batch 620/1583 processed, running loss: 569.238628, correct predictions: 7220, total: 9936\n",
            "Batch 630/1583 processed, running loss: 579.958116, correct predictions: 7338, total: 10096\n",
            "Batch 640/1583 processed, running loss: 589.971464, correct predictions: 7447, total: 10256\n",
            "Batch 650/1583 processed, running loss: 598.755572, correct predictions: 7543, total: 10416\n",
            "Batch 660/1583 processed, running loss: 607.324575, correct predictions: 7639, total: 10576\n",
            "Batch 670/1583 processed, running loss: 617.465085, correct predictions: 7755, total: 10736\n",
            "Batch 680/1583 processed, running loss: 624.307508, correct predictions: 7883, total: 10896\n",
            "Batch 690/1583 processed, running loss: 633.207753, correct predictions: 7996, total: 11056\n",
            "Batch 700/1583 processed, running loss: 641.502761, correct predictions: 8121, total: 11216\n",
            "Batch 710/1583 processed, running loss: 650.937356, correct predictions: 8242, total: 11376\n",
            "Batch 720/1583 processed, running loss: 661.475321, correct predictions: 8356, total: 11536\n",
            "Batch 730/1583 processed, running loss: 669.416987, correct predictions: 8474, total: 11696\n",
            "Batch 740/1583 processed, running loss: 678.208819, correct predictions: 8600, total: 11856\n",
            "Batch 750/1583 processed, running loss: 687.339269, correct predictions: 8721, total: 12016\n",
            "Batch 760/1583 processed, running loss: 694.524835, correct predictions: 8841, total: 12176\n",
            "Batch 770/1583 processed, running loss: 702.143749, correct predictions: 8950, total: 12336\n",
            "Batch 780/1583 processed, running loss: 713.754410, correct predictions: 9060, total: 12496\n",
            "Batch 790/1583 processed, running loss: 722.213827, correct predictions: 9184, total: 12656\n",
            "Batch 800/1583 processed, running loss: 731.220332, correct predictions: 9299, total: 12816\n",
            "Batch 810/1583 processed, running loss: 740.718592, correct predictions: 9414, total: 12976\n",
            "Batch 820/1583 processed, running loss: 750.960729, correct predictions: 9529, total: 13136\n",
            "Batch 830/1583 processed, running loss: 760.412716, correct predictions: 9629, total: 13296\n",
            "Batch 840/1583 processed, running loss: 770.836599, correct predictions: 9742, total: 13456\n",
            "Batch 850/1583 processed, running loss: 778.397134, correct predictions: 9872, total: 13616\n",
            "Batch 860/1583 processed, running loss: 787.103631, correct predictions: 9995, total: 13776\n",
            "Batch 870/1583 processed, running loss: 799.697330, correct predictions: 10103, total: 13936\n",
            "Batch 880/1583 processed, running loss: 810.322313, correct predictions: 10199, total: 14096\n",
            "Batch 890/1583 processed, running loss: 818.782807, correct predictions: 10304, total: 14256\n",
            "Batch 900/1583 processed, running loss: 827.060660, correct predictions: 10421, total: 14416\n",
            "Batch 910/1583 processed, running loss: 837.004158, correct predictions: 10536, total: 14576\n",
            "Batch 920/1583 processed, running loss: 845.416448, correct predictions: 10649, total: 14736\n",
            "Batch 930/1583 processed, running loss: 854.850799, correct predictions: 10751, total: 14896\n",
            "Batch 940/1583 processed, running loss: 864.450053, correct predictions: 10870, total: 15056\n",
            "Batch 950/1583 processed, running loss: 873.080489, correct predictions: 10985, total: 15216\n",
            "Batch 960/1583 processed, running loss: 881.767026, correct predictions: 11106, total: 15376\n",
            "Batch 970/1583 processed, running loss: 889.256894, correct predictions: 11222, total: 15536\n",
            "Batch 980/1583 processed, running loss: 899.153367, correct predictions: 11325, total: 15696\n",
            "Batch 990/1583 processed, running loss: 906.553399, correct predictions: 11443, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 916.363954, correct predictions: 11543, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 924.200709, correct predictions: 11650, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 933.775074, correct predictions: 11755, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 940.602352, correct predictions: 11884, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 950.209531, correct predictions: 12007, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 959.807675, correct predictions: 12129, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 967.760656, correct predictions: 12258, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 976.792343, correct predictions: 12372, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 987.374594, correct predictions: 12487, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 995.065336, correct predictions: 12599, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 1002.785064, correct predictions: 12707, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 1011.021785, correct predictions: 12817, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 1019.702132, correct predictions: 12925, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 1030.345148, correct predictions: 13027, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 1039.503602, correct predictions: 13145, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 1048.943916, correct predictions: 13259, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 1057.711684, correct predictions: 13345, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 1067.866875, correct predictions: 13456, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 1077.553644, correct predictions: 13571, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 1086.512243, correct predictions: 13684, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 1095.252489, correct predictions: 13818, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 1104.173592, correct predictions: 13945, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 1114.137077, correct predictions: 14067, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 1120.639454, correct predictions: 14197, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 1128.539479, correct predictions: 14318, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 1136.815597, correct predictions: 14430, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 1147.651331, correct predictions: 14529, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 1156.487198, correct predictions: 14627, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 1167.120258, correct predictions: 14738, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 1178.793193, correct predictions: 14856, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 1189.674858, correct predictions: 14974, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 1199.956824, correct predictions: 15084, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 1208.491348, correct predictions: 15190, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 1217.767189, correct predictions: 15303, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 1228.751140, correct predictions: 15412, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 1238.153854, correct predictions: 15505, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 1248.120474, correct predictions: 15619, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 1256.885662, correct predictions: 15725, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 1267.244719, correct predictions: 15819, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 1276.673654, correct predictions: 15914, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 1285.348688, correct predictions: 16039, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 1293.483144, correct predictions: 16171, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 1302.639994, correct predictions: 16292, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 1310.466049, correct predictions: 16405, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 1321.249468, correct predictions: 16507, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 1329.138994, correct predictions: 16618, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 1337.485122, correct predictions: 16738, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 1347.108397, correct predictions: 16861, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 1356.588997, correct predictions: 16966, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 1365.352359, correct predictions: 17089, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 1374.543006, correct predictions: 17205, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 1383.587766, correct predictions: 17312, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 1392.386973, correct predictions: 17416, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 1400.003407, correct predictions: 17508, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 1409.009889, correct predictions: 17600, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 1417.740656, correct predictions: 17705, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 1427.262538, correct predictions: 17817, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 1437.666434, correct predictions: 17932, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 1445.371765, correct predictions: 18050, total: 25296\n",
            "\n",
            "Training Loss per batch = 0.914336\tAccuracy on Training set = 71.358590% [18063/25313]\n",
            "\n",
            "Validation Loss per batch = 0.981562\tAccuracy on Validation set = 66.797014% [1879/2813]\n",
            "Train Loss: 0.9143, Train Accuracy: 71.3586\n",
            "Valid Loss: 0.9816, Valid Accuracy: 66.7970\n",
            "\n",
            "Epoch 5/30\n",
            "-------------------------------\n",
            "Epoch: 4, Learning Rate: 0.002500 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0/1583 processed, running loss: 1.637402, correct predictions: 10, total: 16\n",
            "Batch 10/1583 processed, running loss: 9.404937, correct predictions: 118, total: 176\n",
            "Batch 20/1583 processed, running loss: 17.223672, correct predictions: 238, total: 336\n",
            "Batch 30/1583 processed, running loss: 25.501959, correct predictions: 357, total: 496\n",
            "Batch 40/1583 processed, running loss: 33.445681, correct predictions: 466, total: 656\n",
            "Batch 50/1583 processed, running loss: 40.279143, correct predictions: 578, total: 816\n",
            "Batch 60/1583 processed, running loss: 47.995715, correct predictions: 686, total: 976\n",
            "Batch 70/1583 processed, running loss: 56.015311, correct predictions: 801, total: 1136\n",
            "Batch 80/1583 processed, running loss: 63.824844, correct predictions: 904, total: 1296\n",
            "Batch 90/1583 processed, running loss: 71.193984, correct predictions: 1023, total: 1456\n",
            "Batch 100/1583 processed, running loss: 76.922980, correct predictions: 1163, total: 1616\n",
            "Batch 110/1583 processed, running loss: 84.703328, correct predictions: 1293, total: 1776\n",
            "Batch 120/1583 processed, running loss: 93.083745, correct predictions: 1417, total: 1936\n",
            "Batch 130/1583 processed, running loss: 101.923364, correct predictions: 1535, total: 2096\n",
            "Batch 140/1583 processed, running loss: 110.134641, correct predictions: 1651, total: 2256\n",
            "Batch 150/1583 processed, running loss: 117.317632, correct predictions: 1774, total: 2416\n",
            "Batch 160/1583 processed, running loss: 124.615194, correct predictions: 1901, total: 2576\n",
            "Batch 170/1583 processed, running loss: 132.925174, correct predictions: 2017, total: 2736\n",
            "Batch 180/1583 processed, running loss: 138.664096, correct predictions: 2138, total: 2896\n",
            "Batch 190/1583 processed, running loss: 145.840142, correct predictions: 2265, total: 3056\n",
            "Batch 200/1583 processed, running loss: 154.334090, correct predictions: 2383, total: 3216\n",
            "Batch 210/1583 processed, running loss: 162.009043, correct predictions: 2498, total: 3376\n",
            "Batch 220/1583 processed, running loss: 169.667501, correct predictions: 2613, total: 3536\n",
            "Batch 230/1583 processed, running loss: 176.982523, correct predictions: 2743, total: 3696\n",
            "Batch 240/1583 processed, running loss: 184.460106, correct predictions: 2865, total: 3856\n",
            "Batch 250/1583 processed, running loss: 191.419547, correct predictions: 3000, total: 4016\n",
            "Batch 260/1583 processed, running loss: 198.935863, correct predictions: 3130, total: 4176\n",
            "Batch 270/1583 processed, running loss: 209.072574, correct predictions: 3256, total: 4336\n",
            "Batch 280/1583 processed, running loss: 218.076416, correct predictions: 3378, total: 4496\n",
            "Batch 290/1583 processed, running loss: 227.608321, correct predictions: 3494, total: 4656\n",
            "Batch 300/1583 processed, running loss: 233.533190, correct predictions: 3629, total: 4816\n",
            "Batch 310/1583 processed, running loss: 241.127150, correct predictions: 3752, total: 4976\n",
            "Batch 320/1583 processed, running loss: 249.625521, correct predictions: 3870, total: 5136\n",
            "Batch 330/1583 processed, running loss: 258.160228, correct predictions: 3986, total: 5296\n",
            "Batch 340/1583 processed, running loss: 264.566543, correct predictions: 4121, total: 5456\n",
            "Batch 350/1583 processed, running loss: 270.663655, correct predictions: 4247, total: 5616\n",
            "Batch 360/1583 processed, running loss: 277.702929, correct predictions: 4381, total: 5776\n",
            "Batch 370/1583 processed, running loss: 284.494202, correct predictions: 4514, total: 5936\n",
            "Batch 380/1583 processed, running loss: 290.733637, correct predictions: 4646, total: 6096\n",
            "Batch 390/1583 processed, running loss: 299.260249, correct predictions: 4776, total: 6256\n",
            "Batch 400/1583 processed, running loss: 307.181447, correct predictions: 4904, total: 6416\n",
            "Batch 410/1583 processed, running loss: 317.108490, correct predictions: 5027, total: 6576\n",
            "Batch 420/1583 processed, running loss: 326.316662, correct predictions: 5148, total: 6736\n",
            "Batch 430/1583 processed, running loss: 334.622637, correct predictions: 5262, total: 6896\n",
            "Batch 440/1583 processed, running loss: 342.594418, correct predictions: 5381, total: 7056\n",
            "Batch 450/1583 processed, running loss: 349.320687, correct predictions: 5503, total: 7216\n",
            "Batch 460/1583 processed, running loss: 355.307270, correct predictions: 5626, total: 7376\n",
            "Batch 470/1583 processed, running loss: 361.943023, correct predictions: 5744, total: 7536\n",
            "Batch 480/1583 processed, running loss: 369.696219, correct predictions: 5843, total: 7696\n",
            "Batch 490/1583 processed, running loss: 379.987301, correct predictions: 5958, total: 7856\n",
            "Batch 500/1583 processed, running loss: 387.296842, correct predictions: 6078, total: 8016\n",
            "Batch 510/1583 processed, running loss: 394.774779, correct predictions: 6197, total: 8176\n",
            "Batch 520/1583 processed, running loss: 402.896796, correct predictions: 6316, total: 8336\n",
            "Batch 530/1583 processed, running loss: 411.587210, correct predictions: 6433, total: 8496\n",
            "Batch 540/1583 processed, running loss: 419.022248, correct predictions: 6561, total: 8656\n",
            "Batch 550/1583 processed, running loss: 425.292137, correct predictions: 6681, total: 8816\n",
            "Batch 560/1583 processed, running loss: 434.355846, correct predictions: 6798, total: 8976\n",
            "Batch 570/1583 processed, running loss: 441.937937, correct predictions: 6918, total: 9136\n",
            "Batch 580/1583 processed, running loss: 449.047618, correct predictions: 7044, total: 9296\n",
            "Batch 590/1583 processed, running loss: 456.859195, correct predictions: 7167, total: 9456\n",
            "Batch 600/1583 processed, running loss: 464.119713, correct predictions: 7287, total: 9616\n",
            "Batch 610/1583 processed, running loss: 471.794933, correct predictions: 7411, total: 9776\n",
            "Batch 620/1583 processed, running loss: 480.506787, correct predictions: 7521, total: 9936\n",
            "Batch 630/1583 processed, running loss: 488.682291, correct predictions: 7628, total: 10096\n",
            "Batch 640/1583 processed, running loss: 497.355975, correct predictions: 7741, total: 10256\n",
            "Batch 650/1583 processed, running loss: 506.027053, correct predictions: 7860, total: 10416\n",
            "Batch 660/1583 processed, running loss: 512.994638, correct predictions: 7988, total: 10576\n",
            "Batch 670/1583 processed, running loss: 522.975132, correct predictions: 8109, total: 10736\n",
            "Batch 680/1583 processed, running loss: 529.900273, correct predictions: 8233, total: 10896\n",
            "Batch 690/1583 processed, running loss: 536.506757, correct predictions: 8355, total: 11056\n",
            "Batch 700/1583 processed, running loss: 544.858930, correct predictions: 8478, total: 11216\n",
            "Batch 710/1583 processed, running loss: 554.065094, correct predictions: 8594, total: 11376\n",
            "Batch 720/1583 processed, running loss: 561.018745, correct predictions: 8720, total: 11536\n",
            "Batch 730/1583 processed, running loss: 567.867865, correct predictions: 8847, total: 11696\n",
            "Batch 740/1583 processed, running loss: 574.807752, correct predictions: 8961, total: 11856\n",
            "Batch 750/1583 processed, running loss: 582.966735, correct predictions: 9074, total: 12016\n",
            "Batch 760/1583 processed, running loss: 593.266271, correct predictions: 9183, total: 12176\n",
            "Batch 770/1583 processed, running loss: 602.153861, correct predictions: 9281, total: 12336\n",
            "Batch 780/1583 processed, running loss: 610.079841, correct predictions: 9386, total: 12496\n",
            "Batch 790/1583 processed, running loss: 617.523912, correct predictions: 9506, total: 12656\n",
            "Batch 800/1583 processed, running loss: 626.319876, correct predictions: 9623, total: 12816\n",
            "Batch 810/1583 processed, running loss: 633.931748, correct predictions: 9730, total: 12976\n",
            "Batch 820/1583 processed, running loss: 640.042649, correct predictions: 9854, total: 13136\n",
            "Batch 830/1583 processed, running loss: 647.230110, correct predictions: 9976, total: 13296\n",
            "Batch 840/1583 processed, running loss: 656.746802, correct predictions: 10091, total: 13456\n",
            "Batch 850/1583 processed, running loss: 663.706288, correct predictions: 10207, total: 13616\n",
            "Batch 860/1583 processed, running loss: 670.189671, correct predictions: 10321, total: 13776\n",
            "Batch 870/1583 processed, running loss: 676.730974, correct predictions: 10439, total: 13936\n",
            "Batch 880/1583 processed, running loss: 684.720688, correct predictions: 10561, total: 14096\n",
            "Batch 890/1583 processed, running loss: 692.261952, correct predictions: 10692, total: 14256\n",
            "Batch 900/1583 processed, running loss: 701.328662, correct predictions: 10809, total: 14416\n",
            "Batch 910/1583 processed, running loss: 709.266609, correct predictions: 10937, total: 14576\n",
            "Batch 920/1583 processed, running loss: 716.649855, correct predictions: 11053, total: 14736\n",
            "Batch 930/1583 processed, running loss: 723.170222, correct predictions: 11183, total: 14896\n",
            "Batch 940/1583 processed, running loss: 730.051940, correct predictions: 11305, total: 15056\n",
            "Batch 950/1583 processed, running loss: 738.411667, correct predictions: 11424, total: 15216\n",
            "Batch 960/1583 processed, running loss: 745.580474, correct predictions: 11538, total: 15376\n",
            "Batch 970/1583 processed, running loss: 754.396421, correct predictions: 11639, total: 15536\n",
            "Batch 980/1583 processed, running loss: 761.881196, correct predictions: 11746, total: 15696\n",
            "Batch 990/1583 processed, running loss: 768.753803, correct predictions: 11865, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 775.522494, correct predictions: 11978, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 783.232667, correct predictions: 12088, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 790.828418, correct predictions: 12208, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 799.149128, correct predictions: 12320, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 804.437212, correct predictions: 12449, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 811.316827, correct predictions: 12574, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 816.868435, correct predictions: 12705, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 826.133835, correct predictions: 12830, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 833.900313, correct predictions: 12948, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 841.772293, correct predictions: 13065, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 849.252825, correct predictions: 13193, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 855.531054, correct predictions: 13321, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 865.190030, correct predictions: 13444, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 872.592041, correct predictions: 13571, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 881.090774, correct predictions: 13692, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 888.816818, correct predictions: 13815, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 895.660672, correct predictions: 13937, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 903.346834, correct predictions: 14055, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 912.332125, correct predictions: 14180, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 920.336547, correct predictions: 14311, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 927.524876, correct predictions: 14430, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 937.116605, correct predictions: 14546, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 946.240712, correct predictions: 14672, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 956.271089, correct predictions: 14798, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 964.249722, correct predictions: 14928, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 970.630939, correct predictions: 15055, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 978.115365, correct predictions: 15178, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 985.375164, correct predictions: 15302, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 992.180400, correct predictions: 15417, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 999.829526, correct predictions: 15535, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 1008.052947, correct predictions: 15654, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 1014.504406, correct predictions: 15773, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 1022.673380, correct predictions: 15898, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 1032.053550, correct predictions: 16026, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 1041.238471, correct predictions: 16151, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 1049.012038, correct predictions: 16272, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 1055.502467, correct predictions: 16402, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 1061.002572, correct predictions: 16539, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 1069.043850, correct predictions: 16666, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 1077.877100, correct predictions: 16788, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 1085.797516, correct predictions: 16910, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 1093.408002, correct predictions: 17039, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 1100.793300, correct predictions: 17160, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 1109.418243, correct predictions: 17281, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 1117.279411, correct predictions: 17405, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 1125.599186, correct predictions: 17528, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 1133.035762, correct predictions: 17649, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 1139.798860, correct predictions: 17772, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 1148.399363, correct predictions: 17883, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 1155.895862, correct predictions: 17996, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 1164.226361, correct predictions: 18118, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 1172.534654, correct predictions: 18248, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 1179.700870, correct predictions: 18372, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 1187.454352, correct predictions: 18483, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 1195.409289, correct predictions: 18595, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 1202.988929, correct predictions: 18708, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 1209.294399, correct predictions: 18834, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 1215.556806, correct predictions: 18965, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 1225.159146, correct predictions: 19086, total: 25296\n",
            "\n",
            "Training Loss per batch = 0.775200\tAccuracy on Training set = 75.439497% [19096/25313]\n",
            "\n",
            "Validation Loss per batch = 0.970496\tAccuracy on Validation set = 77.532883% [2181/2813]\n",
            "Train Loss: 0.7752, Train Accuracy: 75.4395\n",
            "Valid Loss: 0.9705, Valid Accuracy: 77.5329\n",
            "\n",
            "Epoch 6/30\n",
            "-------------------------------\n",
            "Epoch: 5, Learning Rate: 0.002500 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0/1583 processed, running loss: 0.378984, correct predictions: 11, total: 16\n",
            "Batch 10/1583 processed, running loss: 6.304281, correct predictions: 146, total: 176\n",
            "Batch 20/1583 processed, running loss: 12.653095, correct predictions: 275, total: 336\n",
            "Batch 30/1583 processed, running loss: 17.999802, correct predictions: 403, total: 496\n",
            "Batch 40/1583 processed, running loss: 25.152975, correct predictions: 535, total: 656\n",
            "Batch 50/1583 processed, running loss: 32.743749, correct predictions: 664, total: 816\n",
            "Batch 60/1583 processed, running loss: 39.832706, correct predictions: 775, total: 976\n",
            "Batch 70/1583 processed, running loss: 47.203790, correct predictions: 902, total: 1136\n",
            "Batch 80/1583 processed, running loss: 54.613447, correct predictions: 1036, total: 1296\n",
            "Batch 90/1583 processed, running loss: 61.311557, correct predictions: 1167, total: 1456\n",
            "Batch 100/1583 processed, running loss: 69.097059, correct predictions: 1290, total: 1616\n",
            "Batch 110/1583 processed, running loss: 75.320610, correct predictions: 1410, total: 1776\n",
            "Batch 120/1583 processed, running loss: 82.089449, correct predictions: 1534, total: 1936\n",
            "Batch 130/1583 processed, running loss: 90.278628, correct predictions: 1663, total: 2096\n",
            "Batch 140/1583 processed, running loss: 97.102348, correct predictions: 1786, total: 2256\n",
            "Batch 150/1583 processed, running loss: 104.253690, correct predictions: 1909, total: 2416\n",
            "Batch 160/1583 processed, running loss: 111.998316, correct predictions: 2032, total: 2576\n",
            "Batch 170/1583 processed, running loss: 117.876069, correct predictions: 2154, total: 2736\n",
            "Batch 180/1583 processed, running loss: 124.625132, correct predictions: 2277, total: 2896\n",
            "Batch 190/1583 processed, running loss: 131.220454, correct predictions: 2401, total: 3056\n",
            "Batch 200/1583 processed, running loss: 138.098337, correct predictions: 2536, total: 3216\n",
            "Batch 210/1583 processed, running loss: 143.419679, correct predictions: 2669, total: 3376\n",
            "Batch 220/1583 processed, running loss: 150.765112, correct predictions: 2797, total: 3536\n",
            "Batch 230/1583 processed, running loss: 157.592986, correct predictions: 2916, total: 3696\n",
            "Batch 240/1583 processed, running loss: 163.347147, correct predictions: 3032, total: 3856\n",
            "Batch 250/1583 processed, running loss: 170.229041, correct predictions: 3149, total: 4016\n",
            "Batch 260/1583 processed, running loss: 176.326247, correct predictions: 3276, total: 4176\n",
            "Batch 270/1583 processed, running loss: 184.539356, correct predictions: 3393, total: 4336\n",
            "Batch 280/1583 processed, running loss: 189.436999, correct predictions: 3528, total: 4496\n",
            "Batch 290/1583 processed, running loss: 196.768850, correct predictions: 3649, total: 4656\n",
            "Batch 300/1583 processed, running loss: 204.605081, correct predictions: 3777, total: 4816\n",
            "Batch 310/1583 processed, running loss: 210.917589, correct predictions: 3914, total: 4976\n",
            "Batch 320/1583 processed, running loss: 217.142465, correct predictions: 4039, total: 5136\n",
            "Batch 330/1583 processed, running loss: 223.195105, correct predictions: 4170, total: 5296\n",
            "Batch 340/1583 processed, running loss: 229.829748, correct predictions: 4289, total: 5456\n",
            "Batch 350/1583 processed, running loss: 236.622982, correct predictions: 4410, total: 5616\n",
            "Batch 360/1583 processed, running loss: 242.899780, correct predictions: 4526, total: 5776\n",
            "Batch 370/1583 processed, running loss: 252.072807, correct predictions: 4637, total: 5936\n",
            "Batch 380/1583 processed, running loss: 259.045752, correct predictions: 4769, total: 6096\n",
            "Batch 390/1583 processed, running loss: 264.560771, correct predictions: 4902, total: 6256\n",
            "Batch 400/1583 processed, running loss: 270.453368, correct predictions: 5037, total: 6416\n",
            "Batch 410/1583 processed, running loss: 277.328804, correct predictions: 5174, total: 6576\n",
            "Batch 420/1583 processed, running loss: 283.812746, correct predictions: 5300, total: 6736\n",
            "Batch 430/1583 processed, running loss: 291.563963, correct predictions: 5419, total: 6896\n",
            "Batch 440/1583 processed, running loss: 297.594578, correct predictions: 5542, total: 7056\n",
            "Batch 450/1583 processed, running loss: 305.620840, correct predictions: 5678, total: 7216\n",
            "Batch 460/1583 processed, running loss: 313.162236, correct predictions: 5805, total: 7376\n",
            "Batch 470/1583 processed, running loss: 319.419994, correct predictions: 5945, total: 7536\n",
            "Batch 480/1583 processed, running loss: 324.931310, correct predictions: 6073, total: 7696\n",
            "Batch 490/1583 processed, running loss: 332.624829, correct predictions: 6195, total: 7856\n",
            "Batch 500/1583 processed, running loss: 339.033557, correct predictions: 6328, total: 8016\n",
            "Batch 510/1583 processed, running loss: 344.882974, correct predictions: 6461, total: 8176\n",
            "Batch 520/1583 processed, running loss: 350.300090, correct predictions: 6599, total: 8336\n",
            "Batch 530/1583 processed, running loss: 356.560263, correct predictions: 6736, total: 8496\n",
            "Batch 540/1583 processed, running loss: 363.196372, correct predictions: 6864, total: 8656\n",
            "Batch 550/1583 processed, running loss: 371.484387, correct predictions: 6989, total: 8816\n",
            "Batch 560/1583 processed, running loss: 376.985829, correct predictions: 7123, total: 8976\n",
            "Batch 570/1583 processed, running loss: 384.818627, correct predictions: 7251, total: 9136\n",
            "Batch 580/1583 processed, running loss: 391.041979, correct predictions: 7380, total: 9296\n",
            "Batch 590/1583 processed, running loss: 397.055085, correct predictions: 7505, total: 9456\n",
            "Batch 600/1583 processed, running loss: 403.930707, correct predictions: 7628, total: 9616\n",
            "Batch 610/1583 processed, running loss: 411.944982, correct predictions: 7749, total: 9776\n",
            "Batch 620/1583 processed, running loss: 418.539806, correct predictions: 7877, total: 9936\n",
            "Batch 630/1583 processed, running loss: 424.919130, correct predictions: 8004, total: 10096\n",
            "Batch 640/1583 processed, running loss: 433.363414, correct predictions: 8115, total: 10256\n",
            "Batch 650/1583 processed, running loss: 441.162633, correct predictions: 8237, total: 10416\n",
            "Batch 660/1583 processed, running loss: 447.754268, correct predictions: 8357, total: 10576\n",
            "Batch 670/1583 processed, running loss: 455.228278, correct predictions: 8477, total: 10736\n",
            "Batch 680/1583 processed, running loss: 461.664080, correct predictions: 8616, total: 10896\n",
            "Batch 690/1583 processed, running loss: 469.708557, correct predictions: 8741, total: 11056\n",
            "Batch 700/1583 processed, running loss: 476.475646, correct predictions: 8858, total: 11216\n",
            "Batch 710/1583 processed, running loss: 483.040545, correct predictions: 8983, total: 11376\n",
            "Batch 720/1583 processed, running loss: 490.212828, correct predictions: 9111, total: 11536\n",
            "Batch 730/1583 processed, running loss: 496.923802, correct predictions: 9237, total: 11696\n",
            "Batch 740/1583 processed, running loss: 503.083087, correct predictions: 9364, total: 11856\n",
            "Batch 750/1583 processed, running loss: 508.746810, correct predictions: 9493, total: 12016\n",
            "Batch 760/1583 processed, running loss: 514.236017, correct predictions: 9620, total: 12176\n",
            "Batch 770/1583 processed, running loss: 520.891025, correct predictions: 9740, total: 12336\n",
            "Batch 780/1583 processed, running loss: 528.138762, correct predictions: 9867, total: 12496\n",
            "Batch 790/1583 processed, running loss: 534.080296, correct predictions: 10000, total: 12656\n",
            "Batch 800/1583 processed, running loss: 542.720929, correct predictions: 10125, total: 12816\n",
            "Batch 810/1583 processed, running loss: 548.442852, correct predictions: 10251, total: 12976\n",
            "Batch 820/1583 processed, running loss: 554.794062, correct predictions: 10376, total: 13136\n",
            "Batch 830/1583 processed, running loss: 562.813098, correct predictions: 10496, total: 13296\n",
            "Batch 840/1583 processed, running loss: 569.797334, correct predictions: 10615, total: 13456\n",
            "Batch 850/1583 processed, running loss: 576.499182, correct predictions: 10741, total: 13616\n",
            "Batch 860/1583 processed, running loss: 583.735198, correct predictions: 10858, total: 13776\n",
            "Batch 870/1583 processed, running loss: 593.282593, correct predictions: 10978, total: 13936\n",
            "Batch 880/1583 processed, running loss: 599.869883, correct predictions: 11104, total: 14096\n",
            "Batch 890/1583 processed, running loss: 606.656174, correct predictions: 11231, total: 14256\n",
            "Batch 900/1583 processed, running loss: 613.524258, correct predictions: 11359, total: 14416\n",
            "Batch 910/1583 processed, running loss: 619.203827, correct predictions: 11484, total: 14576\n",
            "Batch 920/1583 processed, running loss: 624.702532, correct predictions: 11616, total: 14736\n",
            "Batch 930/1583 processed, running loss: 633.195083, correct predictions: 11736, total: 14896\n",
            "Batch 940/1583 processed, running loss: 639.857209, correct predictions: 11861, total: 15056\n",
            "Batch 950/1583 processed, running loss: 645.599711, correct predictions: 11993, total: 15216\n",
            "Batch 960/1583 processed, running loss: 652.073459, correct predictions: 12115, total: 15376\n",
            "Batch 970/1583 processed, running loss: 656.903933, correct predictions: 12251, total: 15536\n",
            "Batch 980/1583 processed, running loss: 664.177934, correct predictions: 12382, total: 15696\n",
            "Batch 990/1583 processed, running loss: 670.445326, correct predictions: 12505, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 677.003346, correct predictions: 12634, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 683.350777, correct predictions: 12760, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 691.078463, correct predictions: 12887, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 698.864517, correct predictions: 13004, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 706.145877, correct predictions: 13126, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 712.814734, correct predictions: 13238, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 720.634263, correct predictions: 13350, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 726.942702, correct predictions: 13473, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 732.393958, correct predictions: 13600, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 739.462316, correct predictions: 13725, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 745.938866, correct predictions: 13848, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 753.313924, correct predictions: 13966, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 761.551279, correct predictions: 14074, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 767.858659, correct predictions: 14188, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 775.171298, correct predictions: 14310, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 782.645829, correct predictions: 14421, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 789.111961, correct predictions: 14532, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 796.391134, correct predictions: 14638, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 802.450832, correct predictions: 14759, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 810.778616, correct predictions: 14878, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 817.472936, correct predictions: 14998, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 825.570809, correct predictions: 15126, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 832.424668, correct predictions: 15263, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 838.991474, correct predictions: 15397, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 844.193310, correct predictions: 15537, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 850.720812, correct predictions: 15664, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 859.357813, correct predictions: 15787, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 867.549027, correct predictions: 15912, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 874.438534, correct predictions: 16038, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 883.177400, correct predictions: 16154, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 893.098244, correct predictions: 16274, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 900.421895, correct predictions: 16382, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 908.052103, correct predictions: 16511, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 914.413436, correct predictions: 16637, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 921.645506, correct predictions: 16765, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 929.237231, correct predictions: 16882, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 934.915521, correct predictions: 17023, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 940.995537, correct predictions: 17152, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 947.695393, correct predictions: 17274, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 956.122528, correct predictions: 17398, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 963.788867, correct predictions: 17525, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 971.124226, correct predictions: 17637, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 977.677987, correct predictions: 17761, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 983.893830, correct predictions: 17892, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 992.185085, correct predictions: 18014, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 999.039776, correct predictions: 18138, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 1006.075232, correct predictions: 18266, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 1013.376720, correct predictions: 18385, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 1019.719390, correct predictions: 18510, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 1027.863413, correct predictions: 18612, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 1035.385447, correct predictions: 18730, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 1041.840444, correct predictions: 18863, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 1047.843541, correct predictions: 18986, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 1055.003949, correct predictions: 19113, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 1061.585959, correct predictions: 19232, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 1069.553530, correct predictions: 19352, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 1076.003448, correct predictions: 19478, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 1082.634076, correct predictions: 19601, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 1088.703099, correct predictions: 19734, total: 25296\n",
            "\n",
            "Training Loss per batch = 0.688566\tAccuracy on Training set = 78.023150% [19750/25313]\n",
            "\n",
            "Validation Loss per batch = 1.045974\tAccuracy on Validation set = 74.440100% [2094/2813]\n",
            "Train Loss: 0.6886, Train Accuracy: 78.0232\n",
            "Valid Loss: 1.0460, Valid Accuracy: 74.4401\n",
            "\n",
            "Epoch 7/30\n",
            "-------------------------------\n",
            "Epoch: 6, Learning Rate: 0.002500 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0/1583 processed, running loss: 0.530251, correct predictions: 15, total: 16\n",
            "Batch 10/1583 processed, running loss: 6.591845, correct predictions: 142, total: 176\n",
            "Batch 20/1583 processed, running loss: 12.053524, correct predictions: 280, total: 336\n",
            "Batch 30/1583 processed, running loss: 17.527500, correct predictions: 407, total: 496\n",
            "Batch 40/1583 processed, running loss: 23.596253, correct predictions: 537, total: 656\n",
            "Batch 50/1583 processed, running loss: 28.358743, correct predictions: 678, total: 816\n",
            "Batch 60/1583 processed, running loss: 33.517399, correct predictions: 815, total: 976\n",
            "Batch 70/1583 processed, running loss: 40.638899, correct predictions: 942, total: 1136\n",
            "Batch 80/1583 processed, running loss: 47.428041, correct predictions: 1074, total: 1296\n",
            "Batch 90/1583 processed, running loss: 52.119540, correct predictions: 1214, total: 1456\n",
            "Batch 100/1583 processed, running loss: 59.675892, correct predictions: 1340, total: 1616\n",
            "Batch 110/1583 processed, running loss: 64.929423, correct predictions: 1474, total: 1776\n",
            "Batch 120/1583 processed, running loss: 70.557651, correct predictions: 1605, total: 1936\n",
            "Batch 130/1583 processed, running loss: 76.286522, correct predictions: 1734, total: 2096\n",
            "Batch 140/1583 processed, running loss: 82.530254, correct predictions: 1860, total: 2256\n",
            "Batch 150/1583 processed, running loss: 89.198551, correct predictions: 1983, total: 2416\n",
            "Batch 160/1583 processed, running loss: 94.035526, correct predictions: 2116, total: 2576\n",
            "Batch 170/1583 processed, running loss: 100.245716, correct predictions: 2247, total: 2736\n",
            "Batch 180/1583 processed, running loss: 106.591152, correct predictions: 2373, total: 2896\n",
            "Batch 190/1583 processed, running loss: 113.628423, correct predictions: 2505, total: 3056\n",
            "Batch 200/1583 processed, running loss: 119.085531, correct predictions: 2635, total: 3216\n",
            "Batch 210/1583 processed, running loss: 124.338541, correct predictions: 2758, total: 3376\n",
            "Batch 220/1583 processed, running loss: 130.947105, correct predictions: 2889, total: 3536\n",
            "Batch 230/1583 processed, running loss: 137.355472, correct predictions: 3015, total: 3696\n",
            "Batch 240/1583 processed, running loss: 144.133667, correct predictions: 3148, total: 3856\n",
            "Batch 250/1583 processed, running loss: 149.040909, correct predictions: 3276, total: 4016\n",
            "Batch 260/1583 processed, running loss: 154.890597, correct predictions: 3405, total: 4176\n",
            "Batch 270/1583 processed, running loss: 160.308437, correct predictions: 3541, total: 4336\n",
            "Batch 280/1583 processed, running loss: 168.432078, correct predictions: 3671, total: 4496\n",
            "Batch 290/1583 processed, running loss: 175.701362, correct predictions: 3803, total: 4656\n",
            "Batch 300/1583 processed, running loss: 181.334637, correct predictions: 3926, total: 4816\n",
            "Batch 310/1583 processed, running loss: 188.225011, correct predictions: 4046, total: 4976\n",
            "Batch 320/1583 processed, running loss: 195.914013, correct predictions: 4169, total: 5136\n",
            "Batch 330/1583 processed, running loss: 203.537358, correct predictions: 4287, total: 5296\n",
            "Batch 340/1583 processed, running loss: 210.212546, correct predictions: 4419, total: 5456\n",
            "Batch 350/1583 processed, running loss: 216.140724, correct predictions: 4552, total: 5616\n",
            "Batch 360/1583 processed, running loss: 222.567464, correct predictions: 4672, total: 5776\n",
            "Batch 370/1583 processed, running loss: 227.881004, correct predictions: 4802, total: 5936\n",
            "Batch 380/1583 processed, running loss: 233.289999, correct predictions: 4938, total: 6096\n",
            "Batch 390/1583 processed, running loss: 239.010349, correct predictions: 5062, total: 6256\n",
            "Batch 400/1583 processed, running loss: 244.987408, correct predictions: 5187, total: 6416\n",
            "Batch 410/1583 processed, running loss: 250.829213, correct predictions: 5317, total: 6576\n",
            "Batch 420/1583 processed, running loss: 257.731030, correct predictions: 5449, total: 6736\n",
            "Batch 430/1583 processed, running loss: 263.862799, correct predictions: 5571, total: 6896\n",
            "Batch 440/1583 processed, running loss: 268.785954, correct predictions: 5699, total: 7056\n",
            "Batch 450/1583 processed, running loss: 274.385637, correct predictions: 5825, total: 7216\n",
            "Batch 460/1583 processed, running loss: 281.584830, correct predictions: 5953, total: 7376\n",
            "Batch 470/1583 processed, running loss: 287.844372, correct predictions: 6070, total: 7536\n",
            "Batch 480/1583 processed, running loss: 293.351201, correct predictions: 6202, total: 7696\n",
            "Batch 490/1583 processed, running loss: 299.744882, correct predictions: 6324, total: 7856\n",
            "Batch 500/1583 processed, running loss: 304.478040, correct predictions: 6462, total: 8016\n",
            "Batch 510/1583 processed, running loss: 310.448294, correct predictions: 6586, total: 8176\n",
            "Batch 520/1583 processed, running loss: 316.465117, correct predictions: 6725, total: 8336\n",
            "Batch 530/1583 processed, running loss: 322.673852, correct predictions: 6851, total: 8496\n",
            "Batch 540/1583 processed, running loss: 328.252907, correct predictions: 6989, total: 8656\n",
            "Batch 550/1583 processed, running loss: 333.250730, correct predictions: 7127, total: 8816\n",
            "Batch 560/1583 processed, running loss: 338.194042, correct predictions: 7268, total: 8976\n",
            "Batch 570/1583 processed, running loss: 343.865232, correct predictions: 7405, total: 9136\n",
            "Batch 580/1583 processed, running loss: 349.774192, correct predictions: 7542, total: 9296\n",
            "Batch 590/1583 processed, running loss: 354.631763, correct predictions: 7687, total: 9456\n",
            "Batch 600/1583 processed, running loss: 363.630483, correct predictions: 7811, total: 9616\n",
            "Batch 610/1583 processed, running loss: 368.903429, correct predictions: 7944, total: 9776\n",
            "Batch 620/1583 processed, running loss: 374.792312, correct predictions: 8071, total: 9936\n",
            "Batch 630/1583 processed, running loss: 380.763922, correct predictions: 8198, total: 10096\n",
            "Batch 640/1583 processed, running loss: 386.257621, correct predictions: 8332, total: 10256\n",
            "Batch 650/1583 processed, running loss: 393.649734, correct predictions: 8461, total: 10416\n",
            "Batch 660/1583 processed, running loss: 400.292546, correct predictions: 8578, total: 10576\n",
            "Batch 670/1583 processed, running loss: 407.188393, correct predictions: 8715, total: 10736\n",
            "Batch 680/1583 processed, running loss: 413.102861, correct predictions: 8846, total: 10896\n",
            "Batch 690/1583 processed, running loss: 417.905559, correct predictions: 8982, total: 11056\n",
            "Batch 700/1583 processed, running loss: 423.357495, correct predictions: 9120, total: 11216\n",
            "Batch 710/1583 processed, running loss: 431.590852, correct predictions: 9247, total: 11376\n",
            "Batch 720/1583 processed, running loss: 436.900060, correct predictions: 9375, total: 11536\n",
            "Batch 730/1583 processed, running loss: 442.972511, correct predictions: 9508, total: 11696\n",
            "Batch 740/1583 processed, running loss: 448.955302, correct predictions: 9643, total: 11856\n",
            "Batch 750/1583 processed, running loss: 457.505489, correct predictions: 9766, total: 12016\n",
            "Batch 760/1583 processed, running loss: 464.969934, correct predictions: 9884, total: 12176\n",
            "Batch 770/1583 processed, running loss: 471.361423, correct predictions: 10010, total: 12336\n",
            "Batch 780/1583 processed, running loss: 478.651262, correct predictions: 10137, total: 12496\n",
            "Batch 790/1583 processed, running loss: 484.864128, correct predictions: 10269, total: 12656\n",
            "Batch 800/1583 processed, running loss: 489.720380, correct predictions: 10398, total: 12816\n",
            "Batch 810/1583 processed, running loss: 495.956407, correct predictions: 10525, total: 12976\n",
            "Batch 820/1583 processed, running loss: 503.282535, correct predictions: 10642, total: 13136\n",
            "Batch 830/1583 processed, running loss: 508.209097, correct predictions: 10777, total: 13296\n",
            "Batch 840/1583 processed, running loss: 514.873662, correct predictions: 10901, total: 13456\n",
            "Batch 850/1583 processed, running loss: 521.478283, correct predictions: 11029, total: 13616\n",
            "Batch 860/1583 processed, running loss: 527.660869, correct predictions: 11152, total: 13776\n",
            "Batch 870/1583 processed, running loss: 535.642277, correct predictions: 11276, total: 13936\n",
            "Batch 880/1583 processed, running loss: 542.157567, correct predictions: 11406, total: 14096\n",
            "Batch 890/1583 processed, running loss: 549.812458, correct predictions: 11525, total: 14256\n",
            "Batch 900/1583 processed, running loss: 556.298806, correct predictions: 11664, total: 14416\n",
            "Batch 910/1583 processed, running loss: 561.372541, correct predictions: 11798, total: 14576\n",
            "Batch 920/1583 processed, running loss: 568.302973, correct predictions: 11925, total: 14736\n",
            "Batch 930/1583 processed, running loss: 573.556327, correct predictions: 12058, total: 14896\n",
            "Batch 940/1583 processed, running loss: 578.004446, correct predictions: 12200, total: 15056\n",
            "Batch 950/1583 processed, running loss: 583.919326, correct predictions: 12329, total: 15216\n",
            "Batch 960/1583 processed, running loss: 590.674872, correct predictions: 12453, total: 15376\n",
            "Batch 970/1583 processed, running loss: 597.654806, correct predictions: 12574, total: 15536\n",
            "Batch 980/1583 processed, running loss: 603.192929, correct predictions: 12691, total: 15696\n",
            "Batch 990/1583 processed, running loss: 608.331792, correct predictions: 12807, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 615.104791, correct predictions: 12937, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 621.939794, correct predictions: 13054, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 628.288418, correct predictions: 13174, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 633.723996, correct predictions: 13306, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 639.770187, correct predictions: 13426, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 646.440284, correct predictions: 13554, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 653.284694, correct predictions: 13675, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 660.164749, correct predictions: 13796, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 665.686325, correct predictions: 13934, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 671.404566, correct predictions: 14058, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 677.142429, correct predictions: 14178, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 682.743120, correct predictions: 14309, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 687.946826, correct predictions: 14441, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 694.481361, correct predictions: 14575, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 700.751913, correct predictions: 14717, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 707.194497, correct predictions: 14851, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 713.696071, correct predictions: 14982, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 719.540232, correct predictions: 15112, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 727.293677, correct predictions: 15230, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 732.147365, correct predictions: 15366, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 738.422279, correct predictions: 15504, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 744.687326, correct predictions: 15636, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 749.482910, correct predictions: 15768, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 754.452617, correct predictions: 15901, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 759.857303, correct predictions: 16046, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 766.272855, correct predictions: 16175, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 773.950123, correct predictions: 16305, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 779.737957, correct predictions: 16433, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 786.635692, correct predictions: 16562, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 792.562889, correct predictions: 16694, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 798.290368, correct predictions: 16822, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 805.094494, correct predictions: 16953, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 810.085343, correct predictions: 17079, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 816.133032, correct predictions: 17206, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 823.819542, correct predictions: 17332, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 829.378694, correct predictions: 17450, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 836.109477, correct predictions: 17572, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 843.641006, correct predictions: 17692, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 850.150311, correct predictions: 17821, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 856.509545, correct predictions: 17954, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 862.060282, correct predictions: 18074, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 869.441185, correct predictions: 18202, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 875.409212, correct predictions: 18333, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 881.109314, correct predictions: 18458, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 888.249025, correct predictions: 18581, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 893.652221, correct predictions: 18705, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 897.722345, correct predictions: 18836, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 904.780957, correct predictions: 18959, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 910.050904, correct predictions: 19091, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 916.267884, correct predictions: 19211, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 922.987174, correct predictions: 19325, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 928.760189, correct predictions: 19440, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 934.687916, correct predictions: 19554, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 940.806787, correct predictions: 19676, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 947.306348, correct predictions: 19788, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 953.257402, correct predictions: 19919, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 959.075508, correct predictions: 20042, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 965.266474, correct predictions: 20175, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 972.344793, correct predictions: 20305, total: 25296\n",
            "\n",
            "Training Loss per batch = 0.614881\tAccuracy on Training set = 80.271007% [20319/25313]\n",
            "\n",
            "Validation Loss per batch = 1.086407\tAccuracy on Validation set = 79.381443% [2233/2813]\n",
            "Train Loss: 0.6149, Train Accuracy: 80.2710\n",
            "Valid Loss: 1.0864, Valid Accuracy: 79.3814\n",
            "\n",
            "Epoch 8/30\n",
            "-------------------------------\n",
            "Epoch: 7, Learning Rate: 0.002500 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0/1583 processed, running loss: 0.201548, correct predictions: 16, total: 16\n",
            "Batch 10/1583 processed, running loss: 6.388894, correct predictions: 141, total: 176\n",
            "Batch 20/1583 processed, running loss: 12.164087, correct predictions: 274, total: 336\n",
            "Batch 30/1583 processed, running loss: 17.888700, correct predictions: 404, total: 496\n",
            "Batch 40/1583 processed, running loss: 23.645268, correct predictions: 538, total: 656\n",
            "Batch 50/1583 processed, running loss: 28.472539, correct predictions: 676, total: 816\n",
            "Batch 60/1583 processed, running loss: 33.130411, correct predictions: 815, total: 976\n",
            "Batch 70/1583 processed, running loss: 39.563095, correct predictions: 952, total: 1136\n",
            "Batch 80/1583 processed, running loss: 45.010694, correct predictions: 1082, total: 1296\n",
            "Batch 90/1583 processed, running loss: 49.472130, correct predictions: 1210, total: 1456\n",
            "Batch 100/1583 processed, running loss: 53.417494, correct predictions: 1344, total: 1616\n",
            "Batch 110/1583 processed, running loss: 58.113744, correct predictions: 1478, total: 1776\n",
            "Batch 120/1583 processed, running loss: 63.051583, correct predictions: 1615, total: 1936\n",
            "Batch 130/1583 processed, running loss: 67.965045, correct predictions: 1750, total: 2096\n",
            "Batch 140/1583 processed, running loss: 74.318943, correct predictions: 1892, total: 2256\n",
            "Batch 150/1583 processed, running loss: 79.145690, correct predictions: 2027, total: 2416\n",
            "Batch 160/1583 processed, running loss: 83.911816, correct predictions: 2166, total: 2576\n",
            "Batch 170/1583 processed, running loss: 88.413086, correct predictions: 2309, total: 2736\n",
            "Batch 180/1583 processed, running loss: 93.380184, correct predictions: 2437, total: 2896\n",
            "Batch 190/1583 processed, running loss: 99.014075, correct predictions: 2572, total: 3056\n",
            "Batch 200/1583 processed, running loss: 103.274235, correct predictions: 2713, total: 3216\n",
            "Batch 210/1583 processed, running loss: 108.635821, correct predictions: 2845, total: 3376\n",
            "Batch 220/1583 processed, running loss: 114.234611, correct predictions: 2973, total: 3536\n",
            "Batch 230/1583 processed, running loss: 119.407736, correct predictions: 3111, total: 3696\n",
            "Batch 240/1583 processed, running loss: 124.400368, correct predictions: 3245, total: 3856\n",
            "Batch 250/1583 processed, running loss: 129.572167, correct predictions: 3373, total: 4016\n",
            "Batch 260/1583 processed, running loss: 138.161764, correct predictions: 3498, total: 4176\n",
            "Batch 270/1583 processed, running loss: 143.702701, correct predictions: 3641, total: 4336\n",
            "Batch 280/1583 processed, running loss: 150.285145, correct predictions: 3772, total: 4496\n",
            "Batch 290/1583 processed, running loss: 153.645921, correct predictions: 3900, total: 4656\n",
            "Batch 300/1583 processed, running loss: 160.591080, correct predictions: 4020, total: 4816\n",
            "Batch 310/1583 processed, running loss: 165.466413, correct predictions: 4147, total: 4976\n",
            "Batch 320/1583 processed, running loss: 170.330821, correct predictions: 4280, total: 5136\n",
            "Batch 330/1583 processed, running loss: 175.962863, correct predictions: 4410, total: 5296\n",
            "Batch 340/1583 processed, running loss: 180.202625, correct predictions: 4552, total: 5456\n",
            "Batch 350/1583 processed, running loss: 185.854982, correct predictions: 4683, total: 5616\n",
            "Batch 360/1583 processed, running loss: 190.815145, correct predictions: 4817, total: 5776\n",
            "Batch 370/1583 processed, running loss: 194.980803, correct predictions: 4953, total: 5936\n",
            "Batch 380/1583 processed, running loss: 201.064801, correct predictions: 5080, total: 6096\n",
            "Batch 390/1583 processed, running loss: 205.598606, correct predictions: 5224, total: 6256\n",
            "Batch 400/1583 processed, running loss: 210.518723, correct predictions: 5357, total: 6416\n",
            "Batch 410/1583 processed, running loss: 215.639786, correct predictions: 5496, total: 6576\n",
            "Batch 420/1583 processed, running loss: 220.399982, correct predictions: 5628, total: 6736\n",
            "Batch 430/1583 processed, running loss: 225.800383, correct predictions: 5756, total: 6896\n",
            "Batch 440/1583 processed, running loss: 232.253342, correct predictions: 5880, total: 7056\n",
            "Batch 450/1583 processed, running loss: 238.441432, correct predictions: 6012, total: 7216\n",
            "Batch 460/1583 processed, running loss: 243.123909, correct predictions: 6147, total: 7376\n",
            "Batch 470/1583 processed, running loss: 248.269709, correct predictions: 6274, total: 7536\n",
            "Batch 480/1583 processed, running loss: 252.440450, correct predictions: 6406, total: 7696\n",
            "Batch 490/1583 processed, running loss: 257.372878, correct predictions: 6538, total: 7856\n",
            "Batch 500/1583 processed, running loss: 263.097286, correct predictions: 6668, total: 8016\n",
            "Batch 510/1583 processed, running loss: 268.628629, correct predictions: 6798, total: 8176\n",
            "Batch 520/1583 processed, running loss: 273.046413, correct predictions: 6933, total: 8336\n",
            "Batch 530/1583 processed, running loss: 279.291131, correct predictions: 7066, total: 8496\n",
            "Batch 540/1583 processed, running loss: 285.066728, correct predictions: 7202, total: 8656\n",
            "Batch 550/1583 processed, running loss: 291.125440, correct predictions: 7332, total: 8816\n",
            "Batch 560/1583 processed, running loss: 297.945802, correct predictions: 7462, total: 8976\n",
            "Batch 570/1583 processed, running loss: 302.276973, correct predictions: 7600, total: 9136\n",
            "Batch 580/1583 processed, running loss: 308.028054, correct predictions: 7730, total: 9296\n",
            "Batch 590/1583 processed, running loss: 313.097905, correct predictions: 7854, total: 9456\n",
            "Batch 600/1583 processed, running loss: 318.323523, correct predictions: 7984, total: 9616\n",
            "Batch 610/1583 processed, running loss: 323.457797, correct predictions: 8107, total: 9776\n",
            "Batch 620/1583 processed, running loss: 328.204505, correct predictions: 8241, total: 9936\n",
            "Batch 630/1583 processed, running loss: 333.174869, correct predictions: 8374, total: 10096\n",
            "Batch 640/1583 processed, running loss: 338.933154, correct predictions: 8517, total: 10256\n",
            "Batch 650/1583 processed, running loss: 344.777522, correct predictions: 8648, total: 10416\n",
            "Batch 660/1583 processed, running loss: 349.732359, correct predictions: 8782, total: 10576\n",
            "Batch 670/1583 processed, running loss: 353.530656, correct predictions: 8912, total: 10736\n",
            "Batch 680/1583 processed, running loss: 358.546805, correct predictions: 9030, total: 10896\n",
            "Batch 690/1583 processed, running loss: 363.329380, correct predictions: 9157, total: 11056\n",
            "Batch 700/1583 processed, running loss: 368.373395, correct predictions: 9299, total: 11216\n",
            "Batch 710/1583 processed, running loss: 374.407329, correct predictions: 9425, total: 11376\n",
            "Batch 720/1583 processed, running loss: 379.576076, correct predictions: 9563, total: 11536\n",
            "Batch 730/1583 processed, running loss: 385.297383, correct predictions: 9690, total: 11696\n",
            "Batch 740/1583 processed, running loss: 388.553389, correct predictions: 9839, total: 11856\n",
            "Batch 750/1583 processed, running loss: 393.312503, correct predictions: 9979, total: 12016\n",
            "Batch 760/1583 processed, running loss: 398.599123, correct predictions: 10112, total: 12176\n",
            "Batch 770/1583 processed, running loss: 404.989769, correct predictions: 10248, total: 12336\n",
            "Batch 780/1583 processed, running loss: 410.185247, correct predictions: 10373, total: 12496\n",
            "Batch 790/1583 processed, running loss: 416.246747, correct predictions: 10503, total: 12656\n",
            "Batch 800/1583 processed, running loss: 420.625978, correct predictions: 10638, total: 12816\n",
            "Batch 810/1583 processed, running loss: 424.567420, correct predictions: 10779, total: 12976\n",
            "Batch 820/1583 processed, running loss: 429.115345, correct predictions: 10909, total: 13136\n",
            "Batch 830/1583 processed, running loss: 433.465432, correct predictions: 11041, total: 13296\n",
            "Batch 840/1583 processed, running loss: 437.523204, correct predictions: 11172, total: 13456\n",
            "Batch 850/1583 processed, running loss: 442.877257, correct predictions: 11305, total: 13616\n",
            "Batch 860/1583 processed, running loss: 448.336035, correct predictions: 11430, total: 13776\n",
            "Batch 870/1583 processed, running loss: 453.869429, correct predictions: 11563, total: 13936\n",
            "Batch 880/1583 processed, running loss: 458.404699, correct predictions: 11695, total: 14096\n",
            "Batch 890/1583 processed, running loss: 463.700339, correct predictions: 11834, total: 14256\n",
            "Batch 900/1583 processed, running loss: 467.398068, correct predictions: 11966, total: 14416\n",
            "Batch 910/1583 processed, running loss: 472.740901, correct predictions: 12091, total: 14576\n",
            "Batch 920/1583 processed, running loss: 477.665737, correct predictions: 12226, total: 14736\n",
            "Batch 930/1583 processed, running loss: 484.246839, correct predictions: 12350, total: 14896\n",
            "Batch 940/1583 processed, running loss: 488.423108, correct predictions: 12488, total: 15056\n",
            "Batch 950/1583 processed, running loss: 493.074764, correct predictions: 12626, total: 15216\n",
            "Batch 960/1583 processed, running loss: 498.816246, correct predictions: 12763, total: 15376\n",
            "Batch 970/1583 processed, running loss: 507.385536, correct predictions: 12890, total: 15536\n",
            "Batch 980/1583 processed, running loss: 512.205773, correct predictions: 13025, total: 15696\n",
            "Batch 990/1583 processed, running loss: 517.895698, correct predictions: 13158, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 521.922646, correct predictions: 13295, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 526.834217, correct predictions: 13421, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 535.304300, correct predictions: 13533, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 543.071822, correct predictions: 13653, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 549.290671, correct predictions: 13783, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 556.664920, correct predictions: 13910, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 562.133779, correct predictions: 14038, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 568.194998, correct predictions: 14158, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 572.111439, correct predictions: 14296, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 577.671362, correct predictions: 14424, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 582.601248, correct predictions: 14556, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 587.071464, correct predictions: 14685, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 593.146471, correct predictions: 14807, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 597.371775, correct predictions: 14931, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 602.255294, correct predictions: 15056, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 607.548847, correct predictions: 15190, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 612.450130, correct predictions: 15319, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 616.352006, correct predictions: 15459, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 621.684097, correct predictions: 15577, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 628.044168, correct predictions: 15701, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 634.142499, correct predictions: 15834, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 638.323305, correct predictions: 15972, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 643.015100, correct predictions: 16107, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 648.144061, correct predictions: 16233, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 654.026870, correct predictions: 16348, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 658.758861, correct predictions: 16467, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 665.148525, correct predictions: 16595, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 670.430716, correct predictions: 16725, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 676.453663, correct predictions: 16849, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 680.639712, correct predictions: 16981, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 686.438884, correct predictions: 17108, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 693.140477, correct predictions: 17229, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 698.637113, correct predictions: 17352, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 704.536806, correct predictions: 17459, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 709.346261, correct predictions: 17587, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 715.870320, correct predictions: 17700, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 720.741064, correct predictions: 17819, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 726.370815, correct predictions: 17942, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 731.667298, correct predictions: 18068, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 736.539964, correct predictions: 18200, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 744.698681, correct predictions: 18318, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 750.246786, correct predictions: 18449, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 755.438256, correct predictions: 18575, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 760.590657, correct predictions: 18710, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 765.434060, correct predictions: 18844, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 772.103438, correct predictions: 18973, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 779.581206, correct predictions: 19098, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 785.206932, correct predictions: 19235, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 793.027078, correct predictions: 19350, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 799.851334, correct predictions: 19471, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 804.893254, correct predictions: 19602, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 811.665312, correct predictions: 19726, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 816.101335, correct predictions: 19861, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 822.422950, correct predictions: 19985, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 828.952086, correct predictions: 20115, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 833.113280, correct predictions: 20252, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 839.818934, correct predictions: 20372, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 846.657090, correct predictions: 20499, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 853.340628, correct predictions: 20628, total: 25296\n",
            "\n",
            "Training Loss per batch = 0.539714\tAccuracy on Training set = 81.539130% [20640/25313]\n",
            "\n",
            "Validation Loss per batch = 1.117733\tAccuracy on Validation set = 79.061500% [2224/2813]\n",
            "Train Loss: 0.5397, Train Accuracy: 81.5391\n",
            "Valid Loss: 1.1177, Valid Accuracy: 79.0615\n",
            "\n",
            "Epoch 9/30\n",
            "-------------------------------\n",
            "Epoch: 8, Learning Rate: 0.001250 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0/1583 processed, running loss: 0.342132, correct predictions: 14, total: 16\n",
            "Batch 10/1583 processed, running loss: 5.028346, correct predictions: 145, total: 176\n",
            "Batch 20/1583 processed, running loss: 9.906145, correct predictions: 271, total: 336\n",
            "Batch 30/1583 processed, running loss: 14.787631, correct predictions: 406, total: 496\n",
            "Batch 40/1583 processed, running loss: 18.563215, correct predictions: 542, total: 656\n",
            "Batch 50/1583 processed, running loss: 24.130592, correct predictions: 677, total: 816\n",
            "Batch 60/1583 processed, running loss: 29.151856, correct predictions: 814, total: 976\n",
            "Batch 70/1583 processed, running loss: 33.763846, correct predictions: 949, total: 1136\n",
            "Batch 80/1583 processed, running loss: 37.432492, correct predictions: 1080, total: 1296\n",
            "Batch 90/1583 processed, running loss: 42.354582, correct predictions: 1212, total: 1456\n",
            "Batch 100/1583 processed, running loss: 46.428144, correct predictions: 1356, total: 1616\n",
            "Batch 110/1583 processed, running loss: 49.735130, correct predictions: 1497, total: 1776\n",
            "Batch 120/1583 processed, running loss: 53.867761, correct predictions: 1637, total: 1936\n",
            "Batch 130/1583 processed, running loss: 57.905560, correct predictions: 1769, total: 2096\n",
            "Batch 140/1583 processed, running loss: 62.583855, correct predictions: 1906, total: 2256\n",
            "Batch 150/1583 processed, running loss: 66.683354, correct predictions: 2046, total: 2416\n",
            "Batch 160/1583 processed, running loss: 71.434738, correct predictions: 2184, total: 2576\n",
            "Batch 170/1583 processed, running loss: 75.814041, correct predictions: 2319, total: 2736\n",
            "Batch 180/1583 processed, running loss: 79.518564, correct predictions: 2461, total: 2896\n",
            "Batch 190/1583 processed, running loss: 83.632377, correct predictions: 2598, total: 3056\n",
            "Batch 200/1583 processed, running loss: 88.230504, correct predictions: 2727, total: 3216\n",
            "Batch 210/1583 processed, running loss: 92.501563, correct predictions: 2860, total: 3376\n",
            "Batch 220/1583 processed, running loss: 96.991522, correct predictions: 3003, total: 3536\n",
            "Batch 230/1583 processed, running loss: 101.507048, correct predictions: 3138, total: 3696\n",
            "Batch 240/1583 processed, running loss: 106.074529, correct predictions: 3269, total: 3856\n",
            "Batch 250/1583 processed, running loss: 109.805125, correct predictions: 3410, total: 4016\n",
            "Batch 260/1583 processed, running loss: 113.230545, correct predictions: 3549, total: 4176\n",
            "Batch 270/1583 processed, running loss: 118.189608, correct predictions: 3679, total: 4336\n",
            "Batch 280/1583 processed, running loss: 123.077869, correct predictions: 3809, total: 4496\n",
            "Batch 290/1583 processed, running loss: 127.686361, correct predictions: 3949, total: 4656\n",
            "Batch 300/1583 processed, running loss: 132.350820, correct predictions: 4080, total: 4816\n",
            "Batch 310/1583 processed, running loss: 137.009679, correct predictions: 4218, total: 4976\n",
            "Batch 320/1583 processed, running loss: 140.747862, correct predictions: 4356, total: 5136\n",
            "Batch 330/1583 processed, running loss: 144.674122, correct predictions: 4497, total: 5296\n",
            "Batch 340/1583 processed, running loss: 149.109491, correct predictions: 4637, total: 5456\n",
            "Batch 350/1583 processed, running loss: 153.357673, correct predictions: 4771, total: 5616\n",
            "Batch 360/1583 processed, running loss: 157.834612, correct predictions: 4910, total: 5776\n",
            "Batch 370/1583 processed, running loss: 163.365045, correct predictions: 5038, total: 5936\n",
            "Batch 380/1583 processed, running loss: 167.022214, correct predictions: 5172, total: 6096\n",
            "Batch 390/1583 processed, running loss: 170.310204, correct predictions: 5307, total: 6256\n",
            "Batch 400/1583 processed, running loss: 173.813880, correct predictions: 5444, total: 6416\n",
            "Batch 410/1583 processed, running loss: 177.328283, correct predictions: 5585, total: 6576\n",
            "Batch 420/1583 processed, running loss: 181.361992, correct predictions: 5716, total: 6736\n",
            "Batch 430/1583 processed, running loss: 186.448312, correct predictions: 5841, total: 6896\n",
            "Batch 440/1583 processed, running loss: 191.751169, correct predictions: 5983, total: 7056\n",
            "Batch 450/1583 processed, running loss: 195.200842, correct predictions: 6121, total: 7216\n",
            "Batch 460/1583 processed, running loss: 200.621757, correct predictions: 6257, total: 7376\n",
            "Batch 470/1583 processed, running loss: 203.801649, correct predictions: 6397, total: 7536\n",
            "Batch 480/1583 processed, running loss: 206.522694, correct predictions: 6529, total: 7696\n",
            "Batch 490/1583 processed, running loss: 209.956973, correct predictions: 6671, total: 7856\n",
            "Batch 500/1583 processed, running loss: 213.899569, correct predictions: 6800, total: 8016\n",
            "Batch 510/1583 processed, running loss: 218.339344, correct predictions: 6924, total: 8176\n",
            "Batch 520/1583 processed, running loss: 222.678625, correct predictions: 7055, total: 8336\n",
            "Batch 530/1583 processed, running loss: 228.306437, correct predictions: 7175, total: 8496\n",
            "Batch 540/1583 processed, running loss: 231.652473, correct predictions: 7302, total: 8656\n",
            "Batch 550/1583 processed, running loss: 235.484403, correct predictions: 7428, total: 8816\n",
            "Batch 560/1583 processed, running loss: 240.087848, correct predictions: 7557, total: 8976\n",
            "Batch 570/1583 processed, running loss: 245.010557, correct predictions: 7685, total: 9136\n",
            "Batch 580/1583 processed, running loss: 249.014726, correct predictions: 7820, total: 9296\n",
            "Batch 590/1583 processed, running loss: 252.764691, correct predictions: 7957, total: 9456\n",
            "Batch 600/1583 processed, running loss: 257.775889, correct predictions: 8092, total: 9616\n",
            "Batch 610/1583 processed, running loss: 261.247784, correct predictions: 8235, total: 9776\n",
            "Batch 620/1583 processed, running loss: 265.660136, correct predictions: 8373, total: 9936\n",
            "Batch 630/1583 processed, running loss: 269.293820, correct predictions: 8508, total: 10096\n",
            "Batch 640/1583 processed, running loss: 274.456710, correct predictions: 8640, total: 10256\n",
            "Batch 650/1583 processed, running loss: 277.857215, correct predictions: 8781, total: 10416\n",
            "Batch 660/1583 processed, running loss: 280.625607, correct predictions: 8925, total: 10576\n",
            "Batch 670/1583 processed, running loss: 284.249867, correct predictions: 9060, total: 10736\n",
            "Batch 680/1583 processed, running loss: 287.815875, correct predictions: 9208, total: 10896\n",
            "Batch 690/1583 processed, running loss: 291.815514, correct predictions: 9348, total: 11056\n",
            "Batch 700/1583 processed, running loss: 295.803772, correct predictions: 9487, total: 11216\n",
            "Batch 710/1583 processed, running loss: 300.624949, correct predictions: 9624, total: 11376\n",
            "Batch 720/1583 processed, running loss: 303.819757, correct predictions: 9770, total: 11536\n",
            "Batch 730/1583 processed, running loss: 307.177699, correct predictions: 9910, total: 11696\n",
            "Batch 740/1583 processed, running loss: 310.110418, correct predictions: 10058, total: 11856\n",
            "Batch 750/1583 processed, running loss: 313.271283, correct predictions: 10207, total: 12016\n",
            "Batch 760/1583 processed, running loss: 317.607786, correct predictions: 10350, total: 12176\n",
            "Batch 770/1583 processed, running loss: 323.055589, correct predictions: 10473, total: 12336\n",
            "Batch 780/1583 processed, running loss: 326.741087, correct predictions: 10615, total: 12496\n",
            "Batch 790/1583 processed, running loss: 330.380186, correct predictions: 10756, total: 12656\n",
            "Batch 800/1583 processed, running loss: 335.436629, correct predictions: 10893, total: 12816\n",
            "Batch 810/1583 processed, running loss: 339.701871, correct predictions: 11025, total: 12976\n",
            "Batch 820/1583 processed, running loss: 342.395733, correct predictions: 11168, total: 13136\n",
            "Batch 830/1583 processed, running loss: 347.343018, correct predictions: 11307, total: 13296\n",
            "Batch 840/1583 processed, running loss: 351.361616, correct predictions: 11448, total: 13456\n",
            "Batch 850/1583 processed, running loss: 354.315840, correct predictions: 11591, total: 13616\n",
            "Batch 860/1583 processed, running loss: 357.946383, correct predictions: 11727, total: 13776\n",
            "Batch 870/1583 processed, running loss: 362.531545, correct predictions: 11861, total: 13936\n",
            "Batch 880/1583 processed, running loss: 367.355708, correct predictions: 11994, total: 14096\n",
            "Batch 890/1583 processed, running loss: 371.428929, correct predictions: 12124, total: 14256\n",
            "Batch 900/1583 processed, running loss: 375.953796, correct predictions: 12254, total: 14416\n",
            "Batch 910/1583 processed, running loss: 379.350022, correct predictions: 12396, total: 14576\n",
            "Batch 920/1583 processed, running loss: 383.676188, correct predictions: 12532, total: 14736\n",
            "Batch 930/1583 processed, running loss: 387.731536, correct predictions: 12673, total: 14896\n",
            "Batch 940/1583 processed, running loss: 391.825365, correct predictions: 12812, total: 15056\n",
            "Batch 950/1583 processed, running loss: 395.542785, correct predictions: 12947, total: 15216\n",
            "Batch 960/1583 processed, running loss: 399.227772, correct predictions: 13088, total: 15376\n",
            "Batch 970/1583 processed, running loss: 403.566325, correct predictions: 13230, total: 15536\n",
            "Batch 980/1583 processed, running loss: 408.339557, correct predictions: 13364, total: 15696\n",
            "Batch 990/1583 processed, running loss: 413.353052, correct predictions: 13497, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 417.945924, correct predictions: 13627, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 421.642514, correct predictions: 13759, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 425.666723, correct predictions: 13905, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 429.370918, correct predictions: 14046, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 433.726833, correct predictions: 14185, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 438.235777, correct predictions: 14326, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 443.043639, correct predictions: 14463, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 447.873163, correct predictions: 14597, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 450.851388, correct predictions: 14738, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 455.167453, correct predictions: 14881, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 461.120532, correct predictions: 15009, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 464.763373, correct predictions: 15148, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 468.647761, correct predictions: 15287, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 471.940918, correct predictions: 15429, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 475.725579, correct predictions: 15564, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 480.302578, correct predictions: 15701, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 484.185744, correct predictions: 15840, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 488.036939, correct predictions: 15980, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 492.286560, correct predictions: 16119, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 497.518476, correct predictions: 16252, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 500.840460, correct predictions: 16390, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 505.262988, correct predictions: 16523, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 509.391682, correct predictions: 16652, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 514.750771, correct predictions: 16781, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 518.029949, correct predictions: 16918, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 522.781944, correct predictions: 17057, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 527.001181, correct predictions: 17189, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 531.930002, correct predictions: 17321, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 537.392243, correct predictions: 17450, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 541.568197, correct predictions: 17587, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 545.923487, correct predictions: 17727, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 549.891697, correct predictions: 17866, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 553.983420, correct predictions: 18007, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 558.453100, correct predictions: 18146, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 563.289184, correct predictions: 18275, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 567.705615, correct predictions: 18413, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 571.392366, correct predictions: 18553, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 573.930684, correct predictions: 18692, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 577.182121, correct predictions: 18833, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 581.462551, correct predictions: 18968, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 584.166494, correct predictions: 19106, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 587.732018, correct predictions: 19245, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 591.223209, correct predictions: 19381, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 594.602302, correct predictions: 19518, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 599.675097, correct predictions: 19651, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 603.025476, correct predictions: 19796, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 606.581975, correct predictions: 19931, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 612.112137, correct predictions: 20066, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 616.539838, correct predictions: 20204, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 621.700003, correct predictions: 20344, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 626.046382, correct predictions: 20481, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 629.656904, correct predictions: 20616, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 633.722463, correct predictions: 20750, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 637.375355, correct predictions: 20894, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 640.792168, correct predictions: 21036, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 644.453144, correct predictions: 21172, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 648.983947, correct predictions: 21311, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 651.633581, correct predictions: 21453, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 655.918743, correct predictions: 21591, total: 25296\n",
            "\n",
            "Training Loss per batch = 0.415547\tAccuracy on Training set = 85.343499% [21603/25313]\n",
            "\n",
            "Validation Loss per batch = 1.225474\tAccuracy on Validation set = 77.497334% [2180/2813]\n",
            "Train Loss: 0.4155, Train Accuracy: 85.3435\n",
            "Valid Loss: 1.2255, Valid Accuracy: 77.4973\n",
            "\n",
            "Epoch 10/30\n",
            "-------------------------------\n",
            "Epoch: 9, Learning Rate: 0.001250 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0/1583 processed, running loss: 0.331204, correct predictions: 14, total: 16\n",
            "Batch 10/1583 processed, running loss: 3.515613, correct predictions: 155, total: 176\n",
            "Batch 20/1583 processed, running loss: 6.990306, correct predictions: 289, total: 336\n",
            "Batch 30/1583 processed, running loss: 10.393277, correct predictions: 429, total: 496\n",
            "Batch 40/1583 processed, running loss: 13.067840, correct predictions: 569, total: 656\n",
            "Batch 50/1583 processed, running loss: 16.641242, correct predictions: 708, total: 816\n",
            "Batch 60/1583 processed, running loss: 19.557368, correct predictions: 844, total: 976\n",
            "Batch 70/1583 processed, running loss: 22.349178, correct predictions: 981, total: 1136\n",
            "Batch 80/1583 processed, running loss: 25.747526, correct predictions: 1123, total: 1296\n",
            "Batch 90/1583 processed, running loss: 29.244640, correct predictions: 1262, total: 1456\n",
            "Batch 100/1583 processed, running loss: 32.805642, correct predictions: 1407, total: 1616\n",
            "Batch 110/1583 processed, running loss: 36.273907, correct predictions: 1555, total: 1776\n",
            "Batch 120/1583 processed, running loss: 39.724512, correct predictions: 1695, total: 1936\n",
            "Batch 130/1583 processed, running loss: 42.758723, correct predictions: 1842, total: 2096\n",
            "Batch 140/1583 processed, running loss: 45.224383, correct predictions: 1993, total: 2256\n",
            "Batch 150/1583 processed, running loss: 47.659704, correct predictions: 2140, total: 2416\n",
            "Batch 160/1583 processed, running loss: 51.424182, correct predictions: 2282, total: 2576\n",
            "Batch 170/1583 processed, running loss: 55.606610, correct predictions: 2423, total: 2736\n",
            "Batch 180/1583 processed, running loss: 58.770107, correct predictions: 2566, total: 2896\n",
            "Batch 190/1583 processed, running loss: 62.536277, correct predictions: 2702, total: 3056\n",
            "Batch 200/1583 processed, running loss: 66.655783, correct predictions: 2838, total: 3216\n",
            "Batch 210/1583 processed, running loss: 70.354505, correct predictions: 2977, total: 3376\n",
            "Batch 220/1583 processed, running loss: 73.593460, correct predictions: 3120, total: 3536\n",
            "Batch 230/1583 processed, running loss: 77.710562, correct predictions: 3264, total: 3696\n",
            "Batch 240/1583 processed, running loss: 81.277947, correct predictions: 3410, total: 3856\n",
            "Batch 250/1583 processed, running loss: 84.187741, correct predictions: 3552, total: 4016\n",
            "Batch 260/1583 processed, running loss: 87.040391, correct predictions: 3687, total: 4176\n",
            "Batch 270/1583 processed, running loss: 90.304996, correct predictions: 3836, total: 4336\n",
            "Batch 280/1583 processed, running loss: 93.750875, correct predictions: 3978, total: 4496\n",
            "Batch 290/1583 processed, running loss: 95.927208, correct predictions: 4125, total: 4656\n",
            "Batch 300/1583 processed, running loss: 99.154480, correct predictions: 4268, total: 4816\n",
            "Batch 310/1583 processed, running loss: 101.790541, correct predictions: 4408, total: 4976\n",
            "Batch 320/1583 processed, running loss: 104.371264, correct predictions: 4553, total: 5136\n",
            "Batch 330/1583 processed, running loss: 107.802884, correct predictions: 4692, total: 5296\n",
            "Batch 340/1583 processed, running loss: 111.365872, correct predictions: 4826, total: 5456\n",
            "Batch 350/1583 processed, running loss: 115.638747, correct predictions: 4968, total: 5616\n",
            "Batch 360/1583 processed, running loss: 118.366612, correct predictions: 5107, total: 5776\n",
            "Batch 370/1583 processed, running loss: 121.466913, correct predictions: 5253, total: 5936\n",
            "Batch 380/1583 processed, running loss: 125.117250, correct predictions: 5399, total: 6096\n",
            "Batch 390/1583 processed, running loss: 128.371691, correct predictions: 5541, total: 6256\n",
            "Batch 400/1583 processed, running loss: 131.666123, correct predictions: 5682, total: 6416\n",
            "Batch 410/1583 processed, running loss: 135.286037, correct predictions: 5822, total: 6576\n",
            "Batch 420/1583 processed, running loss: 139.831938, correct predictions: 5959, total: 6736\n",
            "Batch 430/1583 processed, running loss: 143.564332, correct predictions: 6099, total: 6896\n",
            "Batch 440/1583 processed, running loss: 146.677375, correct predictions: 6226, total: 7056\n",
            "Batch 450/1583 processed, running loss: 149.820717, correct predictions: 6364, total: 7216\n",
            "Batch 460/1583 processed, running loss: 152.816540, correct predictions: 6502, total: 7376\n",
            "Batch 470/1583 processed, running loss: 155.876584, correct predictions: 6638, total: 7536\n",
            "Batch 480/1583 processed, running loss: 158.869176, correct predictions: 6780, total: 7696\n",
            "Batch 490/1583 processed, running loss: 162.358112, correct predictions: 6919, total: 7856\n",
            "Batch 500/1583 processed, running loss: 166.435582, correct predictions: 7052, total: 8016\n",
            "Batch 510/1583 processed, running loss: 169.223672, correct predictions: 7189, total: 8176\n",
            "Batch 520/1583 processed, running loss: 172.139531, correct predictions: 7333, total: 8336\n",
            "Batch 530/1583 processed, running loss: 175.764707, correct predictions: 7461, total: 8496\n",
            "Batch 540/1583 processed, running loss: 179.690424, correct predictions: 7597, total: 8656\n",
            "Batch 550/1583 processed, running loss: 183.390328, correct predictions: 7736, total: 8816\n",
            "Batch 560/1583 processed, running loss: 187.224686, correct predictions: 7876, total: 8976\n",
            "Batch 570/1583 processed, running loss: 189.993856, correct predictions: 8024, total: 9136\n",
            "Batch 580/1583 processed, running loss: 193.567587, correct predictions: 8158, total: 9296\n",
            "Batch 590/1583 processed, running loss: 196.495801, correct predictions: 8298, total: 9456\n",
            "Batch 600/1583 processed, running loss: 199.465655, correct predictions: 8436, total: 9616\n",
            "Batch 610/1583 processed, running loss: 202.729566, correct predictions: 8572, total: 9776\n",
            "Batch 620/1583 processed, running loss: 205.896375, correct predictions: 8715, total: 9936\n",
            "Batch 630/1583 processed, running loss: 209.430651, correct predictions: 8857, total: 10096\n",
            "Batch 640/1583 processed, running loss: 212.662380, correct predictions: 8998, total: 10256\n",
            "Batch 650/1583 processed, running loss: 216.713316, correct predictions: 9132, total: 10416\n",
            "Batch 660/1583 processed, running loss: 220.249563, correct predictions: 9273, total: 10576\n",
            "Batch 670/1583 processed, running loss: 223.221632, correct predictions: 9419, total: 10736\n",
            "Batch 680/1583 processed, running loss: 226.792571, correct predictions: 9558, total: 10896\n",
            "Batch 690/1583 processed, running loss: 230.015515, correct predictions: 9701, total: 11056\n",
            "Batch 700/1583 processed, running loss: 234.051396, correct predictions: 9824, total: 11216\n",
            "Batch 710/1583 processed, running loss: 236.469261, correct predictions: 9968, total: 11376\n",
            "Batch 720/1583 processed, running loss: 239.861661, correct predictions: 10113, total: 11536\n",
            "Batch 730/1583 processed, running loss: 242.221283, correct predictions: 10260, total: 11696\n",
            "Batch 740/1583 processed, running loss: 245.180051, correct predictions: 10403, total: 11856\n",
            "Batch 750/1583 processed, running loss: 248.643163, correct predictions: 10549, total: 12016\n",
            "Batch 760/1583 processed, running loss: 252.189090, correct predictions: 10693, total: 12176\n",
            "Batch 770/1583 processed, running loss: 255.505128, correct predictions: 10832, total: 12336\n",
            "Batch 780/1583 processed, running loss: 261.037934, correct predictions: 10969, total: 12496\n",
            "Batch 790/1583 processed, running loss: 265.432701, correct predictions: 11106, total: 12656\n",
            "Batch 800/1583 processed, running loss: 269.049943, correct predictions: 11246, total: 12816\n",
            "Batch 810/1583 processed, running loss: 272.378966, correct predictions: 11382, total: 12976\n",
            "Batch 820/1583 processed, running loss: 275.854707, correct predictions: 11528, total: 13136\n",
            "Batch 830/1583 processed, running loss: 279.623289, correct predictions: 11664, total: 13296\n",
            "Batch 840/1583 processed, running loss: 283.219457, correct predictions: 11801, total: 13456\n",
            "Batch 850/1583 processed, running loss: 286.146391, correct predictions: 11940, total: 13616\n",
            "Batch 860/1583 processed, running loss: 288.946063, correct predictions: 12081, total: 13776\n",
            "Batch 870/1583 processed, running loss: 291.165484, correct predictions: 12230, total: 13936\n",
            "Batch 880/1583 processed, running loss: 294.725509, correct predictions: 12374, total: 14096\n",
            "Batch 890/1583 processed, running loss: 298.524163, correct predictions: 12513, total: 14256\n",
            "Batch 900/1583 processed, running loss: 301.127235, correct predictions: 12662, total: 14416\n",
            "Batch 910/1583 processed, running loss: 304.523308, correct predictions: 12799, total: 14576\n",
            "Batch 920/1583 processed, running loss: 307.650633, correct predictions: 12941, total: 14736\n",
            "Batch 930/1583 processed, running loss: 312.114944, correct predictions: 13076, total: 14896\n",
            "Batch 940/1583 processed, running loss: 316.366993, correct predictions: 13209, total: 15056\n",
            "Batch 950/1583 processed, running loss: 320.571193, correct predictions: 13337, total: 15216\n",
            "Batch 960/1583 processed, running loss: 323.680240, correct predictions: 13478, total: 15376\n",
            "Batch 970/1583 processed, running loss: 329.025956, correct predictions: 13616, total: 15536\n",
            "Batch 980/1583 processed, running loss: 333.348945, correct predictions: 13751, total: 15696\n",
            "Batch 990/1583 processed, running loss: 336.885927, correct predictions: 13886, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 340.961235, correct predictions: 14029, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 343.997997, correct predictions: 14170, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 346.995159, correct predictions: 14313, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 350.762859, correct predictions: 14453, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 353.933751, correct predictions: 14586, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 358.505702, correct predictions: 14719, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 362.061574, correct predictions: 14850, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 365.051184, correct predictions: 14997, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 368.238276, correct predictions: 15136, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 371.037531, correct predictions: 15279, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 374.837957, correct predictions: 15417, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 379.095635, correct predictions: 15549, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 383.899733, correct predictions: 15675, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 386.537994, correct predictions: 15814, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 389.798391, correct predictions: 15956, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 392.600770, correct predictions: 16095, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 396.346827, correct predictions: 16237, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 399.794741, correct predictions: 16379, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 403.754156, correct predictions: 16518, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 406.536933, correct predictions: 16658, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 410.582409, correct predictions: 16796, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 414.477556, correct predictions: 16935, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 418.076495, correct predictions: 17076, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 421.527652, correct predictions: 17215, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 423.943160, correct predictions: 17358, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 427.089449, correct predictions: 17497, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 429.961370, correct predictions: 17642, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 433.403739, correct predictions: 17787, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 436.383431, correct predictions: 17929, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 440.425305, correct predictions: 18070, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 443.236800, correct predictions: 18208, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 446.742672, correct predictions: 18349, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 449.651302, correct predictions: 18496, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 452.683901, correct predictions: 18639, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 456.043087, correct predictions: 18786, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 459.490980, correct predictions: 18925, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 463.334456, correct predictions: 19065, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 467.306142, correct predictions: 19210, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 470.237759, correct predictions: 19351, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 473.682159, correct predictions: 19493, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 477.147504, correct predictions: 19635, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 480.777167, correct predictions: 19769, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 484.639899, correct predictions: 19905, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 488.701939, correct predictions: 20044, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 492.581382, correct predictions: 20179, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 497.308246, correct predictions: 20313, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 501.495763, correct predictions: 20449, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 504.800472, correct predictions: 20594, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 506.912511, correct predictions: 20739, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 510.999740, correct predictions: 20871, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 515.248395, correct predictions: 21012, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 518.465782, correct predictions: 21156, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 521.476393, correct predictions: 21303, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 525.622953, correct predictions: 21438, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 529.354254, correct predictions: 21574, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 531.937065, correct predictions: 21707, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 535.772086, correct predictions: 21844, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 539.591428, correct predictions: 21980, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 542.437437, correct predictions: 22122, total: 25296\n",
            "\n",
            "Training Loss per batch = 0.343631\tAccuracy on Training set = 87.449137% [22136/25313]\n",
            "\n",
            "Validation Loss per batch = 1.299542\tAccuracy on Validation set = 77.568432% [2182/2813]\n",
            "Train Loss: 0.3436, Train Accuracy: 87.4491\n",
            "Valid Loss: 1.2995, Valid Accuracy: 77.5684\n",
            "\n",
            "Epoch 11/30\n",
            "-------------------------------\n",
            "Epoch: 10, Learning Rate: 0.001250 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-473e11fd7032>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0/1583 processed, running loss: 0.196713, correct predictions: 15, total: 16\n",
            "Batch 10/1583 processed, running loss: 2.761672, correct predictions: 156, total: 176\n",
            "Batch 20/1583 processed, running loss: 5.715711, correct predictions: 294, total: 336\n",
            "Batch 30/1583 processed, running loss: 9.020679, correct predictions: 436, total: 496\n",
            "Batch 40/1583 processed, running loss: 11.998389, correct predictions: 579, total: 656\n",
            "Batch 50/1583 processed, running loss: 15.768444, correct predictions: 722, total: 816\n",
            "Batch 60/1583 processed, running loss: 18.674525, correct predictions: 863, total: 976\n",
            "Batch 70/1583 processed, running loss: 20.435012, correct predictions: 1012, total: 1136\n",
            "Batch 80/1583 processed, running loss: 22.476642, correct predictions: 1161, total: 1296\n",
            "Batch 90/1583 processed, running loss: 24.787988, correct predictions: 1306, total: 1456\n",
            "Batch 100/1583 processed, running loss: 28.809603, correct predictions: 1448, total: 1616\n",
            "Batch 110/1583 processed, running loss: 32.414257, correct predictions: 1591, total: 1776\n",
            "Batch 120/1583 processed, running loss: 35.254327, correct predictions: 1732, total: 1936\n",
            "Batch 130/1583 processed, running loss: 38.448120, correct predictions: 1867, total: 2096\n",
            "Batch 140/1583 processed, running loss: 42.157229, correct predictions: 2005, total: 2256\n",
            "Batch 150/1583 processed, running loss: 44.244780, correct predictions: 2155, total: 2416\n",
            "Batch 160/1583 processed, running loss: 46.604092, correct predictions: 2294, total: 2576\n",
            "Batch 170/1583 processed, running loss: 49.465094, correct predictions: 2437, total: 2736\n",
            "Batch 180/1583 processed, running loss: 51.590504, correct predictions: 2577, total: 2896\n",
            "Batch 190/1583 processed, running loss: 54.204986, correct predictions: 2720, total: 3056\n",
            "Batch 200/1583 processed, running loss: 57.206815, correct predictions: 2868, total: 3216\n",
            "Batch 210/1583 processed, running loss: 60.790062, correct predictions: 3005, total: 3376\n",
            "Batch 220/1583 processed, running loss: 63.074329, correct predictions: 3153, total: 3536\n",
            "Batch 230/1583 processed, running loss: 65.405092, correct predictions: 3297, total: 3696\n",
            "Batch 240/1583 processed, running loss: 68.655776, correct predictions: 3438, total: 3856\n",
            "Batch 250/1583 processed, running loss: 71.439298, correct predictions: 3578, total: 4016\n",
            "Batch 260/1583 processed, running loss: 73.578319, correct predictions: 3727, total: 4176\n",
            "Batch 270/1583 processed, running loss: 75.923913, correct predictions: 3872, total: 4336\n",
            "Batch 280/1583 processed, running loss: 79.119149, correct predictions: 4013, total: 4496\n",
            "Batch 290/1583 processed, running loss: 82.203004, correct predictions: 4151, total: 4656\n",
            "Batch 300/1583 processed, running loss: 84.550565, correct predictions: 4300, total: 4816\n",
            "Batch 310/1583 processed, running loss: 86.859146, correct predictions: 4437, total: 4976\n",
            "Batch 320/1583 processed, running loss: 89.116945, correct predictions: 4585, total: 5136\n",
            "Batch 330/1583 processed, running loss: 91.992757, correct predictions: 4730, total: 5296\n",
            "Batch 340/1583 processed, running loss: 94.639785, correct predictions: 4873, total: 5456\n",
            "Batch 350/1583 processed, running loss: 98.677800, correct predictions: 5011, total: 5616\n",
            "Batch 360/1583 processed, running loss: 102.322548, correct predictions: 5150, total: 5776\n",
            "Batch 370/1583 processed, running loss: 105.430586, correct predictions: 5288, total: 5936\n",
            "Batch 380/1583 processed, running loss: 108.963543, correct predictions: 5427, total: 6096\n",
            "Batch 390/1583 processed, running loss: 111.710327, correct predictions: 5563, total: 6256\n",
            "Batch 400/1583 processed, running loss: 115.151654, correct predictions: 5707, total: 6416\n",
            "Batch 410/1583 processed, running loss: 117.841387, correct predictions: 5859, total: 6576\n",
            "Batch 420/1583 processed, running loss: 120.842990, correct predictions: 6004, total: 6736\n",
            "Batch 430/1583 processed, running loss: 124.629227, correct predictions: 6135, total: 6896\n",
            "Batch 440/1583 processed, running loss: 127.840233, correct predictions: 6274, total: 7056\n",
            "Batch 450/1583 processed, running loss: 130.430712, correct predictions: 6419, total: 7216\n",
            "Batch 460/1583 processed, running loss: 133.383245, correct predictions: 6569, total: 7376\n",
            "Batch 470/1583 processed, running loss: 135.976905, correct predictions: 6711, total: 7536\n",
            "Batch 480/1583 processed, running loss: 138.382639, correct predictions: 6858, total: 7696\n",
            "Batch 490/1583 processed, running loss: 141.448100, correct predictions: 6999, total: 7856\n",
            "Batch 500/1583 processed, running loss: 144.960309, correct predictions: 7141, total: 8016\n",
            "Batch 510/1583 processed, running loss: 146.431172, correct predictions: 7292, total: 8176\n",
            "Batch 520/1583 processed, running loss: 148.990129, correct predictions: 7433, total: 8336\n",
            "Batch 530/1583 processed, running loss: 151.622325, correct predictions: 7577, total: 8496\n",
            "Batch 540/1583 processed, running loss: 154.603571, correct predictions: 7720, total: 8656\n",
            "Batch 550/1583 processed, running loss: 156.655167, correct predictions: 7865, total: 8816\n",
            "Batch 560/1583 processed, running loss: 159.240197, correct predictions: 8006, total: 8976\n",
            "Batch 570/1583 processed, running loss: 162.374282, correct predictions: 8152, total: 9136\n",
            "Batch 580/1583 processed, running loss: 166.130758, correct predictions: 8297, total: 9296\n",
            "Batch 590/1583 processed, running loss: 169.124228, correct predictions: 8442, total: 9456\n",
            "Batch 600/1583 processed, running loss: 171.662240, correct predictions: 8588, total: 9616\n",
            "Batch 610/1583 processed, running loss: 176.205088, correct predictions: 8723, total: 9776\n",
            "Batch 620/1583 processed, running loss: 178.757666, correct predictions: 8869, total: 9936\n",
            "Batch 630/1583 processed, running loss: 181.205749, correct predictions: 9015, total: 10096\n",
            "Batch 640/1583 processed, running loss: 184.263894, correct predictions: 9162, total: 10256\n",
            "Batch 650/1583 processed, running loss: 186.076031, correct predictions: 9303, total: 10416\n",
            "Batch 660/1583 processed, running loss: 189.431898, correct predictions: 9446, total: 10576\n",
            "Batch 670/1583 processed, running loss: 191.864210, correct predictions: 9590, total: 10736\n",
            "Batch 680/1583 processed, running loss: 194.105415, correct predictions: 9736, total: 10896\n",
            "Batch 690/1583 processed, running loss: 197.678826, correct predictions: 9881, total: 11056\n",
            "Batch 700/1583 processed, running loss: 200.372202, correct predictions: 10024, total: 11216\n",
            "Batch 710/1583 processed, running loss: 202.811513, correct predictions: 10172, total: 11376\n",
            "Batch 720/1583 processed, running loss: 205.600954, correct predictions: 10313, total: 11536\n",
            "Batch 730/1583 processed, running loss: 209.162846, correct predictions: 10459, total: 11696\n",
            "Batch 740/1583 processed, running loss: 211.977394, correct predictions: 10597, total: 11856\n",
            "Batch 750/1583 processed, running loss: 215.699293, correct predictions: 10733, total: 12016\n",
            "Batch 760/1583 processed, running loss: 218.212020, correct predictions: 10872, total: 12176\n",
            "Batch 770/1583 processed, running loss: 221.103864, correct predictions: 11011, total: 12336\n",
            "Batch 780/1583 processed, running loss: 223.533408, correct predictions: 11158, total: 12496\n",
            "Batch 790/1583 processed, running loss: 226.903901, correct predictions: 11301, total: 12656\n",
            "Batch 800/1583 processed, running loss: 230.497675, correct predictions: 11438, total: 12816\n",
            "Batch 810/1583 processed, running loss: 234.693006, correct predictions: 11573, total: 12976\n",
            "Batch 820/1583 processed, running loss: 237.272306, correct predictions: 11717, total: 13136\n",
            "Batch 830/1583 processed, running loss: 240.360949, correct predictions: 11856, total: 13296\n",
            "Batch 840/1583 processed, running loss: 243.096090, correct predictions: 11991, total: 13456\n",
            "Batch 850/1583 processed, running loss: 244.916048, correct predictions: 12142, total: 13616\n",
            "Batch 860/1583 processed, running loss: 248.187328, correct predictions: 12285, total: 13776\n",
            "Batch 870/1583 processed, running loss: 251.910083, correct predictions: 12431, total: 13936\n",
            "Batch 880/1583 processed, running loss: 254.440538, correct predictions: 12572, total: 14096\n",
            "Batch 890/1583 processed, running loss: 257.154590, correct predictions: 12713, total: 14256\n",
            "Batch 900/1583 processed, running loss: 259.759463, correct predictions: 12856, total: 14416\n",
            "Batch 910/1583 processed, running loss: 263.224320, correct predictions: 13000, total: 14576\n",
            "Batch 920/1583 processed, running loss: 266.081682, correct predictions: 13144, total: 14736\n",
            "Batch 930/1583 processed, running loss: 270.063877, correct predictions: 13285, total: 14896\n",
            "Batch 940/1583 processed, running loss: 272.892288, correct predictions: 13429, total: 15056\n",
            "Batch 950/1583 processed, running loss: 275.952531, correct predictions: 13577, total: 15216\n",
            "Batch 960/1583 processed, running loss: 278.558121, correct predictions: 13724, total: 15376\n",
            "Batch 970/1583 processed, running loss: 281.680640, correct predictions: 13865, total: 15536\n",
            "Batch 980/1583 processed, running loss: 284.374498, correct predictions: 14010, total: 15696\n",
            "Batch 990/1583 processed, running loss: 287.559140, correct predictions: 14162, total: 15856\n",
            "Batch 1000/1583 processed, running loss: 291.416012, correct predictions: 14302, total: 16016\n",
            "Batch 1010/1583 processed, running loss: 293.879696, correct predictions: 14446, total: 16176\n",
            "Batch 1020/1583 processed, running loss: 297.149716, correct predictions: 14586, total: 16336\n",
            "Batch 1030/1583 processed, running loss: 299.939702, correct predictions: 14726, total: 16496\n",
            "Batch 1040/1583 processed, running loss: 302.549883, correct predictions: 14871, total: 16656\n",
            "Batch 1050/1583 processed, running loss: 306.633620, correct predictions: 15014, total: 16816\n",
            "Batch 1060/1583 processed, running loss: 309.315672, correct predictions: 15159, total: 16976\n",
            "Batch 1070/1583 processed, running loss: 312.269252, correct predictions: 15303, total: 17136\n",
            "Batch 1080/1583 processed, running loss: 315.246734, correct predictions: 15443, total: 17296\n",
            "Batch 1090/1583 processed, running loss: 319.188103, correct predictions: 15580, total: 17456\n",
            "Batch 1100/1583 processed, running loss: 321.844286, correct predictions: 15723, total: 17616\n",
            "Batch 1110/1583 processed, running loss: 324.599245, correct predictions: 15865, total: 17776\n",
            "Batch 1120/1583 processed, running loss: 327.328287, correct predictions: 16011, total: 17936\n",
            "Batch 1130/1583 processed, running loss: 330.187557, correct predictions: 16153, total: 18096\n",
            "Batch 1140/1583 processed, running loss: 332.983916, correct predictions: 16299, total: 18256\n",
            "Batch 1150/1583 processed, running loss: 335.731319, correct predictions: 16440, total: 18416\n",
            "Batch 1160/1583 processed, running loss: 338.201794, correct predictions: 16586, total: 18576\n",
            "Batch 1170/1583 processed, running loss: 341.947686, correct predictions: 16726, total: 18736\n",
            "Batch 1180/1583 processed, running loss: 344.508195, correct predictions: 16868, total: 18896\n",
            "Batch 1190/1583 processed, running loss: 347.914499, correct predictions: 17008, total: 19056\n",
            "Batch 1200/1583 processed, running loss: 349.879467, correct predictions: 17154, total: 19216\n",
            "Batch 1210/1583 processed, running loss: 352.411055, correct predictions: 17303, total: 19376\n",
            "Batch 1220/1583 processed, running loss: 354.735567, correct predictions: 17450, total: 19536\n",
            "Batch 1230/1583 processed, running loss: 357.160345, correct predictions: 17594, total: 19696\n",
            "Batch 1240/1583 processed, running loss: 359.188926, correct predictions: 17732, total: 19856\n",
            "Batch 1250/1583 processed, running loss: 362.210541, correct predictions: 17882, total: 20016\n",
            "Batch 1260/1583 processed, running loss: 365.945582, correct predictions: 18013, total: 20176\n",
            "Batch 1270/1583 processed, running loss: 369.064371, correct predictions: 18149, total: 20336\n",
            "Batch 1280/1583 processed, running loss: 371.938041, correct predictions: 18290, total: 20496\n",
            "Batch 1290/1583 processed, running loss: 375.963278, correct predictions: 18431, total: 20656\n",
            "Batch 1300/1583 processed, running loss: 379.441879, correct predictions: 18566, total: 20816\n",
            "Batch 1310/1583 processed, running loss: 381.920403, correct predictions: 18716, total: 20976\n",
            "Batch 1320/1583 processed, running loss: 385.853588, correct predictions: 18854, total: 21136\n",
            "Batch 1330/1583 processed, running loss: 389.413107, correct predictions: 18996, total: 21296\n",
            "Batch 1340/1583 processed, running loss: 391.847396, correct predictions: 19135, total: 21456\n",
            "Batch 1350/1583 processed, running loss: 395.285004, correct predictions: 19273, total: 21616\n",
            "Batch 1360/1583 processed, running loss: 397.352936, correct predictions: 19415, total: 21776\n",
            "Batch 1370/1583 processed, running loss: 400.170518, correct predictions: 19559, total: 21936\n",
            "Batch 1380/1583 processed, running loss: 403.127335, correct predictions: 19701, total: 22096\n",
            "Batch 1390/1583 processed, running loss: 404.815223, correct predictions: 19853, total: 22256\n",
            "Batch 1400/1583 processed, running loss: 407.919493, correct predictions: 19997, total: 22416\n",
            "Batch 1410/1583 processed, running loss: 411.519666, correct predictions: 20132, total: 22576\n",
            "Batch 1420/1583 processed, running loss: 414.376037, correct predictions: 20270, total: 22736\n",
            "Batch 1430/1583 processed, running loss: 416.993035, correct predictions: 20415, total: 22896\n",
            "Batch 1440/1583 processed, running loss: 420.306255, correct predictions: 20555, total: 23056\n",
            "Batch 1450/1583 processed, running loss: 422.801592, correct predictions: 20699, total: 23216\n",
            "Batch 1460/1583 processed, running loss: 426.268256, correct predictions: 20839, total: 23376\n",
            "Batch 1470/1583 processed, running loss: 429.160413, correct predictions: 20981, total: 23536\n",
            "Batch 1480/1583 processed, running loss: 431.645230, correct predictions: 21124, total: 23696\n",
            "Batch 1490/1583 processed, running loss: 433.575069, correct predictions: 21271, total: 23856\n",
            "Batch 1500/1583 processed, running loss: 436.108967, correct predictions: 21412, total: 24016\n",
            "Batch 1510/1583 processed, running loss: 439.488424, correct predictions: 21556, total: 24176\n",
            "Batch 1520/1583 processed, running loss: 442.448866, correct predictions: 21705, total: 24336\n",
            "Batch 1530/1583 processed, running loss: 445.816404, correct predictions: 21853, total: 24496\n",
            "Batch 1540/1583 processed, running loss: 448.408968, correct predictions: 21998, total: 24656\n",
            "Batch 1550/1583 processed, running loss: 451.402601, correct predictions: 22145, total: 24816\n",
            "Batch 1560/1583 processed, running loss: 454.682865, correct predictions: 22282, total: 24976\n",
            "Batch 1570/1583 processed, running loss: 457.497176, correct predictions: 22422, total: 25136\n",
            "Batch 1580/1583 processed, running loss: 460.377637, correct predictions: 22565, total: 25296\n",
            "\n",
            "Training Loss per batch = 0.291319\tAccuracy on Training set = 89.199226% [22579/25313]\n",
            "\n",
            "Validation Loss per batch = 1.252062\tAccuracy on Validation set = 75.684323% [2129/2813]\n",
            "Train Loss: 0.2913, Train Accuracy: 89.1992\n",
            "Valid Loss: 1.2521, Valid Accuracy: 75.6843\n",
            "Early stopping at epoch 11, the validation loss did not improve for the last 6 epochs\n",
            "\n",
            "Training has completed!\n"
          ]
        }
      ],
      "source": [
        "loss_fn   = nn.CrossEntropyLoss(weight=class_weights) #CrossEntropyLoss with class_weights.\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.005)\n",
        "nb_epochs = 30\n",
        "patience = 6\n",
        "#Call the optimize function.\n",
        "train_losses, valid_losses = optimize(train_dataloader,valid_dataloader,model,loss_fn,optimizer,nb_epochs, patience)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Kaggle/unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "culfm9CsH-w5",
        "outputId": "2fd712f3-48cd-4877-f8ed-b52ead9360f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Kaggle/unzip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "I1AcQn3ikQyD"
      },
      "outputs": [],
      "source": [
        "model = torch.load(\"DR_ResNet50.pt\")\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Store all the model predictions for the test set\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# No need to track gradients for evaluation, saves memory and computations\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "26QT6jxWj_07"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7I92W90hYTAe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "outputId": "2fc88963-c44f-46a8-9caf-df9075c1ec5f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89      5150\n",
            "           1       0.20      0.30      0.24       482\n",
            "           2       0.67      0.51      0.58      1060\n",
            "           3       0.38      0.45      0.42       165\n",
            "           4       0.59      0.62      0.60       143\n",
            "\n",
            "    accuracy                           0.77      7000\n",
            "   macro avg       0.55      0.55      0.55      7000\n",
            "weighted avg       0.79      0.77      0.78      7000\n",
            "\n",
            "For class 0, Sensitivity: 0.8866019417475728, Specificity: 0.7032432432432433\n",
            "For class 1, Sensitivity: 0.2987551867219917, Specificity: 0.90948143602332\n",
            "For class 2, Sensitivity: 0.5103773584905661, Specificity: 0.9552188552188552\n",
            "For class 3, Sensitivity: 0.45454545454545453, Specificity: 0.9822970007315289\n",
            "For class 4, Sensitivity: 0.6153846153846154, Specificity: 0.9912498177045355\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(classification_report(all_labels, all_preds))\n",
        "\n",
        "# For multiclass case:\n",
        "num_classes = cm.shape[0]  # assuming cm is a square matrix\n",
        "\n",
        "for i in range(num_classes):\n",
        "    tp = cm[i, i]\n",
        "    fn = cm[i, :].sum() - tp  # sum across the row, excluding the diagonal element\n",
        "    fp = cm[:, i].sum() - tp  # sum down the column, excluding the diagonal element\n",
        "    tn = cm.sum() - fn - fp - tp\n",
        "\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    print(f\"For class {i}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grmA2x5vW406"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0OulKlKU_m4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug7vI984UA0E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTotw6mzRe_e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEUo1d9LRah0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNm+jdM8FbsIfi6XZePNT9P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}