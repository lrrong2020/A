{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lrrong2020/A/blob/main/FYP_crash1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjeGEXN7MH4C"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwK1YvMFL9Xz",
        "outputId": "409bc570-f5ac-45e9-8d96-d98d31060bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/xdg-open: 882: www-browser: not found\n",
            "/usr/bin/xdg-open: 882: links2: not found\n",
            "/usr/bin/xdg-open: 882: elinks: not found\n",
            "/usr/bin/xdg-open: 882: links: not found\n",
            "/usr/bin/xdg-open: 882: lynx: not found\n",
            "/usr/bin/xdg-open: 882: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=wD2b%2FVTFXXXrSfIcs0kiiYi4mGGMUQ4uhznbFG%2FzHuY'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/usr/bin/open: 882: www-browser: not found\n",
            "/usr/bin/open: 882: links2: not found\n",
            "/usr/bin/open: 882: elinks: not found\n",
            "/usr/bin/open: 882: links: not found\n",
            "/usr/bin/open: 882: lynx: not found\n",
            "/usr/bin/open: 882: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=wD2b%2FVTFXXXrSfIcs0kiiYi4mGGMUQ4uhznbFG%2FzHuY'\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=wD2b%2FVTFXXXrSfIcs0kiiYi4mGGMUQ4uhznbFG%2FzHuY\")\n",
            "/content\n",
            "/content/gdrive\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "!sudo echo -ne '\\n' | sudo add-apt-repository ppa:alessandro-strada/ppa >/dev/null 2>&1 # note: >/dev/null 2>&1 is used to supress printing\n",
        "!sudo apt update >/dev/null 2>&1\n",
        "!sudo apt install google-drive-ocamlfuse >/dev/null 2>&1\n",
        "!google-drive-ocamlfuse\n",
        "!sudo apt-get install w3m >/dev/null 2>&1 # to act as web browser\n",
        "!xdg-settings set default-web-browser w3m.desktop >/dev/null 2>&1 # to set default browser\n",
        "%cd /content\n",
        "!mkdir gdrive\n",
        "%cd gdrive\n",
        "!mkdir \"MyDrive\"\n",
        "!google-drive-ocamlfuse \"/content/gdrive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT_n6JPqMeCj"
      },
      "source": [
        "Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kWJglFbYMmEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b51ee4c-5c72-473b-c40c-c6910bc1d655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/honme'\n",
            "/content/gdrive\n"
          ]
        }
      ],
      "source": [
        "!cp /content/gdrive/MyDrive/Kaggle/unzip/data.zip /home\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /home\n",
        "!unzip -nq /home/data.zip \"train/*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdZTKNzNJdzd",
        "outputId": "39f6147c-2a02-4fd4-b119-0b55cdec9941"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /home/data.zip"
      ],
      "metadata": {
        "id": "688Rixw8Lr1n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Y1lyGWiJAU"
      },
      "source": [
        "#GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqAFoYKfjQHr",
        "outputId": "7cff129b-9774-4a08-aa07-a9287765de4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7bcd3875d8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd #For reading csv files.\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt #For plotting.\n",
        "import PIL.Image as Image #For working with image files.\n",
        "\n",
        "#Importing torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,DataLoader #For working with data.\n",
        "from torchvision import models,transforms #For pretrained models,image transformations.\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "#manual seed for reproductivity and potential performance improvement\n",
        "torch.manual_seed(3407)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-dPSwwujHvj",
        "outputId": "d4a28b2c-cf78-4a6d-be34-2f1eb200916b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Use GPU if it's available or else use CPU.\n",
        "print(device) #Prints the device we're using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrT4r4xvM09a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/gdrive/MyDrive/Kaggle/unzip/allLabels.csv /home"
      ],
      "metadata": {
        "id": "Vgy874jFDdQk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjkojF_kawHd",
        "outputId": "4030c13a-7dcf-461f-df30-155bd892c226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.of.training_samples: 5062\n",
            "No.of.testing_samples: 1400\n",
            "No.of.val_samples: 563\n"
          ]
        }
      ],
      "source": [
        "\n",
        "path = \"/home/\"\n",
        "\n",
        "#label csv\n",
        "all_df = pd.read_csv(f\"{path}allLabels.csv\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# subset for hyperparameters tuning\n",
        "\n",
        "part = 0.80\n",
        "train_df, drop_df = train_test_split(all_df, test_size=part, random_state=42)\n",
        "test_sample_size = round(7000 * (1 - part) )  #roughtly 1/3\n",
        "train_df, test_df = train_test_split(train_df, test_size=test_sample_size, random_state=42)\n",
        "\n",
        "# Assuming train_df is your original training DataFrame\n",
        "# test_sample_size = 7000 # roughtly 1/3\n",
        "# train_df, test_df = train_test_split(all_df, test_size=test_sample_size, random_state=42)\n",
        "\n",
        "# Now split the remaining training data into training and validation sets\n",
        "train_df, valid_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f'No.of.training_samples: {len(train_df)}')\n",
        "print(f'No.of.testing_samples: {len(test_df)}')\n",
        "print(f'No.of.val_samples: {len(valid_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "yQVZJzjXkBwP",
        "outputId": "51e12cd2-70b8-404c-a08d-1070175ac69a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Histogram of label counts.\n",
        "train_df.level.hist()\n",
        "plt.xticks([0,1,2,3,4])\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = train_df['level'].value_counts().to_dict()\n",
        "print(class_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esD0oFYPf5YN",
        "outputId": "682badb7-67b1-4942-b356-7c7c9c2fc3d6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 3691, 2: 777, 1: 340, 3: 146, 4: 108}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "majority_class_count = max(class_counts.values())\n",
        "print(majority_class_count)\n",
        "\n",
        "desired_counts = {label: majority_class_count for label in class_counts.keys()}\n",
        "print(desired_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0MNsRl2gqM9",
        "outputId": "a5bbcbc6-1563-4d72-f16e-bd1496131df0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3691\n",
            "{0: 3691, 2: 3691, 1: 3691, 3: 3691, 4: 3691}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYrE034FkXSI",
        "outputId": "d951a391-9c7c-4fb2-9ab8-ef8e1a8101ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2743, 2.9776, 1.3030, 6.9342, 9.3741], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "#As you can see,the data is imbalanced.\n",
        "#So we've to calculate weights for each class,which can be used in calculating loss.\n",
        "\n",
        "from sklearn.utils import class_weight #For calculating weights for each class.\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.array([0,1,2,3,4]),y=train_df['level'].values)\n",
        "class_weights = torch.tensor(class_weights,dtype=torch.float).to(device)\n",
        "\n",
        "print(class_weights) #Prints the calculated weights for the classes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import functional as F\n",
        "import random\n",
        "\n",
        "class Augmenter:\n",
        "    def __init__(self, rotate=True, flip_lr=True, flip_tb=True):\n",
        "        self.rotate = rotate\n",
        "        self.flip_lr = flip_lr\n",
        "        self.flip_tb = flip_tb\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if self.rotate:\n",
        "            img = img.rotate(random.uniform(-25, 25))\n",
        "        if self.flip_lr and random.random() > 0.5:\n",
        "            img = F.hflip(img)\n",
        "        if self.flip_tb and random.random() > 0.5:\n",
        "            img = F.vflip(img)\n",
        "        return img\n",
        "\n",
        "augmenter = Augmenter()"
      ],
      "metadata": {
        "id": "CKzb2bykSY4_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CAOhlpYklys"
      },
      "outputs": [],
      "source": [
        "#For getting a random image from our training set.\n",
        "# num = int(np.random.randint(0,len(train_df)-1,(1,))) #Picks a random number.\n",
        "# sample_image = (f'{path}train/{train_df[\"image\"][num]}.jpeg')#Image file.\n",
        "# sample_image = Image.open(sample_image)\n",
        "# plt.imshow(sample_image)\n",
        "# plt.axis('off')\n",
        "# plt.title(f'Class: {train_df[\"level\"][num]}') #Class of the random image.\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def append_dict_to_df(df, dict_to_append):\n",
        "    df = pd.concat([df, pd.DataFrame.from_records([dict_to_append])])\n",
        "    return df"
      ],
      "metadata": {
        "id": "tDgcDBPuleR7"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "C8rgUjyom5uS"
      },
      "outputs": [],
      "source": [
        "class dataset(Dataset):\n",
        "    def __init__(self,df,data_path,image_transform=None,augment_transform=None,train=True):\n",
        "        super(Dataset,self).__init__()\n",
        "        self.df = df\n",
        "        self.data_path = data_path\n",
        "        self.image_transform = image_transform\n",
        "        self.augment_transform = augment_transform\n",
        "        self.train = train\n",
        "        self.minority_classes = [1, 2, 3, 4]  # specify minority classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        image_id = self.df['image'][index]\n",
        "        image = Image.open(f'{self.data_path}/{image_id}.jpeg')\n",
        "        label = self.df['level'][index] if self.train else None\n",
        "\n",
        "        if self.train and self.augment_transform and label in self.minority_classes:\n",
        "            image = self.augment_transform(image)\n",
        "\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "\n",
        "        return (image, label) if self.train else image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "4UsJqLqinRA0"
      },
      "outputs": [],
      "source": [
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize([512,512]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "valid_df = valid_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "# Create the datasets\n",
        "train_set = dataset(train_df, f'{path}train', image_transform=image_transform, augment_transform=augmenter, desired_counts=desired_counts)\n",
        "test_set = dataset(test_df, f'{path}train', image_transform=image_transform)\n",
        "valid_set = dataset(valid_df, f'{path}train', image_transform=image_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "rm8l4B2Am0Ry"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_set,batch_size=16,shuffle=True, num_workers=0)\n",
        "valid_dataloader = DataLoader(valid_set,batch_size=16,shuffle=False, num_workers=0)\n",
        "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "4SXyKyippyDz"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50,ResNet50_Weights\n",
        "\n",
        "model = models.resnet50(weights=ResNet50_Weights.DEFAULT) #Downloads the resnet50 model which is pretrained on Imagenet dataset.\n",
        "# Replace the Final layer of pretrained resnet50\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 5),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "r96X5p-_q2YI"
      },
      "outputs": [],
      "source": [
        "model = model.to(device) #Moves the model to the device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OYwzKdDzqier"
      },
      "outputs": [],
      "source": [
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "    '''\n",
        "    train function updates the weights of the model based on the\n",
        "    loss using the optimizer in order to get a lower loss.\n",
        "\n",
        "    Args :\n",
        "         dataloader: Iterator for the batches in the data_set.\n",
        "         model: Given an input produces an output by multiplying the input with the model weights.\n",
        "         loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "         optimizer: Updates the model weights.\n",
        "\n",
        "    Returns :\n",
        "         Average loss per batch which is calculated by dividing the losses for all the batches\n",
        "         with the number of batches.\n",
        "    '''\n",
        "\n",
        "    model.train() #Sets the model for training.\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    for batch,(x,y) in enumerate(dataloader): #Iterates through the batches.\n",
        "\n",
        "\n",
        "        output = model(x.to(device)) #model's predictions.\n",
        "        loss   = loss_fn(output,y.to(device)) #loss calculation.\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        total        += y.size(0)\n",
        "        predictions   = output.argmax(dim=1).cpu().detach() #Index for the highest score for all the samples in the batch.\n",
        "        correct      += (predictions == y.cpu().detach()).sum().item() #No.of.cases where model's predictions are equal to the label.\n",
        "        accuracy = 100*(correct/total)\n",
        "\n",
        "        optimizer.zero_grad() #Gradient values are set to zero.\n",
        "        loss.backward() #Calculates the gradients.\n",
        "        optimizer.step() #Updates the model weights.\n",
        "\n",
        "        #for memory\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Print some information every 100 batches\n",
        "        if batch % 70 == 0:\n",
        "            print(f'Batch {batch}/{len(dataloader)} processed, running loss: {running_loss:.6f}, correct predictions: {correct}, total: {total}')\n",
        "\n",
        "\n",
        "    avg_loss = running_loss/len(dataloader) # Average loss for a single batch\n",
        "\n",
        "    print(f'\\nTraining Loss per batch = {avg_loss:.6f}',end='\\t')\n",
        "    print(f'Accuracy on Training set = {100*(correct/total):.6f}% [{correct}/{total}]') #Prints the Accuracy.\n",
        "\n",
        "    torch.save(model, '/content/gdrive/MyDrive/Kaggle/unzip/DR_new_aug_1.pt')\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "CG6C4yH-qf48"
      },
      "outputs": [],
      "source": [
        "def validate(dataloader,model,loss_fn):\n",
        "    '''\n",
        "    validate function calculates the average loss per batch and the accuracy of the model's predictions.\n",
        "\n",
        "    Args :\n",
        "         dataloader: Iterator for the batches in the data_set.\n",
        "         model: Given an input produces an output by multiplying the input with the model weights.\n",
        "         loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "\n",
        "    Returns :\n",
        "         Average loss per batch which is calculated by dividing the losses for all the batches\n",
        "         with the number of batches.\n",
        "    '''\n",
        "\n",
        "    model.eval() #Sets the model for evaluation.\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    with torch.no_grad(): #No need to calculate the gradients.\n",
        "\n",
        "        for x,y in dataloader:\n",
        "\n",
        "            output        = model(x.to(device)) #model's output.\n",
        "            loss          = loss_fn(output,y.to(device)).item() #loss calculation.\n",
        "            running_loss += loss\n",
        "\n",
        "            total        += y.size(0)\n",
        "            predictions   = output.argmax(dim=1).cpu().detach()\n",
        "            correct      += (predictions == y.cpu().detach()).sum().item()\n",
        "            accuracy = 100*(correct/total)\n",
        "\n",
        "    avg_loss = running_loss/len(dataloader) #Average loss per batch.\n",
        "\n",
        "    print(f'\\nValidation Loss per batch = {avg_loss:.6f}',end='\\t')\n",
        "    print(f'Accuracy on Validation set = {100*(correct/total):.6f}% [{correct}/{total}]') #Prints the Accuracy.\n",
        "\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_learning_curve(train_losses, valid_losses, train_accuracies, valid_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, 'g', label='Training Loss')\n",
        "    plt.plot(epochs, valid_losses, 'b', label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, 'g', label='Training Accuracy')\n",
        "    plt.plot(epochs, valid_accuracies, 'b', label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TIp6Sz0bAds2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "U661TQ5wqYGU"
      },
      "outputs": [],
      "source": [
        "def optimize(train_dataloader,valid_dataloader,model,loss_fn,optimizer,nb_epochs, patience):\n",
        "    '''\n",
        "    optimize function calls the train & validate functions for (nb_epochs) times.\n",
        "\n",
        "    Args :\n",
        "        train_dataloader: DataLoader for the train_set.\n",
        "        valid_dataloader: DataLoader for the valid_set.\n",
        "        model: Given an input produces an output by multiplying the input with the model weights.\n",
        "        loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "        optimizer: Updates the model weights.\n",
        "        nb_epochs: Number of epochs.\n",
        "\n",
        "    Returns :\n",
        "        Tuple of lists containing losses for all the epochs.\n",
        "    '''\n",
        "    # Initialize the learning rate scheduler\n",
        "    # scheduler = StepLR(optimizer, step_size=4, gamma=0.5)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "\n",
        "    #Lists to store losses for all the epochs.\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    train_accuracies = []\n",
        "    valid_accuracies = []\n",
        "\n",
        "    df = pd.DataFrame(columns=['epoch', 'train_loss', 'train_accuracy', 'valid_loss', 'valid_accuracy'])\n",
        "\n",
        "    best_valid_loss = float('inf')\n",
        "    no_improve_epoch = 0\n",
        "\n",
        "    for epoch in range(nb_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{nb_epochs}')\n",
        "        print('-------------------------------')\n",
        "        print(\"Epoch: %d, Learning Rate: %f \" % (epoch, optimizer.param_groups[0]['lr']))\n",
        "        train_loss, train_accuracy = train(train_dataloader,model,loss_fn,optimizer)\n",
        "        valid_loss, valid_accuracy = validate(valid_dataloader,model,loss_fn)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        valid_accuracies.append(valid_accuracy)\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "        print(f'Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}')\n",
        "\n",
        "        plot_learning_curve(train_losses, valid_losses, train_accuracies, valid_accuracies)\n",
        "\n",
        "\n",
        "        # Check if the validation loss improved\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            no_improve_epoch = 0\n",
        "\n",
        "            # Save the model when validation loss improves\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "            no_improve_epoch += 1\n",
        "\n",
        "        # If the validation loss did not improve for 'patience' epochs, stop training\n",
        "        if no_improve_epoch >= patience:\n",
        "            print(f'Early stopping at epoch {epoch+1}, the validation loss did not improve for the last {patience} epochs')\n",
        "\n",
        "            # Save to CSV\n",
        "            df.to_csv('training_validation_metrics.csv', index=False)\n",
        "            break\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        # scheduler.step()\n",
        "        scheduler.step(valid_loss)\n",
        "\n",
        "        df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n",
        "\n",
        "    print('\\nTraining has completed!')\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv('training_validation_metrics.csv', index=False)\n",
        "\n",
        "    return train_losses,valid_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guN3gCYfqFdp",
        "outputId": "62d43aae-768a-4fcf-9f7e-0dcd1679bab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/1\n",
            "-------------------------------\n",
            "Epoch: 0, Learning Rate: 0.005000 \n",
            "Batch 0/318 processed, running loss: 1.558942, correct predictions: 11, total: 16\n"
          ]
        }
      ],
      "source": [
        "loss_fn   = nn.CrossEntropyLoss(weight=class_weights) #CrossEntropyLoss with class_weights.\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.005, weight_decay=1e-5)\n",
        "nb_epochs = 1\n",
        "patience = 500\n",
        "\n",
        "#Call the optimize function.\n",
        "train_losses, valid_losses = optimize(train_dataloader,valid_dataloader,model,loss_fn,optimizer,nb_epochs, patience)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "culfm9CsH-w5"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/Kaggle/unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1AcQn3ikQyD"
      },
      "outputs": [],
      "source": [
        "model = torch.load(\"DR_ResNet50_test.pt\")\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Store all the model predictions for the test set\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# No need to track gradients for evaluation, saves memory and computations\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26QT6jxWj_07"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I92W90hYTAe"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(classification_report(all_labels, all_preds))\n",
        "\n",
        "# For multiclass case:\n",
        "num_classes = cm.shape[0]  # assuming cm is a square matrix\n",
        "\n",
        "for i in range(num_classes):\n",
        "    tp = cm[i, i]\n",
        "    fn = cm[i, :].sum() - tp  # sum across the row, excluding the diagonal element\n",
        "    fp = cm[:, i].sum() - tp  # sum down the column, excluding the diagonal element\n",
        "    tn = cm.sum() - fn - fp - tp\n",
        "\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    print(f\"For class {i}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grmA2x5vW406"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0OulKlKU_m4"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r data.zip test train"
      ],
      "metadata": {
        "id": "eh5Tt7zRE4cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ooZihzRhE9ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mMXQy51n2KXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VwtfH3HhE6FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "edKrBcr75TIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwavX-r1IHAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mf8zd-ah2O9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "__b1JrWyHoq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-EB5YrKBbyRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTotw6mzRe_e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEUo1d9LRah0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}