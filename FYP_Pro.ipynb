{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOd6vtK2DO80PWQgHhNF0xM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lrrong2020/A/blob/main/FYP_Pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "VjeGEXN7MH4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwK1YvMFL9Xz",
        "outputId": "060915c8-7933-440a-df96-0104df8b1d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prep"
      ],
      "metadata": {
        "id": "wT_n6JPqMeCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Kaggle/unzip/\n",
        "!cp ../kaggle.json /root/.kaggle/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWJglFbYMmEr",
        "outputId": "b6d9f034-a36b-421f-e23a-f6072b294794"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Kaggle/unzip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GitHub"
      ],
      "metadata": {
        "id": "i_Y1lyGWiJAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #For reading csv files.\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt #For plotting.\n",
        "\n",
        "import PIL.Image as Image #For working with image files.\n",
        "\n",
        "#Importing torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset,DataLoader #For working with data.\n",
        "\n",
        "from torchvision import models,transforms #For pretrained models,image transformations."
      ],
      "metadata": {
        "id": "qqAFoYKfjQHr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Use GPU if it's available or else use CPU.\n",
        "print(device) #Prints the device we're using."
      ],
      "metadata": {
        "id": "_-dPSwwujHvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a17a9f-6791-463d-f613-dbef3d003a83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/gdrive/MyDrive/Kaggle/unzip/\"\n",
        "\n",
        "all_df = pd.read_csv(f\"{path}allLabels.csv\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# subset\n",
        "sub_df, depre_df = train_test_split(all_df, test_size=0.9, random_state=42)\n",
        "\n",
        "# Assuming train_df is your original training DataFrame\n",
        "train_df, test_df = train_test_split(sub_df, test_size=700, random_state=42)\n",
        "\n",
        "# Now split the remaining training data into training and validation sets\n",
        "train_df, valid_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "print(f'No.of.training_samples: {len(train_df)}')\n",
        "print(f'No.of.testing_samples: {len(test_df)}')\n",
        "print(f'No.of.val_samples: {len(valid_df)}')"
      ],
      "metadata": {
        "id": "NjkojF_kawHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44226902-4523-4d39-9f54-1d8652347b29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.of.training_samples: 2530\n",
            "No.of.testing_samples: 700\n",
            "No.of.val_samples: 282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogram of label counts.\n",
        "train_df.level.hist()\n",
        "plt.xticks([0,1,2,3,4])\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "yQVZJzjXkBwP",
        "outputId": "c0c68f52-3b2f-4daa-f2dd-4d1f9d959a19"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#As you can see,the data is imbalanced.\n",
        "#So we've to calculate weights for each class,which can be used in calculating loss.\n",
        "\n",
        "from sklearn.utils import class_weight #For calculating weights for each class.\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.array([0,1,2,3,4]),y=train_df['level'].values)\n",
        "class_weights = torch.tensor(class_weights,dtype=torch.float).to(device)\n",
        "\n",
        "print(class_weights) #Prints the calculated weights for the classes."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYrE034FkXSI",
        "outputId": "f0753302-da16-45da-ca94-4a7528fda73a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2719, 3.0299, 1.3602, 6.8378, 9.0357], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For getting a random image from our training set.\n",
        "num = int(np.random.randint(0,len(train_df)-1,(1,))) #Picks a random number.\n",
        "sample_image = (f'{path}train/{train_df[\"image\"][num]}.jpeg')#Image file.\n",
        "sample_image = Image.open(sample_image)\n",
        "plt.imshow(sample_image)\n",
        "plt.axis('off')\n",
        "plt.title(f'Class: {train_df[\"level\"][num]}') #Class of the random image.\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "2CAOhlpYklys",
        "outputId": "08947d9a-aafc-441c-982f-29357fff414e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "2262",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 2262",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-36f268529b43>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#For getting a random image from our training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Picks a random number.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}train/{train_df[\"image\"][num]}.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#Image file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 2262"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset): # Inherits from the Dataset class.\n",
        "    '''\n",
        "    dataset class overloads the __init__, __len__, __getitem__ methods of the Dataset class.\n",
        "\n",
        "    Attributes :\n",
        "        df:  DataFrame object for the csv file.\n",
        "        data_path: Location of the dataset.\n",
        "        image_transform: Transformations to apply to the image.\n",
        "        train: A boolean indicating whether it is a training_set or not.\n",
        "    '''\n",
        "\n",
        "    def __init__(self,df,data_path,image_transform=None,train=True): # Constructor.\n",
        "        super(Dataset,self).__init__() #Calls the constructor of the Dataset class.\n",
        "        self.df = df\n",
        "        self.data_path = data_path\n",
        "        self.image_transform = image_transform\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df) #Returns the number of samples in the dataset.\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        image_id = self.df['image'][index]\n",
        "        image = Image.open(f'{self.data_path}/{image_id}.jpeg') #Image.\n",
        "        if self.image_transform :\n",
        "            image = self.image_transform(image) #Applies transformation to the image.\n",
        "\n",
        "        if self.train :\n",
        "            label = self.df['level'][index] #Label.\n",
        "            return image,label #If train == True, return image & label.\n",
        "\n",
        "        else:\n",
        "            return image #If train != True, return image.\n"
      ],
      "metadata": {
        "id": "C8rgUjyom5uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_transform = transforms.Compose([transforms.Resize([512,512]),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) #Transformations to apply to the image.\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "valid_df = valid_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train_set = dataset(train_df,f'{path}train',image_transform=image_transform)\n",
        "test_set = dataset(test_df,f'{path}train',image_transform=image_transform)\n",
        "valid_set = dataset(valid_df,f'{path}train',image_transform=image_transform)"
      ],
      "metadata": {
        "id": "4UsJqLqinRA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_set,batch_size=64,shuffle=True, num_workers=4) #DataLoader for train_set.\n",
        "valid_dataloader = DataLoader(valid_set,batch_size=64,shuffle=False, num_workers=4) #DataLoader for validation_set.\n",
        "test_dataloader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "rm8l4B2Am0Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50,ResNet50_Weights\n",
        "#Since we've less data, we'll use Transfer learning.\n",
        "model = models.resnet50(weights=ResNet50_Weights.DEFAULT) #Downloads the resnet50 model which is pretrained on Imagenet dataset.\n",
        "# Replace the Final layer of pretrained resnet50 with 2 new layers.\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 256),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.Linear(64, 5)\n",
        ")"
      ],
      "metadata": {
        "id": "4SXyKyippyDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device) #Moves the model to the device."
      ],
      "metadata": {
        "id": "r96X5p-_q2YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "    '''\n",
        "    train function updates the weights of the model based on the\n",
        "    loss using the optimizer in order to get a lower loss.\n",
        "\n",
        "    Args :\n",
        "         dataloader: Iterator for the batches in the data_set.\n",
        "         model: Given an input produces an output by multiplying the input with the model weights.\n",
        "         loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "         optimizer: Updates the model weights.\n",
        "\n",
        "    Returns :\n",
        "         Average loss per batch which is calculated by dividing the losses for all the batches\n",
        "         with the number of batches.\n",
        "    '''\n",
        "\n",
        "    model.train() #Sets the model for training.\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    for batch,(x,y) in enumerate(dataloader): #Iterates through the batches.\n",
        "\n",
        "        output = model(x.to(device)) #model's predictions.\n",
        "        loss   = loss_fn(output,y.to(device)) #loss calculation.\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        total        += y.size(0)\n",
        "        predictions   = output.argmax(dim=1).cpu().detach() #Index for the highest score for all the samples in the batch.\n",
        "        correct      += (predictions == y.cpu().detach()).sum().item() #No.of.cases where model's predictions are equal to the label.\n",
        "        accuracy = 100*(correct/total)\n",
        "\n",
        "        optimizer.zero_grad() #Gradient values are set to zero.\n",
        "        loss.backward() #Calculates the gradients.\n",
        "        optimizer.step() #Updates the model weights.\n",
        "\n",
        "        # x, y = x.cpu(), y.cpu()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Print some information every 10 batches\n",
        "        if batch % 10 == 0:\n",
        "            print(f'Batch {batch}/{len(dataloader)} processed, running loss: {running_loss:.6f}, correct predictions: {correct}, total: {total}')\n",
        "\n",
        "\n",
        "    avg_loss = running_loss/len(dataloader) # Average loss for a single batch\n",
        "\n",
        "    print(f'\\nTraining Loss per batch = {avg_loss:.6f}',end='\\t')\n",
        "    print(f'Accuracy on Training set = {100*(correct/total):.6f}% [{correct}/{total}]') #Prints the Accuracy.\n",
        "\n",
        "    torch.save(model, './DR_ResNet50.pt')\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "OYwzKdDzqier"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(dataloader,model,loss_fn):\n",
        "    '''\n",
        "    validate function calculates the average loss per batch and the accuracy of the model's predictions.\n",
        "\n",
        "    Args :\n",
        "         dataloader: Iterator for the batches in the data_set.\n",
        "         model: Given an input produces an output by multiplying the input with the model weights.\n",
        "         loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "\n",
        "    Returns :\n",
        "         Average loss per batch which is calculated by dividing the losses for all the batches\n",
        "         with the number of batches.\n",
        "    '''\n",
        "\n",
        "    model.eval() #Sets the model for evaluation.\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    with torch.no_grad(): #No need to calculate the gradients.\n",
        "\n",
        "        for x,y in dataloader:\n",
        "\n",
        "            output        = model(x.to(device)) #model's output.\n",
        "            loss          = loss_fn(output,y.to(device)).item() #loss calculation.\n",
        "            running_loss += loss\n",
        "\n",
        "            total        += y.size(0)\n",
        "            predictions   = output.argmax(dim=1).cpu().detach()\n",
        "            correct      += (predictions == y.cpu().detach()).sum().item()\n",
        "            accuracy = 100*(correct/total)\n",
        "\n",
        "    avg_loss = running_loss/len(dataloader) #Average loss per batch.\n",
        "\n",
        "    print(f'\\nValidation Loss per batch = {avg_loss:.6f}',end='\\t')\n",
        "    print(f'Accuracy on Validation set = {100*(correct/total):.6f}% [{correct}/{total}]') #Prints the Accuracy.\n",
        "\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "CG6C4yH-qf48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize(train_dataloader,valid_dataloader,model,loss_fn,optimizer,nb_epochs):\n",
        "    '''\n",
        "    optimize function calls the train & validate functions for (nb_epochs) times.\n",
        "\n",
        "    Args :\n",
        "        train_dataloader: DataLoader for the train_set.\n",
        "        valid_dataloader: DataLoader for the valid_set.\n",
        "        model: Given an input produces an output by multiplying the input with the model weights.\n",
        "        loss_fn: Calculates the discrepancy between the label & the model's predictions.\n",
        "        optimizer: Updates the model weights.\n",
        "        nb_epochs: Number of epochs.\n",
        "\n",
        "    Returns :\n",
        "        Tuple of lists containing losses for all the epochs.\n",
        "    '''\n",
        "    #Lists to store losses for all the epochs.\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    df = pd.DataFrame(columns=['epoch', 'train_loss', 'train_accuracy', 'valid_loss', 'valid_accuracy'])\n",
        "\n",
        "    for epoch in range(nb_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{nb_epochs}')\n",
        "        print('-------------------------------')\n",
        "        train_loss, train_accuracy = train(train_dataloader,model,loss_fn,optimizer)\n",
        "        valid_loss, valid_accuracy = validate(valid_dataloader,model,loss_fn)\n",
        "        df = df.append({'epoch': epoch+1, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy}, ignore_index=True)\n",
        "\n",
        "\n",
        "    print('\\nTraining has completed!')\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv('training_validation_metrics.csv', index=False)\n",
        "\n",
        "    return train_losses,valid_losses"
      ],
      "metadata": {
        "id": "U661TQ5wqYGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn   = nn.CrossEntropyLoss(weight=class_weights) #CrossEntropyLoss with class_weights.\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.001)\n",
        "nb_epochs = 5\n",
        "#Call the optimize function.\n",
        "train_losses, valid_losses = optimize(train_dataloader,valid_dataloader,model,loss_fn,optimizer,nb_epochs)"
      ],
      "metadata": {
        "id": "guN3gCYfqFdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Store all the model predictions for the test set\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# No need to track gradients for evaluation, saves memory and computations\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "I1AcQn3ikQyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "26QT6jxWj_07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(classification_report(all_labels, all_preds))\n",
        "\n",
        "# For multiclass case:\n",
        "num_classes = cm.shape[0]  # assuming cm is a square matrix\n",
        "\n",
        "for i in range(num_classes):\n",
        "    tp = cm[i, i]\n",
        "    fn = cm[i, :].sum() - tp  # sum across the row, excluding the diagonal element\n",
        "    fp = cm[:, i].sum() - tp  # sum down the column, excluding the diagonal element\n",
        "    tn = cm.sum() - fn - fp - tp\n",
        "\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    print(f\"For class {i}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n"
      ],
      "metadata": {
        "id": "7I92W90hYTAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "grmA2x5vW406"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0OulKlKU_m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ug7vI984UA0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WTotw6mzRe_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEUo1d9LRah0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}